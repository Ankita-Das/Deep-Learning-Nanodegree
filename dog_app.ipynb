{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for a Dog Identification App \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'(IMPLEMENTATION)'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully! \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the Jupyter Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to **File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "\n",
    "The rubric contains _optional_ \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. If you decide to pursue the \"Stand Out Suggestions\", you should include the code in this Jupyter notebook.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Why We're Here \n",
    "\n",
    "In this notebook, you will make the first steps towards developing an algorithm that could be used as part of a mobile or web app.  At the end of this project, your code will accept any user-supplied image as input.  If a dog is detected in the image, it will provide an estimate of the dog's breed.  If a human is detected, it will provide an estimate of the dog breed that is most resembling.  The image below displays potential sample output of your finished project (... but we expect that each student's algorithm will behave differently!). \n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "In this real-world setting, you will need to piece together a series of models to perform different tasks; for instance, the algorithm that detects humans in an image will be different from the CNN that infers dog breed.  There are many points of possible failure, and no perfect algorithm exists.  Your imperfect solution will nonetheless create a fun user experience!\n",
    "\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Detect Humans\n",
    "* [Step 2](#step2): Detect Dogs\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "* [Step 4](#step4): Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 5](#step5): Write your Algorithm\n",
    "* [Step 6](#step6): Test Your Algorithm\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "Make sure that you've downloaded the required human and dog datasets:\n",
    "\n",
    "**Note: if you are using the Udacity workspace, you *DO NOT* need to re-download these - they can be found in the `/data` folder as noted in the cell below.**\n",
    "\n",
    "* Download the [dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip).  Unzip the folder and place it in this project's home directory, at the location `/dog_images`. \n",
    "\n",
    "* Download the [human dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip).  Unzip the folder and place it in the home directory, at location `/lfw`.  \n",
    "\n",
    "*Note: If you are using a Windows machine, you are encouraged to use [7zip](http://www.7-zip.org/) to extract the folder.*\n",
    "\n",
    "In the code cell below, we save the file paths for both the human (LFW) dataset and dog dataset in the numpy arrays `human_files` and `dog_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/dog_images/train/103.Mastiff/Mastiff_06833.jpg'\n",
      " '/data/dog_images/train/103.Mastiff/Mastiff_06826.jpg'\n",
      " '/data/dog_images/train/103.Mastiff/Mastiff_06871.jpg' ...,\n",
      " '/data/dog_images/valid/100.Lowchen/Lowchen_06682.jpg'\n",
      " '/data/dog_images/valid/100.Lowchen/Lowchen_06708.jpg'\n",
      " '/data/dog_images/valid/100.Lowchen/Lowchen_06684.jpg']\n",
      "There are 13233 total human images.\n",
      "There are 8351 total dog images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load filenames for human and dog images\n",
    "human_files = np.array(glob(\"/data/lfw/*/*\"))\n",
    "dog_files = np.array(glob(\"/data/dog_images/*/*/*\"))\n",
    "print(dog_files)\n",
    "# print number of images in each dataset\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Detect Humans\n",
    "\n",
    "In this section, we use OpenCV's implementation of [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) to detect human faces in images.  \n",
    "\n",
    "OpenCV provides many pre-trained face detectors, stored as XML files on [github](https://github.com/opencv/opencv/tree/master/data/haarcascades).  We have downloaded one of these detectors and stored it in the `haarcascades` directory.  In the next code cell, we demonstrate how to use this detector to find human faces in a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvcuPJMuX5/U5ZuYej3xUVt3H7zfdPQ0txIYFbNCAxAaEQOxmxQjYsEDqFRLL6TWaxfwHaHqBhIQQIKERSIx4CIn9LBFoBs30NNO//r3uvVVZWZnxcDezw+KYmbtHRuaturfuUNOUSZERGeFubm5u9rVzvudhoqp8Lp/L5/K5fF9x/1834HP5XD6XfzrKZ7D4XD6Xz+W9ymew+Fw+l8/lvcpnsPhcPpfP5b3KZ7D4XD6Xz+W9ymew+Fw+l8/lvcpPBhYi8u+IyN8XkX8gIn/0U13nc/lcPpd/MkV+Cj8LEfHA/w38W8AvgL8L/Puq+n999It9Lp/L5/JPpPxUksVfAf6Bqv6Jqg7Afw381Z/oWp/L5/K5/BMo4Seq93eBP5v9/wvgX3nq4Fc3F/p7v/PyJ2rKP6VFAan/ZPsfmX+JSgZVFFAVUsrEmIlJyAqK2GkqIIJqPXspTdb/pP21bx5LnQrlOxGZjlFFVVGWv83buriS1tuzM0QfHzP/a3cyPyLP/hcQLXXU61Pa2S6EL8uiiBC8w4dA8B7nPeKcHdbaPZ3XOu2MAL7st3P3e+6c95Pk5T3q+tDyf/y9X32rql/90PN/KrA4d6eLXhKRPwT+EOB3f37D//hf/if1+zOD1Ablx1KZVKpAlZ87ajZ4rF1O9Ie1Q/2TP9X7PV+nQ1xG9EjOGbIH7RA8mQTdkZgjKSvHUbi9PXD75oFv3qzZDZnkVgwZcu7AOVJUnAfRafLl2bUFcM76JudMztGarwpkRBOarM+8zUhyzsh4ZMzJ7kOs3bXuWl+bhmrnqCpCRFVxya7vFJREBrJk7PlkhIxTQDNkJcsREUFE8eIMLLLV5yXjRCEnNI2gmRAclxsQMn0fePnimlevXvHy5Usur68J2w1JwYWA956UR0gJcVbPo8epFUzPDfPnhfXT53z6v93XxwcKgD/4V//G//Njzv+pwOIXwF+e/f97wC/nB6jqHwN/DPAv/gt/WU8nZjlmUelTQPKhRZ6porVDTv4HwNmq9Z6rw6zW538t9zW/1un/IlKWTAEt51AHF6DLY+u59fO0clq9cnKNc/06ryPnPGuDFQOUTBAhBBtKKm4ChHwejNt9/cRhSVL76+Q7wRn4O9f65/QJ1X7VRV1TMaDQxfHll/L+/Rr+6TOe1/NTAcaPKT8VWPxd4J8XkT8A/hz494D/4KmDRaYVrZZzk6d+99wAf7/y9IOcwGIpUrdJ94Mki+9/8I8Ho4nR4hyirvzvQB2CN0mh9JmS7W+e6nLO4cRB0tl3gjhtkoWIkOdqRZnk59rknENU8SHYc1BFNeOcQ/G40j+5SBuUNtT6FHDfNwEkz+bfc1Lf+dJUoTaeXAFWyDnhxSHicc4RQsB7Azlr5zS26ss5QTU88Wy+b/ydH2Pzc54C6E8RKOAnAgtVjSLyHwP/M+CB/1xV/8/nzpmDRQWFc5LFc/+/f3kPXlceo/wcMD6ofA9YPLeqI9r0V3E2+I2DqKukYMan+Oj8JnWcqfspyWLelvm5pgYlqCrcDLjdrK9UcwMrnYGPuDKRK5eAqTbT5+8rH74wTJLFUgJwzrWXOG39dPqcRUBcmNVVb70uGEsV5VQKfXQHJ/19bvyek7A/lfJTSRao6t8B/s77HX0eTb9vYv4UYNGuJ0uU/8FAUSt7n6POSUyScSIm9mYb/CIOnJLxiOhiUqvKyeCfSQ5NZZm+07lkMbv2XDVSVVJK5DiSkIVkISL03sR5nDwCHVOB0nv3gZ30cfQTaztTe2aq5Rw07Lu5hFXfKxgvpc2p7ufa+fx4fur8/z+qIR9Uqkh8WuaD9WN23tNs/bJRp2CxPPeDrviD2tfuW6fJbjx5tSOA4Kgi+0cjgNuAnj7nnBnHEdGysqbU1JDsBO89OGt3mnMVkhfMvgpoLirl97bkw1WRdtlZv8mMdF38Xj87IJ2XXBdg0dAmT2ohE9CctOCHt5vPYPF0keUEmZenJoCqFkb+/Utb9WYmuXPXONVd59+fU5G+/8G+x7Q4IQPnForldQTNtkp678mA5Mc8yuk9mOg81Vfb7GY8zKlUoDq1qUoXZFMt0jgS40jOmVXweO9RgRACoesMPIAsgswsIM45cIJkg73zquZSslqCS549l9pmLfcxB4eqXjhU0yMJ0TmH975wLqYGq2RUC/FZrunEzdpVO8MZCC6e+ymwPb34nT7r9y3vq4b/VAmtPg2w0FNdeZqUT5FLVe9+ssozk7m+Zx5LDI/Ok3M6/GN98vuA4vsI0TZp3eNBqWRbtYr64cQITsUhHrJzTRUQ8Y0bsetN9ao6xHs0C1nNXJkr6J20pVoIKrg0M6cIKSXG41BAI3M8HjgcDkhWVus1603ParWCMiGyQN8HxDm8LFWUjCI5L75TDKC0UA3GKQjisGNzLMdMYG9WniXnomq/KFVVsvvwRV3y3jegaH2voG6SQqRwKXIyVqbFQgqxXEs1j9fvnuYjnhszz/32PgvpUwvcxyifBljMyqnacUosnft8rszB5rQDq15/ypUsUF+efjjn6j7Xnnacex5QngQuzJdAi7jrmIGFAyoQSF7cYzNdOp2ttkWNUR5N0FpySu1YM4sWriJnUhqbKlLBYr/f8/btW+JxYHtxweXlJf36OE1E77i42OC9J1RCUYTKZWueSwJVHXUgEHOaSUJLyWfRXzoBhLR7nwjUOumr2lAtIdUKUsHDIWSZjT+MCxJ9rIZOUp8/w698fKfotsg9IX2e7Rd4dmz+kPJpgMWMH3hypeexqvLcY5mv1I/Et9yYrmVHqk3L1ha37Px00ufngWj2AD+E0zsZjKpmNoVI1jLJ8KAeFY9KblKDk4BILNKWb1JAzJExFZOqc8WYMZlOVZVUfCVyNm/Qvu8BiDEyDEdijCZRjEeCc3Rdx+Fw4N3bt9zfvyPGiCgcDgf2+z3HcSDGAdcF+r7HOViv12y3W64uNmw2G1arVTFd2mosmss9l3dXza6RmCLkjMec4pxI6Rcwz9bl+Ch2nuIXYhPezMjFZOr7ZjatL+cAcc2CY+pHeSb5aRLy2Un4kUjaean99aFt+Vj8x6cBFpwXw+fl3IR8Diye4xTaYJPHaDyr4cz376cz1t/m5OBzpUogpwCXNVk7JEOxfGhZScVNKkQd4CmlJglUsGqrSzk259z6rZ5nkkMieN+AYxxHYozNGevy8pLxuOeQEvv9nvv7e4ZhwBUAAQOM+90Dx+OeXNUIUdbrNZeXlwwvrri+vuby8pLNZoPzxikYb5AhTZKBC8ZvCOaO7RSEjOicQM04zj+/ymnMOYoqScz7+LnnB4/9f+Zleq5njpHHnp+1zz9GOSdFnLvGx+QvPhGweFqq+DGo+OTA0KfB4jzh1lr5qH2n7TwVDc/Vea7USTu/Xtbi8qyn5lFtHOB8ws/fH4GlTMThUr9fguI4ju2lmpoEEIJndz/y7t077u7u2O/3xDgCEL0d/+7dO3aHPSmNJAohSiaEwMXFBQ+7d7za7bi5ueHi4oKLtXEc69AVSc61SZ7SUNpdn19GtDyBJ7rT1KqigpxIdqdq4+nkOh1m07iY9/lSZW2OX+fKGc7rx4zn03PPje35s/wpAOOTAAvTVd//pr+PNITzashU/3Tcucltx06/z3XG00H2fXoknBcf58fPgWJRfyPZTo/HLASSz7RbTgBDZuShPuJi5iuvqRsjwzAQY8R7+63rOobhwMPDA2/fvuXdu3eMxyPjOBiopGxSxf0DMUPfG1kYoxIjQOR4fMtx2DMejhyPRy4uLnh5fcnl5SWy2dJ1HaFYHpwIx6M5mYkz1TA4igemNAuFPZQZYD/Tx6d99D7Fxt/cLG2A0XgNeeq5uiINLtswnffDAOPcWJ7PmdPPP3axPS2fBFgokPI0UCDPAMNZAJPJ30UvNVVibtqbOuXxCl/1+Ca257Gdc+pc6ZwzPluXoKSq4M0d2c2Gpau1Fh5ETgemguqhHZ1n11OKl6MYMFRert2LZCPXUwDncJJQPaJptPgGF8jRJqVmX1biSPSePAI5IqOQU8L5jt55Yswk8hRAlnJTbVKGcYh4F+g2Hb030T2NRw67Hb/+9W+5fXvH/jhwOBwZDkcDl/3A8TgyjuCdkMIaLx2OhCNCyqSDsE8e3UcO7x7o+iNvb/bcXA/cvExcXV2wXfV0vccDa78ia7T+FSWPI6NG4x1Wk5WmeoVmIIj1afH4RlRxGToXCIy4GgxXgt7auHFCwghXVYeoUaNOBM1LQLBJaCD29Hql7Tk6cY8WmGfLM1xHXQDPWkFKwNs50EwfiT/5NMBCq8gKKmYBqCXnbDZvTh4w4P3UeVMHLpnjifSaofGsbrvm1Jb6XdLHEaZaoyOrPquTlNJ05/lKV34b8+SKPYO35XVLOxYrgSSrI2WSKFmc9UNKxHFAvWdMwhAz4xgZhoHj8UhKgZwtDsTuu/ZznmsjSDaCM0bjOoaYcQ76VUfnjCOJMXI4HHj9+jW3t7e8ffuW4/7QOA0jQOs9Q4xKPgw4Z3xHjKktsscjHJzxHc4L+8OGu9u3fPd6y8XFhheXF1xebdmsel5cbQmdxwvG3cziTJ6KX2n9Xj/P7tukMVtts05SYcwJSak4niuqgiuOb8ZtzSW9NAFEOn/9qR2TZemc1PxkOfESnZc6R07rUdU27k7PFRGelms/rHwSYAGQorH5ZTgsfjsFi3ZOOh0os3MWXMOJvsckpjfJ4eSZ55zP+A8u9VM34w18JcJKCLfmKf4i5hGYVpgsVb+eVK0mcbiZqMnR3pOpKOqsBRaolYlRGSPE0cCiEpJGdIIjoOrKRMlN1clxaPc4jonj8djAZrNZo10geatnt7/n/v6e29tbdvcPHHZ7hmFovEaMCYkF+BTMqppQZwO763wBVQUyOcHxGA1YxpE37o4QYL1Z8fL6ipcvX3B9dUEcrrm+umC97s3PQjzO1UjXicCs6kEdO8UVDJyZP9VZ2xJaHExdW5zGnJAYUTxZEhSrU8JZ9KwD77v2jB+Nhhn5+RwYfAhv8dyxp3Uv1MmTdpzjZn5s+STAIufE8fgAnEHqXDD/hB8w85a2B3x67rLT3Ml35/VYETM56uz3eaenspyICJKrS45AVluV64p9Ml58ub6WHzxQtC4ydbWfqVgATnBFzcqSiuRSrAZSLAXZ+u5wGLh/u+P+7oH9/sjx6BmOIA5ycgxRGYbI/nBgGAbuH+4MWBIMw2Amz+NIGiPrjZkWU0rEaA5YVWJ5d/u2+VnEaEAzjkAqPgkCIdgEm1sT7GX9UC0kIsJhvyfnRBwz+3jkcH/kt7/+FnHw6mbN1eWGm5trvvziJa9evWS9Xlud1eVdPDmPpo5KxrtMIpI1W995EO/Aq4GaF47jyP1+R7jriJrpVj0aOvAO53xZiQXRqmI+TYyeG3d1bCbi2Ymqqs1E+1w5d+6zE7/kTKn8kyuOcN77jwYYnwRYGBNeRCZ/ojLkJbKeQ9NWx/ewxU89gInZnqkmZ+pIMrbz5lKFFOvKKVhM13OLk+aShPiy0pX7WuZYsHDwHJXQ/ABSa2OvHt8lcj7wcFD63Ug3ZMCx3+8Y44HjIbE7jOx2B97d3/Pw8MBufz/dZxZikRKGYWC73VoCmDQ20TarDfx6TM5AnojHVNwdVB9HD0/PzTXLhvfmELXd+Bb16UikNBLHIzFm3r07cNiZhyhZ6bqOruvYbDakfLQFQFPpEwpxm0AV1Tg5aKFEzayCEIIj9N7q6j2h7wjBkYOg4nDVeU61qRxVYhSkGVnqPTUOYfas6z0nnVTP0/E3VyfO9dUPKTEux3J1Z6/j5mPQFp8EWDgnbLd9u9GnJrecdmjLYvT0OfW75fcTn3FqNTkXTd7Uh5kWMonWINVpSs8TTE5qYphJMjKwyA0s4iwXRXupJyfQLtP7mnchE2NkzImHuwOH48hxjAzHyOE4cjiM3N3t+c1vvmO3H9nvRh72Aw8PD9y9e+Bw3DGOoxGFrsR0qJQkNhYTIZLMr6EMOMWRRot+NeIQEHNmEhFIEKvVIGXibMCPowHstNpN0sVmtcVLwHtHcB0hBDofyDqSxgMxwm635/Xr1/hgvfriRaJfWT9YmIk344NYdKuooOoRCz5BNRGzsA4GDpvtiourC65vXnB9fUm36olFSqljSzRBTjigm88QnZy2VI3Pmf14OmhmE3/JHbUzzqgVp0DyFHicgkvMZZHRJWjEKhmdreXDyicDFpdXm5Nvl0TlvNQOcvp08+edXkVk+1ziKOAROD1V2vUegUVtaVEXVG2S6fIhN6dqMUtP5SzAXKxNsjCJQEpjRQSJlpSFrIxAEEfKiTFlHh4O/Oo33/Lu/sD9w8Dr2x3fvX7L3f2B33x75Fe//IbdfuR4jByGyH5/5OHhgYyRmV4cOQRC6Ns9ei8cj0ecm3gYLcluhqHEhKhr/VCT8mSnpiBl8xad33tS8GIkY0qZKBMZnEaKxODpvBCCEHxH5z3ZK+gIqtzf7xpI7vd7fud3foY4LTEe4J1HXAbx5g1qDvF4STZps127+nxstisuL7dcX1/Tr1dk50kqk6qbI+SEF8W7aUGq/TSZutezMWYKZHuuLe3H+SC908/zY09/PyX253W29uhSomsyrRYjwV8UyWLRyXnuO/BEVGLpmMhkLjp9KM8x5vW7ZdDU0kFpYXqtaoiODbnhhO6sbHTKExlbLSPzgUZqlpbMfFIV/wiZ1BCnAVFlHBIh9DjnOBwmf4df/Opb9ofE/qjc3w+8vn3Hw8Oe33535JvvXjMOyjCMHEctYODRqLgKbsVTk2SkYXQDOZpo3/WeEEJbPQ+HA5qFzhcpSWdu6VIT3kBGiwmyWnfMwkXhAqw/CvE7puLbIaxWHVvXI70n+IDvHN5lVBO73QO3tzuqGfzm5so8QJv5Ulrfu2Ben1kHmyTO+Iys2YLoxPqhqjUhBKJ6xE8TUdQXySLjXTo7fqbx4hZjpI6fUaaxOX8/reNcmfvJPGVNmb+blNUt6s05oymjMZ1dcH9I+STAIsbIt9+9Buokn6bh/P8F8qprk7J1zhnQOFdOGeY5eTpH4VMAqeg9j9WcTKXJhmyqnpRxVodNrKi5cQ6ZGbABMWvRqmaE6hiL6jH1xW63Y7fbcfv2HW8fjuTcMSbHw/3Am9t7drsDr+9G3t6+A0yNyYhFnOYlw54zkEbLCB4j1cIbAuTco72g3TRgg6tkmVu4lc/vxfrKHplrg3zS7a1PKL4MiqjgcagKUTMhKqKRbu1KSkHjK5QjwxC5vb3l7vbCyDtZAQ4VqydrxiWl+kpNk8z8HVQzMQ7FXX1HCD3dEFHfmeN4WwQsAM1pBnc4qWsai957aL4+J5Y69xgk5mCilWg5MybtWqdgMpHz83cA55QQlmDRXsmsYO7p6fDe5ZMAi8PhyN//e/+o2eVbYBOQdVrlU1oCQUoTWMw/Lzt56f5sxFRYnDeXZlKJvCQvgcckms2iTtPdy7nVTyRbCPg8x8RQRGC7TmqTS7U4ZGXhOFQQsWAwI6iMW4iF0HBSgsQ0m4UiOlR6hhHu70fevr3nfjdw+zDy7t2uOKN1liM7m44tQiMVfemPnEwaoI1faQCXTZJnHMwiI+JPANr6A7SZT9UV1a/pbdKuQ+3TLHRSCNG6amYDDFFhTEoo4fehNwsNkjmOke++fVOiRkFk3RykVJOZSKGAg/l4iDiyGon78G7Ht7xmOEbe3r6jX69R16POI86XADItDlwZ38UFB9AmPL6NFeeqtDWNlexOJ//jCOVTns1C8lO7Vq0TSu6SmZfvqcTRolSKpFUtgN4Jwf8FsoZ8880b/tZ/9t9RSSNVIVVzaaodVsyaepJk9rRIfvTbJHXY4E4zFtMm9pzlnnEcp5yV9rh6joCTuupq8TTMONW2YFQJxQVpx0Fz9iypND0pKfuD+UbMI1v7NSVqsysMvqkiWSDGzP6YGSKmiuwi+6OSYuYwRIYRhETOqd2vpeYvVgsFkWT3gUck4DpHjAMxgR4GhuOIYipKCI6+7wluSvZbV7OEreZpJmF47xAfANuCIKdMFiVrRtXyRSRN5JRJmkg4kkYSnuRNqhhyMpOoF1adb0B1d3dHSomHhwdevnzBi+tL+t43s7OixU3c2covinc9x13i7s1veXj3J9zf79gfjgwxkfzG+A6pkpNtP+ABxMSthZWqSBhVuvCuW4w3ESGdhIzMz23RtieT3jmHD6lZMuYgslqtZiH+7tHLy9JsGkKgD4Gu687Pkx9QPgmwiDHz228eyJmy0tv3qvasze+B5oE300RaWVo8Hud3MBLI6slZZ+cUm/cZbqSZQuuKkEY7Vsy12AfovMN5Q36nQpKIr7xG9aA0zwryLKZB6x8x3wmtrH6a1JbDMRuB520ajDmR80jSTFbhOMIY4TjCcRRiUnIOaI7Fy9SRcyJrTfCSyMkIx9q/ZIilw12w9og4XHAEN/VfKjrKJPFlfAn77qSYeKFJTeItZ8QYzQOzbQugDpNCPGVBNn8ZcpGAbKIJAddJIY8zMWPciGoLWqvu4MELQS5YrwNg1gyHVLNNmUjFXSsq+/3A29t77u4HDkc45kNJuOMLL2Ju9l6gGLJmYv+MX0tGzlfSfEFOnslhMp/8p+N2ssYdHkkNIhafM0/WM4+idc7hdCl11AQ/ITzOTv5DyycBFpqF4WhiVhxdE29NrJ3S4KcZqQY8MnNOnXLGzZbUQCKlyQFWZscvygxQ6oPReDDJw4GGYhFpiG5XceKMjZ/Rz3XjnIqCzQ05g0oip3pfk89FzoovC+MQS3avXMBNHOMQOY5qDlejMIzZJmZKOBdI1TKRBYTi2TlJTROuTn0WixctIaPq7ZolxwQqS5VNBQkO75xZLxrHaKnpJHi8C8SiHuaciYVINavPjBQU5TSPZRYKGHkDuVzVARhzMgmURHBC13vWXWC7vUDzWIhN8C0/qUOzs+C77MjJkZKQzOhhfiK4tpgUYcSe8zAfX/Y0KyaYv2Adj7l9r0rjTU6pM5Hz3019kdt3y+seZsfaq1mlRB7HJLVjZAFOP6Z8EmCRFcbBGPacvE2aAhQpTpaRpBl0huAz9J5Q3QbHImWaTKu16ctLHRPKhJdlfc3yoTVDFdQgJTvHJAofXBnsRdUQ09+rZJJPMnC3Cjw26RxF7ATEkaMlbhkieA9BHTFlI0/LIMgijCmTkhrYVB9PJ+Q0NJXN2mkrUM7R1JBcBno2stb7ulJ5QFu0qfWmNBJvYWFiyjKFCUXWnxS1xPS0MxLeNBEsstXcuJOY2bnuO7IknRMpjjPeICPZfDj2+z273Y7h6hK4KOdmXDRAnxQThULypqTEMRNHSBEU2+6xcjtV4nKZ5iwoUuJFxLfn1/KXFom3fm9S7FMk+xmfhyrYiix8ceqEz+V5TeBwSnQuVenpe8q4PJ9b40PLJwEWqsqYhqIi2HfVElnGtKF9EwhKevqZWN+kkao6FKcamYUU14fnYmp1NygS69Layd6BeCnirInIqWybEbxNYucohFQ00tAtfTHmapIycRgyu05OigtC0mSxCNls9DmWVwaXq3ksgPOkZJvlxNogSWg6kMt9hcEbaVkGrakiQoe0oC8TBSqjaXkZxqB4MZVJUbyaLqzOE7xnzCPN+uEyySWyS1zgbJI7tfR5mLlUNaIu0TJWFdB2mux6HjPVCnTOkztHioCH6AKhC4UzsSTFmjKIkNcd4iJZlWM+cBwf2I93OH+NIsRoGcerE1vOiW2xnFkSHY+4FQSbYZIt0lUonA6zcdRWCEO5avA2otwAOvuJPK9jUPMSEiaVYhrj89LIUU4GTSlOHTku86bOpeeYRk7Lgpw/rfAHlE8CLKq4ZGV5Q87ZwAPzhKxxG2binFYskfKQZ3XOX3MgKQvohNCOFsZexcBGGM1EAlfAoO/Ms6/vHF0nBG8IblaGWc6LsrJq2QBokrTrEmTBSognqenjWieGJnwBzxhzCZlOuK5YI/I0OHPOpKzEmpG6qjNllcxCI4WNv6Ck17N+D8HhfUe3EdadedJ6cQQTykr/KkMMDCkyjoOpGzmTU4JQPDOlBMkJ5AIgwUFyM4LQWYNkYYA+MffpXOo7SfSrxZpVLEspaQmGGxmH1PrVQmiKumMhZbbKeocLHt8ZCZhyJrWU/nWFL6IF5nNx6uOQc/GQmcX61JFbjBHk2R4q7Vet0hiL+pb3ObkK1Ot6xBIXy6SSL87NSheWmyEt667lMaB8SPlkwKLvzNXap3kU5qROKJPuldT04qqi2ISRxknMLRqVgGqIr9o21TJfgLCM9Czii3cFALQcKDZBxcF65emCEAL0AVNDiGUFLW7DMz00pSlIzNqnhUsQtIq2GA+gzhVnILNApGj+iJqV5I23ULW0+zk7csqMydx9c0lyO8RMzNqEzyatMRdPTf3pQmC1WtF1HX7rubq8pPehuGVPoraIcDjs2R8PPOzNZVxF6HCGQCUNHlI5GVfUNHB+7jxndZppc6mbz8EiRSUG8Ewgp4IF8GWTNFOCAdjvBh7ujzzcD6zWHbbtYF39Ban9h4HwZPo1a5Hz/dQGqTxH6R9ZRp3mwsnknBsALwYyxX+E5QZHpqYYnNT+rFxF48y0a6pXMzrPpAdbIA0oJg28jtvalqnuOhc+VvkkwCKEwM9+/somj1bRuKyIOTeSM1WyDZvULk3oOffNSM0Xf0ZOzolRneUFOLFQNK6jEHCVqKymV+ccm5Xp2d6ZRUTEAr2Q6kthJOVkV9/aijLTViufkEre+ywH8yORQvT6iIs9yVkei5jsPasQk3AcEw+7kXFMxDGV8PTSn5oNKGoWc3GlT8reHYDzynYdeHFzyatXN1xfXnF1dcXFxQWd93hxJaeFgVxKiX3xHn1z95a7uzuOYw11Lw5oladwDt93dP2aN2/viUOihdsXSc4744IWwXe57teqHI92fOhKEJQrWx1mrJbTAAAgAElEQVT4bGREduS055iUuzSSx3t69y1ff/UFNy8vcaE8bx2BTJTEmDOHeOCQ9ox5RDz43kOepACTQUz5tc3Ya+Ki0s7yqiboNilnfMJ8XM0lplOJYbn6G3hJWKrMlQ13IiU+ZuZ82BIucUL2Twhxytv/mPJJgEXXBb786quZblU6eZbwRFUZ4+RDISL4U7BgKXqpLCNK27ElItAm0lOpQXIjtyaAUhPPO4u2rCuDEyMFVZdOXlXKqIFkS1a6DgoTx7t+z2GIRaweURlwKTAQzcOyiMfifHEJtzYlxbYUdKZ1A2QZIbtWt914BShltfZs1x1X11u+eHXDV199wdX1JS8urum7zjJpl6Av2zbRgG+73rBZr+m7jpUPPOx2xBh5ODwYoVqsHRIgiNAFR9cHi/YMgRRqmn5zmAqINblsmqRZ0JRJqgxRLLxcvInhZa8Uy3BuUaJoIOfIMSk5Hbl7u2e7PlgOjI0niJlBxSWSK1nMq2Tlyz0i+BBam6atFhUktwVpMa7a++PJOPnQzD07K8FdUhwsFBd7r6peoYpn/jxVsnCzcVjiazztt5iXJOZSrfs44sUnAhYdv/u7v9smZpqZp2pRaOTcBBaTeDt3OZ7UmAoIS5v1fH+MuvHt4lpV8lhIFalYLLR5xBlPUR2c7LuagEZ1JkKezVU0rTwZR79+MGZ/fyA/PCBjZMxVYjIVS7wUS0a2Fdx3eG9qRtWXDTiLeuPkJIAo0wfPV1/c8OLmkpsXF7x8dc0XNy+4vNqyCtu2y5sXU0Vyzmi0iRZcb5YSzWgyU+YwDGSNHIahkNSZHBMaOwtYQ/AidE7IvTe1KmZTK5iyibX8poXd1xgbuJofhTPyte41qEbyqli2Lz0mbm/vCZ35vVy/WHF5GQhdQohGQooQ+sB6u2FUR+iTmVDTFHFqHrlTVvUwt6KVsXkuY1cjE6uKoxMQwAQuQAn5Z/FdEzrLw5w/T1EtfJlbcGiL8RXnY1Xb+Vn1x/KarXwSYOFDx8svv2x6WUt/xhIcqvmzebzN0DTNEHSevAZAvFuAhcwiPKfVvgQE+QkcYFI/VBXnDdFrVOZ8C7tKBMaYm4j4yNdjgYB2XdNvHeI6nO/J6jgeR3ADY4zEpFBACpGSNTsX+s32G62Je00Hz7g8ibzT9ntmXN2u13z5xSu++PKKVzdXXL/YcnV1wWa9wmXfwu2D9yYR5UwcC+nrAzln1us1XdexWq0swKzkldgPCuNoMTDZcm+a+7v1U+c8zls4fs6xEdRTwJ02VYqUGVMqnFPAOwM/A0mPTwL0ePXkmEh55O27e0JwdJ3Dh0tWq605zDlzPBPn6VZrLl/09OtMipCyb3k26zM1Ja6QjXUszsy5pyv2xIHM1dAaGyRnj50+s6i77SU7C3OAAhTI7FoziVpHfKiLT+XwyoIrM0D6keWTAAvnHP3qAjiZUEURPJdjAlg6PlU0nRFRQNtlaj5puxlPMV/1MzWhSW4DBwyImiv3rDR2H1pqja6bD4jqEnwa2eoaAZpzRvCs1omH3cAYM8chMg4K3tF3a8vUpyXQTA38SBb8lfLY/CWEXKwEFlzknBC8cQ+rdcfFdsXVxZbf/72veXF9wfaiZ73pWAdHcNaOEByuxKY4J0gOhFBWODzqnG3z55R+FXi437M/7ozD8cI9OygZv4+HnUneWUlxYBzNhIs4QufNF0IVS4EnzTElqhGYxCkuI4krGayEusVhnVS+Czj1xMMDD4c963ee1Qr6leK8peUzK5J5pm7Cms2mQ9Wj2YH2s3FWHVDM5Fod5ioQnMvmfu6V8vDouDouVR8DTE2H6JBH12kpFc6cV4FDZrzc/LWs6935ifSe5ZMAC2OejXWei1lQeemnPNAmPqN8WIpz2Pp66jpbPi2rUtfWevCoUyjmVFf1z5kk0/iVatYNdjUj1aSs7hXExsKM+Qbz0iQbOz7jOY6Zu/s97x4OjGOk6y/sOsVMiQOXjHPJ2TJLpTTahNRiCoWW2KbrPZebLdv1mottz9X1BV99ccPv/+7PWa8D3mlxVbfYlhBsfxDBvDJrzENl/y1BjJu4Gudw3nP1cFV6TlmNwzSZs816hyVdTiWQLARnPiNti8JqQaoBc2Vt12kDpFhGgXpPlOIVWgnvbJ5mWSAm5WF/oH+XTQVxG66ko3e2C1kIPV3YEPwGJz3gSdFNC03xJs1FHUk5PJIoTsfAOW7A6XE5vGaTt0qe5wDDfFGm46oEDCXIcQEY0+d4Ekh5nq/4iwAW4tBuu7ix6fPTrqpzb7dTEseFpW43f3cnD8qpO/Hlr1JJbv8rNEADE1If+9ybq7dAARsrMWWcs9XaomilHe+8I8bIN28f+PPfvObX39xyPB7Np78r8KUecQHvIOuIiGcc9+g4EKDtCJbGSFQLJru+vODF9Zavv3zFF69e8OrmkuurLavecXPdY4nRM6Hz9H1vKeu6S+rGOc45XAiE0FEdwGLMJBXGsS9Jga8Zx5FV33P79i3v7u94e3fHbrfjGC3K83CMsBK8etbDSI3/SSkzioX1u7ZJsdSexkycMI4RTZEoI7Ecl3spGb7KM8RW5KiO3RAZUuQ47NntH9gfr0jphi9/1iMayLlD6XDSE/zGVJyyaXR1yxeX2rCLOplVH42/tNzYuY4xU7mecpJ6srqiIk+pDRbnza41BxAwiSPOFs5TlWc670+evvh7lE8CLIyIMaPUdGPn9PzT8+aTdTlx3RxktB5R7eA0122LcG1cZhGLpbrklC/NB2ROFtZw7PbQdNIZZbqktaU4zGQVy5Qw00ezwjBmvv3ultu394xREdeRVdjvhonMLVGIqRnvLNDNe0/nnenWJLzaHqlfvbzhi1fX/PzrL3j16pIX11uuLlZ4p6z76gNhINGVlH2bbtXMzDUQzJfdwnLfM4zGiXgRYln5us5z8/Il3apjs12zWq142O04Ho8cxoE3t28NHDpfwqyVw3Ek5yMp5eIYaY5WVepzoriq62NCokgmVz8G7Y2LESznhBRXbN8hGlFNjBEOR+WwtwhcVY/5f4tFMnsjSJ0EcjY/l0wxTRYD6jkHqYXFrvjhzCdkkzbIj84RaFLaaWk8nM5/m0jwRGq5Uxa+GUwWuXrsOX7kY5RPAiwAajZDmZkXba15usydYvzpKq8ztK9AUOc1M0/BAiELziNB9qYqqGRE5jmeGvVFdb01NVzKwGGRTQvA+d4eeCoOVq4EZRU2an8cefP2Hbv9ES1ivqqyP4wNKEKw5DOqZuD3EqxdakAhqvhCaK27nq9fveSrr2/46ssbrq/XXG47NuuAI7FedQTn227i1Y+lE0fwwbgbCTgfCD4gzjWyORfLQcg2kaL3pEuh6825q+97tvt7DocDx8NombqOI8NgSXRxdh9RJqVv9kQLiPkS3FWIZZ2AvhxFVvMypez5mikh86XCmBOHY+JhHznsjTSX4qnqfV88dg0wLDgPnGrZAsA8cVUEKbHmMpuclHHiS9DgfOjV9irBxsLJxKbyYnrq+wOImcBVpw2668B1QnMVraA6gZAnacmjsliqtI2lj1E+CbCoEw6W4HDGhX5Rlig/MRuilIcoU5AJlGS00qzdk+ZRB4RREFkskAtnZqmqjtTckVosfM1Ls7XBKqjPRopFpW4NmCmDO1mzLJ3+kbt3Dzw87NkPIxonXmSMZad0TPdXXwaJTn4Q5sgUIZtj2Hrdc3X1kp99/SVffHnNi+sNF2vHykPA0sz1QSzfga85OB0xZwMLV0K5xdh3NwPcII4c6i5q1efFs9Ie52tYtLDZrNgfbVf1wzgieLzcsT8MlpK/U7xsOMSheLfWl7SH4LxQo3CdVitU8f3IkJP5GbjSB5FEUPNt8WVQxZjY70bu3j4wjtd03dpA0BWza5YSIuOaybayZArF7f7MRKskZh09BRRsslKCyOoYrbTWJDFXn4myVpxWjalj0ykT7zaLlp6rIfX46hN08v6xZIsfBRYi8qcYa5KAqKr/soi8Av4b4J8F/hT4a6r65tl6mDr71LHqVDc7uf5T7VrqkHlZVxMVhSLuzqSA6l4ukJmceJZlikBVBXXSvBhda+c8QlOLB6Vg/gG28o0p8e5hz+3tLQ+7shKPh+YUlbRHVZAM0TxNLFVdViNkXUDTQIrmzxBWKy62W7766iu+/PILXt5ccrENBB/xbsR5CM7RByP7vK9Wj0AAfHJT6vtZ3I0WHwjvfcmuFVr/uuQYSidZ0hZhvV6zOpgLeYoQfI/3HW/v7tnvD0UdgTcHGzrNNF7B1zmkmFtPwUKYCFdxznxKNJOjKY7eAcGC0zUnjofIw/2Rw+FA161YrwRXeArvO9BgZveSns9I6qKK1Oss1IglD+CRaXIuR+FsfC4lkmrFqepkHZPnQslbv2S3GNPz66Vn5e/n99r9kPIxJIt/Q1W/nf3/R8D/pqp/U0T+qPz/17+vEj/b4m9eND+Ni7Iwgc7FVNqGPuoypz5ReUGaurJ6Fsa5yh1qOSksT0B1wrEH5U/IJI3a1KBpgExi5lgGhyORk6kWa5/Z392S9jt2774lj/ekeE8cRsayZG3WG1Q9KXdkF0ihQ7wv/gYZ1dFYewHphNXlmldff8nPf/YFX7x6xXod6ILQhRV9gH5l2wGKExTPmMzd3JfMTDmEKXW8a0tiuw9xAt6xCp6Mmu+CetYIgyRUhN4FoodAR+82dFqkk3HAa2YfPPuDbVq0DT27uEedmtrnMQuHaFnbzVxa9wuVkibAFT+ZmHOJkcmknAnOUxQMA9s4oIMlu3l3j+W9WAeCC8SmJmRCWBHjQE4ZdWqJgnNCJdP5ZdZ5W/iLU3hORaV9vHBpUJ5a059SC8x3dDlYXVtzMkhj8mjmfYpkE1YlwG3Jn4jwaUgWT5S/Cvzr5fN/AfzvvAdYPFWekh6AxzLc/DwA8vmekom4mowWFTCm3Jp2/crOT5vKNJHzPSQbAFIultPHFpq7uzt2Dw/EwXwTHOA618Krx5SQzrNedXT9ipwSw3EgjUfb8jFDCMLFdsvNi2tubl5wc3NNVwjFrvP0ndB5JTjLt+F9TRFnkkXwXXH6WWZgqvxRELG9QIyJtqDOmhRDy/4ZabLnVymk6zqurjpiLlYNHH1/ZLU2S8m74YhqZkzTpkDeeyR4hmEo21baY/GYaiLiLYOXN9Wzxgs186JmhmREoXMBL6bL397e0ndrNutLum5N0LpHR8b3q0fPsnr+Pvdsz57D93MEz43p02wXc2VjWW/xZKX4Ep255sckN+HHg4UC/4vYjPpbqvrHwM9U9VcAqvorEfn63Iki8ofAHwK8vLnCnwvy5/tueC4h1OMKv/BMdiD1NUuGBX/VHcWmxk31VOAQmR6cam6DG51yUrZ26PLlxfarGIdEPJqzToyZd2/e8ebbN3z3zWse3j2UhMTmfRdzJHuHeMfF5TWr9QbnHMfDgZwTcRgJIvRrz8vrF/z85z/n66+/5quvvuLrL3/GxdbyZa7WHV2A4AwsVBMh+GJd8Q0cnARC0+cLP+BKhm0RQkpELUldUs2r4MgOXlysmaQvcxYbhsGS23Q91zevePHihm+/e8PbQuTGmEgivFlvuH33lv3xYPENzoja3nlTA0sqAuOJzOfF+YALHhfsXdXiaXb3O8sQNkSyy2w6z6rfMEblz375DcchgQS6fsuql9bfLo8Gfk6Rso2hkkBTCwhcjB8oqscS/GfsGM8lnHkOLNx8J6sFa+cadmmVduep/Gbq0ccGiVp+LFj8a6r6ywII/6uI/L33PbEAyx8D/P7v/ewH3d2y02vHnnkQsgSiifuoEsYTv5ddrWZtfvL9qVVFREjVm3QWwKZq+48+PDzwcL8jZ/OXECzqdMwjMSc6FxaRszFG0jjiRVltV1ysem5eXvPFqxte3lxzdbll1Qe63vgFy8tRImgdULwz6/8tY7XkSaJY0vvTfSXrD1dWXSkMsYRV83xNKTHI0Hii9WZD6NegnpikpbA7Hgcutxcc90aE7vd7cixOR8UBy0nxf8la0vthwWrOmVu6U/rOfFBEhB274uyGhe6TOIjSB3ARHvZHbt/dc/WwZ726LKBAC0IUse0KnbMs48Vx9oxZtI6eGYfwSIR9mp5/bi7LIrBx/jkv2qFtgVtWdg4oHkm6P7D8KLBQ1V+W99+KyN8G/grwGxH5S0Wq+EvAb9+nrqew9lk1RGylfKJt5ZjHqsjcmatKBovfTz6cA4L55+eAwkymY9vxvRJrx6NtOLzfHYgx03frRkTFmMHZihoV0oy3iTFyOOzonbLdbrm+2PLi6pKXN1dcX12wWfe2w1cXCM6S9HgU54v64RTvZhKFmzJNF6+vdi/z1PM5WQ5TAxkBJzPQCZZQCLcYmN57QrcmeCVt4ars1J6SqXQ319cMhwP39/d0zhOJbUc3U4OKxaCK2Vkn87cmtCSmCcFiVrzvikt4huiI6Ug+RDQI240jJmG3P/LwsOfqamS9tlD8+aTPlXNUFttQnE6408/PjtMPKScc3SS8TGSolWSJhsp/FVaeAoaP0b4fDBYicgE4VX1XPv/bwH8K/A/Afwj8zfL+379PfU/h3vM3+T3GVTn/+2kkppXJAeb0uhMghcUx8+POOebUz947vHfFTFh9KA68fnPL/jigOFabLSkljuNgKgiK61a2/2dJ555TQpPZXZ0Tri+3XF9f8fLmBS9fXPHi8pL1xZZ+ZdsBOmfh/15M7fLemcPTSRr5yUpk2b7mwTjze3Il65QlxpkkFJ1nflLb9tD1PV23IpfNfUJJsnNxccEYs/lSjIn9xSX3F/cch0MxEydLFiG5mRgtWMrcxmmWJl8S4di91fotOtWh48BhnxkPe8jCRXF0G46Jh92ew/HIqt8gneVHNHOwtr1UUpEoGpCcjgkmCWGpgtCO/xhlnqtishiadDZvhLjzi9XHLD9GsvgZ8LdLgwLwX6nq/yQifxf4b0XkPwL+MfDvfl9FCk+YKOuvz5ST85Yd9sS5ek5lOc0H4Gah55MD0TmgEJGZL//yN4DQe3wXYMxkMimO3O92vH7zlv1hICP4rmOMkcMwNqKw7zrWmws2m43p5WWl71eBlXdcXV6YW/fVBdfX11xebVmvbbMREcU7KUl6vKm4MmVQqm2cqx110EsD0CmlXCgqgUkgBTCKlSLmKYajSiPOO4IEjiWS0ovQB89qtWK7LuHtuyPr9ZqLzYbj0eJgYhxKkFhq/Ro1mnXi5BnPg6RCCPR9j3cdvfMkHxjHgUEPxKSMCUKCISYOxVEsXiSCdMUNv2x1oArMYi+Kv85TYvzHnpCn4Q16suCprTaLNp2Cybl2PSWBf0j5wWChqn8C/Etnvv8O+Dc/uMIz+yyU+p47iUfSxUIlOPM7RWR7IpR1bhvPbukl6hZ1nz/vrNThLGtzzEaY3d7v+NN//Atev71jfxxZb7eMKXKII/txICXoe8/aWxj4vL7gAO/YbtdcX17w6uaaL17ecLFZs+47ghNcsM2C8F2z9tRcHKDNv2K+QXRtq3Ou5WRwgkkQysLSYQnMy5qrDi9SWHwhFSuDy86cyNrqaxLNqus5ro7E5HDeomJXfc+q6xmGAY2jkYozXkWka8BR+9iSE2dS8qiuTYILgRwzo5rk1fcruLyCZBsqQ6BfWzrG/WFgGCJdlwjBEYszXHVCsw1/XNn0SheAOnvqZ8fQubKUVJ8b0yfjdUa+1+k+nS7NRaAR8ifj0Kxq590SPrR8Eh6cQNlF/HF53nQKCySeB5a1T/X32W9pecSiSp0S50xLWZEs5CTKlcdm1KWNu0G+mbeC57A/8N3r1/z22294e3dP6FfgAsM4mOgrDvHZ2P4iHg/DQE6J8Xgk50zXdVxsNrx8+ZIvX73ixc0V24s1fR/KKgmheFO6oo5I8VgVCWhxRJsMOJYPk5LlPqm2XjNuYLkbV7u3bG7RWVIhGjJebO8USqIWFaEvF8q9cS598MRQMnIV6c07V9QcbINj51r8RwOJOiEwslhT8YxNiexsk+c4WPrd4Mxxo+tXaA4McUeXTKiMarzQcRhYrTr6PiyklWnovO8EPz+OTv9/H9Pq4zWstEfds+dV/mL+Aswd8CMJP58IWEhLPXdanu+gUzPTLBpv0UGTXwXUzWeWv9cEwVonirp2jrH+riU0Mae9CQhEytaKULJw20ZA9bfDOJCPGbTjze0d//Af/im/+OVviSnT+UBMyjAmnPesLramQngPWTns9oS+tzD1ZHEdLy9e8Jd/50v+uT/4Z7i82LBd9XROShZoR3COEDrLoenM+9EX1UGrf4G6peuzGp9SYyCEMnDVgph8DSNX80Zt/gA66fNS0wu6koy2iPAZZ4mNBbxs6Z2wXffk4YgPysXlipfXV3z75oLvvvuOdw/3hN78NPDT/iBjidOITO7UlUBGbNeuGDOHw5E0jjiUvg8E7yD1jINw/zDSdfd4Z16c/SpwcbEhdCVdn05baAbxqC5X5aWU8eTQLFs3TueUrpqNp/Mlxad4uFne2LnJ9uQaZ9vykVSlTwQslHORePB+nVB5BZFKDz9OUrKss070ChL1vEJSWn5+qp3k1FGmtqtKFfPP5x5M5zwxC4chsd/tuL+/57jbg+tIYya7REomDvc+NP3yeDgiImyds+zboqyDsF73XG629H2g9zOiMpQJVgi/OlmdmDnQO9vMdzKR2o5fTdetUgFmfWigoYq6KXtTywhSwHDuNWjF9jPVkmPC+AxLuOwFVl0AWbFe92yHTeM7Hg4WiBaOtg2h9b3HuYQ4hysSTqzZ0p3iZ/kfUsk3YgAFw3AkxoGuD3QipJgZhmjbBpQkx1XNACMJbUBMKfffRxo4O8ZmSYDnwAbgngELd0rKn5Uo6v8n/MYZH4uPaan5RMBCHjtGlXKaDGde2kNutbSzlr4ST1bglseUiM66YXGFCij275OmzB9CjVWo5BPlpVA8M4XD7oF3t3fs7vekUfEB4phxLpJjIrsaPVu2MKzbYJQ6gw+sVoHNamVmydl+liEEXPm/tV7mAVgWhl1NnXM1ybqx2AuZiE7zp6DsRD6Z7ur9VV5BNVL3MIUpbBuXi8VCyanGzphr+QpKuy2exBWJyDnw4kiUFIFz57oawVf7hFmSZBX2+4OlACx6ZEqJcUyMeeSis82TRIRxs25AMRwjYzRHuRDCYhSllGwdmfuanHn2T5X5AjJ/f6oO1aW3ht1jKo/m8fww61DNefK0Wm3l+8Iyv798ImDxNCg891Cq8CAIVH23FN8G2RmnKybrixQzXP1BBZyUtPMtGKiCysxqcObhnNre6yvFSPA9d7fveP36NcfdHhHoQ4fDyEcdlTiOttmvsw17ui5AccryYrkjtusNl5eXrNdmVq0b4HrvW2q1ulcKM7XC2lQlsJkZLpcJLmJkjjytG0+SxJnnInmhcNvmPo4sFkuTa9o3C9lCUfpVx2rdM6Y1x+ORruvaPQnOnqkUsPO+TTiZEXbNH0TNijSOoz2vwj2lZG1LjejLHA6H9joejwzD0HJcOh9K3ywlig/1XZCTsXLu2CVgV/GDxf/TVVMDBpFZ7jjJZ4HkpyifDFg8NUCfUydql02isYHG4/rmDypPcQ7l/0U7il9AFbW1Zb2x78+1ef6+MGnNmXXvub+/5+72rWXCEqHve3CeLgT2UPYnBQkB3wc2G3PxlpKcJoRgpsaLC66ursxU6CcHK04HHssBOXeysnaCzqI7RZ52FbbfMzoTfZsKVnffKoAxXdOsJDYRl1mvVZW+79lsNqDCOI4tEbD3Hu+ETCoRqB0hxAKEDikp5Go9tmmyZfwajrZjWlWfEhb/YxKIEbaHw8B+f+R4PJasXSUlnQ9IeV56xtfkcd88t5A9L0HU/p++s5c0KXd5fTk5vwnOIk0y/lBV6UPLpwEWCjpzbV3qXsuOXoj+c8tD4R2kSBIqpw9bGz8xZdFSU39a0JiUp+ZKngMhl53IIE3bKDJNSrP1a8lZkXGhbkJcE+c6NrIm0LN7d+D+fsfhMLLabAh9h4q3fUFxjJHCW6zoQocLWwMaRjqBjXdcX/S8vNpwebHBdw6/6ixa040EbwRj1p7s6316m+DiCN6I2M7ZFoW5gl+xSKgcJtVOZFrJnLSdyXwBF+tKOz/GsmeJYCzmbDulDuNJRDJRLQ4nqYFOD0jX0W2UeFhz33dc9oF9EJKDrI7QBxJKzL3Fcjgh+N4iVSlZ1F1PCB2hM+sIO7O6GIhmYiobIIvFCw8pMGjHIfccRle4qUzWA0pCvG07kcXhNSykg+nlF5Pz0XYPfto9Xk98cNqYLePW+JcCrnnVyOY6xqSqQm1I24InRWW1Z4epvXXuiAEjRSP+GF5inwZY8DQqnqLyXLyb/7awY5eIvPnAzxhbDzQSD/PpRSQseYvS8VlqRqLqlDWJhiYOMyMLSz6CM+RVHMx9+2Fv6ebMo7OzPUaYEsGaF2LXMk65GuhW4kY2mw3b9Yb1em0E5qwvJo9MKaRgEauZtU9Mwulc11bptvFOBQehcRpm1ix9VbxGjXWQIoVM0bh1gIqEpZhcncHaM5pWwbmKUT1VqyqSNeGLNOUE/GCTPxaASyk1c7sryYAqh+MKd2T9Wp6BmvenK1m/qoXlWMzRaLbsXS6WRMUVMM+PO4u3ORPIqFN/SRlryjTRmzTWFjcKaVTaOztuXuZ9dzrzl0AyL2Xh1Lkx9YeXTwIsYkq8efNmgd5gHZTKhkC1zDtxntSj6tKLIhOizxWIZh61/+xQpSVfseMLV1EnvzrLoDXTP+cDvrZh2qtSGsuvw47Qd/z2m++4Pxz59i7B3Q/qqs/lB5aHeWb+e/jTXy9//xt//a9ZQJrlIkfF0gmS4nLiVs4Gx2IT7PZzMeHPJWUm/soAYiZRzDglBDSP9SSqVWyuNtZyGlSdnyBRK5gjZ9Hkg8qnARbjyK9/85v2/zxeoZa53l07vlj6MIQAACAASURBVEY/1t/P6YYwOVOdfi8izfqwLOZMNN8HtZrj5iupqhLKythUj5Tb6lbDtdPwgJPAmBN+liH8c/l0SkoKvWVfT0lLciHb9e4RWYlj4WszKza2EvPkR+fMmU8VVyUv0w3nJ1GXsflbrW90y2tNn7NFC3+E8kmAxTCO/Pmf/znAI8li/t288+01/33JODdwkSU4AM39tYnn5Zy5FGJb400gUY+fg0U17YUQ6Ly3JDBZm8SjqmY61NH2voiZ0C/B4vJqA+LZbtd0ISzGx8Z7tus1X716wcvra15eb7m5vuLF9QUXmxWvXl7R94UQDNKu63xX7ssci+o+InX7u8cidV3ZqlnVF15mWiFF3OP0hOUeYzw2EXohdZGRsvVhzFOUZNTImCL7nakCu4OFqD88PPCbb7/h17/5hj/79S9JWZFgVp4xK2Mxv/rQk3NuOTNSSX9XU/Y5FyxUfrCMXHE0h7YxmcS/Wnm2F2s2m55/9GevATiOSt/bbmmqingFD16lEI+WO3OuduaTCbt8P+/tWxeWeT/O68jTwZwt587RupObkRM2N6YAyQYaP7J8EmARY+Tbb1+fFaGeUkFgUkOmAT/lzJzHEZyWpLmRlNUC0PaoLPUxC92u39UUbiEEyNpUpK7rCM4xjmPR5wWNqQEJkhjHyHEYTvRcC4P2zgbeMAzFYmHS1boPkDucatl82dMFTx8C637FuuttUyApE7uqRJXDwMLJjcd4HDRWjz39TmZp7GSeY937FmuianuM5rLzuRaROhdBHrBdvucktGCqYbR9MKyfpfVTv1mz3W7ZbC1/p46j7WOaM0mnybVarRjHsfENFRwna482c3IbO+JxzjZdTppLcNnkFXn79o5x3Nh4EGxbAe/oZwuL5QCd5wN52mS5zEsx3X8+E9awlEBMX3Ju2vz6tB57X0oQoe8X9dWpbf3yFyg2JOfMw2EPLDtuDhZN9Zgh+3Ok6CnoLEoZ8cu9I029aQOs+Co08IAFWNiKGm1X9RBwmFtycN62FhxHQjDzZ1LL4zAMsXAhy7bW9o7jUFh8oQ8d0lm8xKoPbFYdm1VvyXALAdp1JWKy+iNIwDtfErnU4K56IbXYCgnN/cp079O21Ezbbno1s95kqs5ZiWpek5JNZK7Zxw2KJ3FcJJvrtEDC4SURRRA/kZuqZq1ar9fNhBpTIuZcNso2C0oFFlWzjGix1Jw+9xY+P1sEcIJmtY2ScqKL04T+9tvX7NYr6ycB3/UgHp+nLRRPJYJleL/gZJIafHBnz4FpU6j5+Kxj0MvQgOjcWBe3nAPTPY6PxvopsPzY8kmABZyaS3ncSbOOPwWS+l0tp74ZcwISmMJ+dXnMog06iYWt0/2SS5nzKCnZLuu9C+wOD6Qxslmt2a43DHngsB/Mo/BEf6yh1cMwMI6mrvTFMakLnnXXcXFhIegX2y0XmxV9mCZYSgm8s2Q3ZTMj7/zkwapSfB9cYeZzkzwmyqdS/vWkzMLm5vykvuTlM7HPBg72uT4n+36ejUzVnLG0uFQ7ZxagcRwNNNTR94GLi4sSbSqkHIlF/Yk5lXgRh+jECwkly1dW64czk9FJsH4qkzJFJa2mZ/ndt2+566eEPqYyOaoSek51OwWD5evU1HoecE5/c3J8EiyamunO1DufyvMNu59SZ35A+STAohl2ZmDQyjM32+bDbJJPJrp5FScdJ1Jya4INZG36eIs4LRMniDzS9s4Cm3Mlx4NJBc53XKw3bLsVve/Y746ktw+cxglJ8GQxFURzxjlTa/q+Z90H+lVgu+7Zrles1ytL8BICOkvW6rCVf5nG56TNjXB3i8FmJ9R3LScbUEgxkUoL3FLrl4IjHme+C7FIgrXfVMtWAvP4GSlANZsgiz7UluS3782M6o5FrcvmoxELeXy6gIgYUV2J5erl4Zkmmrpya8WfQUXmW9dy97Cj208LUBZQcScbFD9trn806d3yQT8HFvXdJOd4Us/jFIin9agmOrd6si1/oTgL6gr5oac5ad55jVgCc6aa51+YbdwjIugsgs/OX0oskC33ozuRXsrnVCdXNskjx1j4AeX+uONyteFnX3/FzfULvPf84rtfE48Dw+FIOsG+NIxEFxnHI6vefCnWq46u8wSvXF6sePXymqvrLZvVihD+X/LeJNaWZFnT+szdo1nNbk6TefNm3VvviXqIRohpTZEQQoWQ3qiQGAFCqgnMqRnTmiIhIdUAQU1oxAQGzJAQE5pBPSEVAyQQqOrWuzfzZp485+y9mohwd2Ng7hGx1t7nZPPylY4unkqtfVYTK1aEu7nZb7/95mZXFG/1FOKdCdcWN1jzsqupVNxiEauRutqvd7ySP5YqmUft2GUutlbwT8z1d97jQyCOaQY4AduNc+nMNU1Qla7KdfPealdSniyMc6a14dUTt1uSZm5v95yGM/lUANIUmcZoJfqn0yVzNRsW0a7iduccfd8TNaP5xHGMRgbLlTAXSdMSyx8PA22w+N6MiwcRklhNSZ0f81xYebbz48pKO+Kz2ZA1znHtLVfMpaZM11SCy89dnoeqzlXB18eeOTA/w/gkjIVFtz/+B4mWwt2Csi8LXy8urrHAL1fp0gKgqCbndarKU2tNKgHLGH7lJiyRygz0hcYmahon2t0Ndze33N/eGcYhjiDGp5yusCYR24Vr7O7cGreBUNSlGm86lxazL+I14nwpiV9CBVfi+GXCWHWpkdGKi3q1cy07W+056lcFZyU1fDX5q1KVeIOLq5KWU5jbrmUtehdF3xITrolTXqjWpJlEFRy0jWfT93N3NDClrhFr/jxN03zu1rAoz5tNNQSVtDansQsBDy1EtAxOVptG1c9wJYwVqzqu9wEqVnspnDs/zpOx3NdVKvOj+NnVsBCtgJNlkqku2U9x61BvOWbVeF3OzT7s3M+n9v1JGIsP5ay/b1xfhDw3y70+3gL1qerKUJRXtRiFQphRmaPsEo1fuqL10WL4fEGIyTHRti33t3fc395yPp9nJSjgiUJ80zTknOn6liY08zlWZanWB9o24ENdHMsCoO4czrIO1qO0LPTiRbjS4k/EMg+i3vq3Xly34miowzqmVY/Czx5GQsnzgi+fQ0hqoRq+tA6o1yc6lAhNwBWRGjDtiVj5JynOVOg51Vp+0wziOk8yqiwiUlLQsWSZpBiC0jtEIcdEUvN0QghzSLL2BKoS+cV9cA3OaREmto5kJmyZloxOPU6dSyVzxdposADA9vf88WKQL6bljDDPRkmv5lf9rkqzz89gEarzcdZPmxfNR/Uzfsz4NIyFPuVC/JCxxMOLNZ1d5NmzkHkizZ+rIYtK8ShYBfXVo1jlzWck+lLU1zmHK6BTniI5WMHXtjcVq/vbWx7fP3B/c8vpdKJvO7IOMC3nUs+z3+ysYXAcoQB2m82GzXbJfMwVmSUjMOfsRWahmutsgBNXTOUKV9A6aZMJ2ZTiL5fDqsBWzEBkq00w7+Qpl8XCj6J0tcpAmGEyLCenpZ6kpmJretYVrGfe0ctx+75ns9kYRjGWdKJCzJbJCDE+deFVZhB57VWYK24TzXuoCsPXWQJVJceqheKp2c/ncQotGaJLQNOOUzYd/XBZ+vrc6+NFOKHLFmcGSi7TVysjU27pEzyjvh7jjw/xnxufhrHgw+7Zx4zHpbFYSq9xbt6lq7FYG4yaMgWHpmyxuKxcRtOixyNz8Zl9jkKAWXQWDFxzxBLrtiGw3W65v7UwhKy8fPmSYRjY79+gzvHdcfkN1X3ebrcEJxyPeW5xuN9v2e128y5buQPOOUJJm1JDgAomfujaqWVCLt3iPO9YAAGPaiKLI+dkeKez1Ke56eECoEzZznPmtNSdcg7Tys68GjV0cM4EfQFyNjxkncRqmmYGc+09y7nX8KV+dzUWroYYMZGDHayGdzkvFOkZA1idW8555s6klJEgBOfgioi2TqE5MfzI5t2lUM662HC+BVcbos01mY24wqwYp6rWunMuWahzdikgY30/awjowrwOqrei+uE19GPGJ2MsJBeLeB1CfDTcynWfQjXj1BBwjy7pNHnqCkpepRZL9WCd8NZwxjqe26IAkYCKxbmiKwZnjDhnC1i9sR5D03B3d0fTdWz3O4Zh4OWLPafjlvvbnqzj5S9II7UlX/CeJjiQhk3bsWk31nJvs2G721kf1FLQlZLSttUzyoRyrs6VBj21sEzBWHwguSlxcEHHneB0IWxVQpnTEso9SdHp7M1Y4sRIWoecCLJUpuaymOfb54ymtZCrPG3bc5pi8ZJa3BStXeGUkNhw7zY8uJ5daDmokMaIEyWguJyI0wTqmFIhWomQJJOChY9ZcpH/83gCIZSMkSrOGTEvxWVyDXHAU/qX5gQRIovDuQYb1+HMc7v5erHa/FsqQS83v+rt1TDC8B2bwRUTq17gyhixOrHyfbU4UpM+2TCea234U8YnYyzgMq78IWPt4l0gyzBP6mt3D0BYLL+UXH01AOYuOwRTj55jwYJlrI81eyxZCd5wgtZ79vs9N7vdTDAKg4UUL1+9MFzlN8tvcCJkTUzjiLQtkk3ZumJ7cz+MEMwLKgpS62tloe6Cy1xO3qeJVHttATkvcZjioq8+JyJkLFux/neuYZ/l9ZbzWV2nlNKsnFUlBapX5lKoqDS4S4JW5Z90RUt0EJmbBBsfxfgaKeW53+k6JTyHJsXV+ZD7X0fFVFhf17Ljf2hOPhdeLKMqh1G+/9kjlOfX7zMw/anK7kqkCai7nW2wC662Dp8rRvJT8MDnxidhLISPU2c/PNzVxRbsJjnTabwyPvXmejW9C6uBuJw03vuigu3n/hUV1PMF/U+kIuVWCD5lY4jjyObuBa9fvmK/3ZXaDFtENzc3/PrXvzZm4D9Yvi/GsbiOSuOEsO1oQ8N+v+P2bs/LV/dmyArHIDSNNdJZK0f5Zs6kADMGAYv77iXMQJftiGFODc87Jd7cWUqPEJyxVlWQBMkl/CQzdqFqxXZN081Gwyl41xBdRFOGZHT+rEpORWIvl3i/eCfeOTR4GrFUcNM0vMwwJeV4OnMYBk7jwDja3T0eB3I+IYSSRTOwt9+083XJKTMMJ5y01oqwitHk0pYwXeEVMZFF5z6wirUwvAYHn+XYyJpq/nS+fd9Yeyozr0MyzMzVAp7rqqht6UE2iw9d/1+Pvaa9/0XGJ2EskGW3ub4ZP3Rc7/bTNK16Vlxb1iXmAy7Sqrb41hCnw5W4vrI51/9bXG/p1Ay0bcu2tz4WaZwgW/4/pYR7fJrzNuS/YVvaDpKFprFdNYRgepQp4cXhQyFs+TBXtOIdzdwVfRGaXXCassuKziHU4g1YaFF/ty1g65cic0pIyK6AvslS3JIX0V+7mmsG4sI+zNGMqq8TWBYwUlXNZS6G1j4f5r4oXZdMEWy/Z9P1NK7hxGjtBqO1QBSXEPFETZeeoYhBt0lRN81CRLbLKpS+qU4ucyLzYq/g7MxiXebYNQbxXEiyno/fN5ZwRZ49/vp9lx+sSvMFp5JFA3XtyVhk/wcGcP7UsTYSsOyk9bm5b+ZFyLLKaqxSVfVRtIqkLHoCzhWWZ3Wly32Z6xKyfVfXtLShgZQNKFsZlhjHohG5jE3XsNl0c31JLr03vBQ+QrQdWlrF+0Djln4iUXVuiiNSCt20SP+khKrgVKmqTnkFZprWqJRrUftx1OtizWtcNRRqalLrbEUubr+lZv0MpKn3hTmpkAXvG0iFaSpLmrZ6g66g/g4x3ZiyC4YQ2HYbdrsd225rXlVVIi/X1hVgOudMckKbG2YcQHXOsq2zZeu5cj3qHEkpUcvQccu8WXCE+u8lbNEirjPPtedSnM+NK9BzPU8tvCyhsFvm3nL1dN7S5OI3rn+f8oGf+6PHp2Es9Omi//goaknlhtb05npnqccyF/yyYe8FAewZpFhEEJdmY2E75Qqj4PJ2iC76ln1Jc5LtvU0IbH0PmCFp2stLPhdNjSPJqfECQgJNqCamaSBrRMTovHN7QOdofenE5auXUCeqWsNztbRmKNciqZ2sOHAXu5hlfZyalJwAmoXoMpI9c61B7Zq+8iTWitv13HwBXFQsrMshzyHcXIOTM8blSCu6wSIoI2LhSN+W1LEPtCEgtfw/KUkMZ7BUqZKmiPiVS16PK8aH0NV6K47VTPmuZLecS6bFyyyAXOfSh8Zzry1dzp+GJs+FKst5VTOQZkMA1Zhceh3LZxNuVWV6baB+iqf+3PgkjIWyUF0/Pj7Mb0/oTP2+NhY4cCtKd7ryIi48kbrgUNa023q91y4jWush7LXg3AzKGZkJOh9obl5zPJ55+3Di9uHh4rzb4lEM48nwjeBQ9YhmUyhfue2kXBaIlWmHri3nStmbjYJNiksPUGnMEOQF9LPFat7DuvtarjgHOhOQtP4tQm0rIBXVlwUkXYO9dbdXtexJSgm9KowSMTwnC0bGgkKOK6laXdKsoWScgjN6eXCOqMlAVs0l3DBj5XD2XL2XxtCbDUUNe7xzBIFKQfAzDpTRrHM4FVcFJM+mPlev/dgQZD0ujMYz7Svs0OvjV0xjKVEwcJ4nxuhaaPqnjk/CWAAzSLjm169vQI2p16+tn5gr8vTpZ2ENgV5ZXbu6dryy8FRyYT0uJ1ONWc5LMVPbtnhxjKfzXKq+7TdsNht22+3M0c3bht3uht/89vc07hJsUtUimpPILtF0G+5ubnl5f8d2u10yH1kZ4zhneWYasy7lzUmN9hzPxvnYtBsUK1KLUwmpsrK7vbGGPVnwoZCWwBS4Rc0zcB6nMmcw1oI+FfNZwqs4/9bJ5cXDEMc4jRdGeB3jV0RWi+p21jz38wBKYZ3j/sUtL9/dz8xNTRFfcJVKGssK05QIQc0rWHmSS7VmvehPwfQ5/CjX1gyPv5hD15vZc8Zh7d0t3sB1qPw8LlHxpgsB6fL4nMr9RYYnr49x+bv+oLIh1VUz0IuLtNDa1bq+cc8Z8LpTOj5wgYSFvi2gs7VevUVlluKTq52lnpMRfYzU1Jc6hjyanH3XmO6EUyArQzPNJey77f7idIbTiZwjwQv9dsOLu1u+/PxzPv/8Na92G0SEb7/+iun2xP39/czcHIYBlxOhaVBxTKOpTp3HkdPDI999966kLe3aNs7jvVWzvnr1aiZ8abDWiCklWh/oNhYyxZiIOeEkENpmrgNRVSgGM4SAeDNAORWj5gFx+LBUgKpi7RdW43pSV0WzXP5TB+KNybnf79nvtxwOHVngZtMzpcwwKTqM5Ij1MI0RVW/VsPXwWnqXyHKPK5a1zipLMci5djhTo89/TApiZlheP6eX+rAXGMTaM+XKC6D4DlVVHaGqwa43OQuFzQtaFTJ8+ER/pvGJGItl2MVc/rbxfIjyMVGPJ/mPC9dsfZNzqSlZGaK5Q3ia06cOQBfsQ0TmfhN9qftQoWgx2G7dOG/sTmefjdGk4K6HQwjO03pTwNrtdtzu99ze7BARTieTndtsNrNnU3ur1hkfY+Q0DJzPZw6nI9++ecPxcCDFTPCetukX5WwgZqus3aD4qhTuHefz2cIFX/gdvsUFb8BsFlJOiyixlIK1fIkXzVkiZa7lqKzLlNITaXxximZIqzCzHq9tGzZFQavrOo7DmbZrCEkQJuKUSvtH0Ggok9Hy7X4mKotxFYbUMOojC2zetX/IGrzAE8tOvtpkZPWoLLjX+rfW19f8lsJoW6je83HMiLAKrT+0N/6c45MxFhc4Q74MR56+72PKDfUleVIwthykhAf186uYzrIKgqhVSpLTjP5XJK5iI7nMvqgZl5Subfniiy/oum5eNHUHrgv88fHx8lQUEJkb7vR9z7Yvili9SeNv3m+Yponz+czpdLAq1KYhFb2FMU4cTieOx2PRtLSsyzhNTFMs4UCR+XMe3wTGODFMI/f3t9ze3rLZbQ1oJpEUvCZUfSGBFT+fmmUwgDJnE4OVXLMazEai3svaNyMXI4EucXYuTFtdXfssoE7I2UhxtQXCbr+l61sOw5HGOwgBxTFMhecSk9HFUy4p1dK5PsOih2n/LzKDH5hfylxr8VPi/csMzNOsyMcAzw8d7wlomf36DRjfdG2W6ms/+vQ/OD4ZY1HHclH0YhdfXlvfvA/fSBE3V49ej1zTpag5ec9gG1AMhrOFYmnsYtDc5XnFGNExcrvf8+WXX9K2rT1HQn1GeqFt+7nL93rURsW7fsPtzQ33N7dsNhu6xghGjQ/c391xOBzQnHl8fKRte25f3EOG49mMxMPhwOFgfTCGaaTd9Khz5Mk6glu60XptvHv3jvP5zOPxwGk4owKhbSx82mxQXao7Y4xolhmnqUbCeqlGC/vSImQ8X0etFbCXi2d9n0VMFm/uwDdvxktja+ehbQP7/d46tL19W4xvQ87QeMfoHCLJKtALeczkBl3xZBaAs363E4e/2iR+rvHcb73GNT4Gll4ebMmqPD1+zdb8E3Ar+MSMxcUNk+W5D97HQob6qd+T0eJVuJnWW18R0bkcGFdvyApsLSreAkVERdntdrx8+RIy1kwIIbkI25auc2y3RgFfjwoGbjZWqfry5UtudntruOPt9tzdWavC49GaFD0+PhK6lqzC+8cHHh4eOI9F5zNacdd2v6NtO8MtsoGQ42hg4+l04nA68nB45Hw+k3PkNA589uIFtzd3c8MfcLNWRErpglOSSWiymplUirBQV/ojV13MjJYUsBn2cl2rSHJt1FM4CrlkoGbAtpjuEALbrdXImOAPOG/d1WvVqhRMwnABE0DOYvUfemEUrH6oyvDVURfdNeD4Qe/04zNsxsWWWbN+dXly/r55j1yKHC9GwSnWn1nCGbFQ+jnP4md0LT4hY/FUYwCW2PJDln9uRXr9fLmgidqZfHVMp+ZdVHdZst0IMZd4FrdxghQhlPmmFIQ+abKu3yLEcaLvOlOm3mw4H46G6Bfp+DiOVm6+2bDdbp/8PlFLhe73e25ubthsNhehy83NDU1jbe1OpaHv4+Mj4gKPj48cDotc3zr0cWWxo45Q2vmllDgcDgwF35hSIkvmOJx5+O477m7vubu748WLVwV/KWK6K4KZQhG1MUMiadXLpZTPAwunQlcp29VinFWc1p6dMDM9K81ZSpjWdc3ccX3NIJ2vY2EmzFkHtTDHXufie5/jItTYv3I06nF/7HjqDX94XHsd9px/8lztFrc8/0/Gm1iP7zUWIvKfAv868LWq/gvluZfAfwX8MfD/Av+Gqn4ndmX+I+BfA47Av62qf//7T0NRTJ/AlYa4ywnU1+sNWEIRpSkYw2LF5y5O5ZqaPuXKBVQgh0u7bbOftXy76qVLrUD2Ct6jPuDFkxN4H2gd7Not+36PxIzTzM2uh5zQNOFcwzic2HUd+93m4pdbuCE0wdF5IbiMk4kutKh4Nrst4h29XzIS337zHefzmRcvXuFVOB9POGfewKbb4EPHOEQk2GfGKYH3tPsN4zgRhkR0Z/M2suPbt0feHybavmO3ecf9/T1/9CvlxYtEEwJdaJhSxInxR5IT8yLEEbPiou3q2RvW5KKiJFxSk9yPRQagZIdc4YNIApVk9PLkluyUZlxONN4zpsh4OBBy5rbf0ok3mf7iuTStEJLAyUJFq0A2UR4VE/y1itcyH+q8EMX55R7HkPGd1QORBC9L0dz3jXVK+LmQ60lq9clC16u/8vzXbHjKRnbhkVwZj+tMy3Pf/xcZP8Sz+M+A/xj4e6vn/jbwP6jq3xGRv13+/R8AfwP4p8v/fx34T8rjR0dN7dWL5HFFPux6KOsLm0mg5im4K4NbY2VYHLrlog3Pn8jVV84TZX4ocWYeS12D+b7KhA/KZtfPhNBNv2XTd+SceZcPtL6l7zZ8+YsvL75jv9kSGsfrFy949eoVNzc72lJ5Sc4GSBbef9d13NzcMI0GlE7TxH6/h1Lw5b1J8J3OEylaUVTb9qaV6T3eW1e0zz//3IDQ45Fz8TJijDw8PPDVb3/HOI787+2fcXd3xy8+/5zPXr7iiy++4PXLV4SCXXi3FLNNaZjrVKJaQVaDGZbTOJCKDF7wHpVmNr6VjGeyAOa4m2aom4v1AELrkejY7TZ88cXnfPf/vCfliPN2sZ2DthXGUXHB4ZtARphSZIqRnK1e05f3ChmPt1oc60DBtjOjnXM2HQtvSmEf6ixfjcKcVZnX/zMVputMhiyA6/Lk+vX6fTq/v87FS6NTDUl5nL2lZ93sp8/9hPG9xkJV/ycR+eOrp/8U+JfK3/858D9ixuJPgb+n9qv+FxG5F5Ffqupvv+97nCwxoylK19RV9TIuRVvKizMhZZ2ys9eACpDqOr67JMV8bOeQKyadr0icGhdAxJkGgqh12SqNb4bR8IommDx/53urFi0pzMvvMPJS13X0bbc0PM7WRYuc0CglFSu4fkO6mWa3fixhiQt+DgPapoetI3QtXbcp8f1Ssj9ttpw3Z06bLcfNhtPpRIqRIUVELaZPKfH48IATYTydDe9Imb7rTMWr7eZrl8hkUVz1/pwU/KF4fMGbBumK6q2qJFl4MYt4iyOuUoKLzuZEaBy3+y1t2zLlxEZ6pjGSojK1ip8Gu+eZWWrPXELbMETKtMiWbltXHHuHoaNa2aR5XnfrKbLMwZodmu/kxeuX82q9WD+woOdxGSJ9KKRZexHmeawNzPX7PvJ1P2L8VMziF9UAqOpvReTz8vxfAf7R6n2/Kc991FgIrIAknQ21UEuL60XIC56giner4h0u3bvlQlJCGGaj4f33/+znUl0+Hy0lR0QQWyBezZ1W5TyeGOLAOI64JATXsO2VsCsd0dU9sfK1U/im72m7YJTvep5SOpYbCdpwjM527CZ0DDFxHs1LqpTogtdaDxMfnuh1Vixkpk87oW0apmmiGQbyFNn1GysrT4lpmnjz5g2Hw4EcE7cFU7nb39j5r8hHzpnKeL32F7ob3gRxcy0RnxeBNZw2CqkZmiqEVDtpORRRlkfuPwAAIABJREFUA0f7vmW77RnHiHaemDJTykxZCSESsexUQgup1G583cwVrAhNJmCRz3dqWiEOXWUg8jPLetnxLxfhpSdwDaquw4WPL1598vj8+y/fJ2sj9TN5Etfj5wY4n/tZz565iPwt4G8BhLASWpkfS+pshq2wKsOZwFKUq1aGwoxFsczKU4ad1EzG+jye0q/r58t5zn+7ej7Fa3HOQFBL9SXGcZgbBY3pzMlbKz/XeaYccbrItNXRN1bSfrPbs2k7E70p5+B9xWfc7EV57+nbjrGJuNI1a9tNNH2H86Hszp6pLMSUEjkpIVjBmaizJkUlvPECjfNMYbLmPKqzAM04jpwPRw6HA8fjka+//ppxGLi9vSWUQq+u69Bs2aAlMyFzCX09Z1+qUctFJukigyxSi7YCImn2gNY7pzgI3tF3Lfvdhgc9gmvZ7jLncWKM4NyIS8pUNEZqjL+urFUtiZtn0pu2kOs52nVPT/p//DAM4NobWf79PbyKq8LGtVfx3PfO18g9BXJ/7vFTjcVXNbwQkV8CX5fnfwP8evW+XwF//twBVPXvAn8XYNM3dl8vwB+ZmZR+teiXzIfDSZyNhCOU3V6eXNjl5lSUa30ml7X+cuUmqi6fV2msIAqILs87YRaYknUcS7kUcTkHKTOczkTNDHGy3foqXG3blu2mY7/f0vc93pnhCc68hUqGQpQUoylrZaXvOtQHmqab8QJfPIlxskrOGEfyaHU3TdPQ91uaBrzvaLzgu47ghK4xvY3jNKA507btnDmJ+xsOhwOHw4FxHDkej2awmnYmnwUU8R7nzPALJhI7DaOlgItgz5rQ5ZwrxWxlkZaFWu9vkBIkqOKKQetCg3Y9u92Ox8cjaKJvrSlRGKaSdl274DJnR2ppvNMS+ujTjMgFUJmvjMfV++DSaDwffizv/9jrF+/Lz7/+fUCrX7EYPxTG/EXHTzUW/x3wbwF/pzz+t6vn/30R+S8xYPPdD8Er4NKCwuXFr2BlZTvW15+kzqSI7D77DauWbu6yecf1xX2u0MhebFBf4vHasITKD9CiepbxInRtg/eOlCLffXfgfD7ju5581TjEie3ktYEQqvhVyFB/U6VOi1gnrZQyaUqMKXI8HpmmiSzQdT1SuoinpJyHiRgTwbf0/dk6nfW9hSOOGSdwztHmhMeqQYMPhK7H7W/Y7/e8ffuWr3/31cwkPR6P9EXkZ993eKDxnlD1NtVo4U2hsdt5JzPNpZ/I7EFkWJenwyq9WaTxvDia4NA20LeNhSiiONfOHeJTMuk575x9RVrdJ1c9xMuQZ33fn1tT12n5izm3KmF/6lNfCR098TSe+bIrb/jCwKxfU33y93Nh84f+/VPHD0md/hcYmPlaRH4D/IeYkfivReTfBf4h8DfL2/97LG36f2Gp03/nh57IWrHJxgIwzVmN4Od4XlWtOtQtYQe1v8WKE7Acc/k7yzT/vc6pgysyapcal3Ysh2hDRkkp4nxTnIdMCI4uNIgm+iYQ2kCDY9O0TMNIOia+/vprvvjyV09qQ3JM7LY9bWsNi33waCouvJr4bZSqqWHVkCG04BJ5zNa5Xax+5Hw2L0YVmtCh4vCuoSm1K6fTiWkyWrSQC95gOJD3nqTJQpxpmq95KGrlKSUe3r030d2UGIaB0+lECIHbvrcmSIXBmaaJaRhmqnwoVZwxWhewGpq4ZJ3Ck1x1kGNJW4ozjYlpMlC38YG+7wvzVRinAR8cm66BbM0NxAc6H8ga54ZBIrV0XWiDwzXNZQjqrQm11vCotDm8zGR82Gt4ukCf7wRWQdvnPN+1avx1CnbtnazfUx/9M+BmeeLJOfzU8UOyIf/mB176l595rwL/3o89CRElhFICHmuLe5AgaExzJ66a0XBlJ4l5CTlmEZPitdeGNyKKbV1111ISq8a5skj6A8tEnXed6j6b+xp8wHvQHEsKLoEomyDc7nprPegD+97YmtN54r1muu2GlCeUS6Wsv/KrX/D555/Rdc1cQq1Fdfvt+/eYEnY7pz5bJ6gzL2tTpPgMyBQeHx/nBsvjMJAUEiODDITQ4kPLSGI8V2NQ6jZy6eCVE912Q06JYUpMw0TTtahC32/4/PNfmPFLCe+CxdcZFEdWYRwsI3Qex5ktuicxxoE0RYZhWCQCvfV4tX5kWnZ+47DklHFth/dGU9c4mmJVts5it/sbfvHZa949HImngcYHtluhaQUicyjqxZFdOb9swsGN93RNw7Zr2WyWedB23ryVMl20GC8v6wW7nrMy4xcVQK/PmxecP2gs1nhYnZMVBK6SAIvi9/q7Lz2hWZwXE4x+blTj9HOMT4PBqQo6YDhFKpa6dNVqpEjj6QxQ1nyY9/ViCwSLgXMqrfByLHZAgERNx5pru6QvnVv6NNTHi8o/lgyGhBFSRPKIQwnCrCjdiOI0opoIoSc7ISYlonTbDbe3+0Khvhy7nXVGr8bQcA8zKC5VkLP+jssdp0rzt21g13ekNOG9sOs7hjbxeDzx/t2R43kAZ5hFaDqmQk+vug1ajEUjmfZ8RoIZqJqOVV3Uth1SvBk3h4e1+CthTXrGmJiSeRCVOzHqxOH0SIyRrrGiuVR2fecbskY0W9cznDApRMWUq9TKpJIY2N00DfvNnsPjuXhFQu+tWncYM5NCVodLRQoRoSu/1dtUIXihCcvia5zhXTlbmfyk5qEG9xR8r3/XmVixlZqJsNcuF/vywWtPZHafAfCusDdnLPg6O8K8aVZjJfJhB8Le8wekwSkCm8Z+bRJQrZ2+oSu6ESldKhHlouUwDxWTXHNCckLWOKs6UXZR54zsFVfxsi8svkW7c91C4Ao/8cUrkIR3QiMGYmbN+CxMBTvQDYxT4jydTSeia7i7v+U8jHM6sI7tdktb6kWSWnVmTGZ0urCxXqY+sJ4RWSPBt9YyAAiN8TRuVIltV4C/qrlRgT7rUN61HW/efMc4jogIMS5aGze9p+t7k7HrO3xjgGkYG3a7HaIwFgKXOj/zSsR5sjduxjiNDONAjHb8x+EAA5wOB96+fcs0nOcsyrbrcU1g1gjNkSRKDp4owjla+JHGiVzqS3zJuPR9f6W8ZcV4yGiK4mt6umYazCMz7EPog7BplunvXalB9s4kCYuKmH+m9d/FQi+gbZ3HM+bClcf6ARxhnWK2I+Z54a9JV+vN7HrtiMhSt/OM1fiD6kjmBFpfysbnH12a6cTBcvMpzZLzZlkzmobSO8JUnpsCpHmnkMCTEZSkEdGi9ajCQrYSRAIVXDMfdK1aXWNne7fXwQBJMTEVycoUE3mISLclDlYivt3doS6RculFmia6rmMYR9r20ru4udmx3fVWr5IzSeO884Qi8Y9bskRZFU0JN0vFm7CvkhCnhMaVtKaj77fc3rxgjLbTinimBF///g2nODBOp7k4zXsP+458W3CQcUB8kQncFLXyKTINhrmE7aLbkRxoTAzTaOnjOKFqu/d3D+84PDzy9u0b3r9/z3A+z4vj9YuXVkka2pmjUVsajDlyjJHT8cQ4ndGYmPu/qmVsDKzNxKwM0bCknDOykhDMOZNVmZJpkoRWaV2gbRxrOVTNE+LMaHonVmzsBK7Zllwv2Nm3uOD6+NWavTYYF1kXVVJRCbPFcBkyzPhcNRgXhqQaymWOrsOhZfwhhSFkNJ+pLr+INypSXb8o3pkRqLJyqkpMyeL7Ur3YzF6CQoq4wtIQEirJyE3i2PbTvCGE0p/UmIWyUt++lHYHaLJ5K03dN0TxXgmNsNs07LqWmCamojClPqAukNKAC9bu77qQ7Pb2lu12O3tLqmr07CD4tpmbIJnGxqJ1OcahnLedcxynWYyn9Z6m7XC+w/kW7zpUAlk9b96948WLF3jvLR06RM66LOBpmixdLeCyYxLBBW/SfONkLM6iXnV7e0vXdUyaicM4F6hpDY984PT+kW+++YY333zNw8MDw3AmTpZG/u7t25KmDbNhamumJgjTNJLGiSkO5DgVsDJzW4rbmqZhu3UMU2RMleOSZ4NvncwTa900lzMBaASa1RoKYtiTr5WwWPj0pEZILaxZdvqFEVwXrYG0z2Edy2cWyUbzemcNTf8czlGdlzUloBqecvwZB+HJvP0hJMQfMj4JY+GcY7fpi7Ws2Y16MVe9METMkNQQIjTzDfRiXoUW1iGbDi/gg4N8BvKsNxn9dytBWZ1DETMY7Xxe6+8SEbqxSMUpqwZCDjSgEnj58tXMT8jOFr9TywaISAlJLi/5ZrOhbVtyGoqHZAutaZbGx2kyI6WyNKFZaNDGbFwmHIzjwL7f2vO6KJQLnu12yxdffMFd0cjouo537zYgmU5M0cp5T1fL1KueR81g+MDNdsfNjaVUQwhM4himkYfDI6fTCVB829CnluF84jQcOZxPHM4nYpzmrmun04nH44EYjdUZQqDpSr8Ub5WmTbCMTdaEVqWt8WCAbOGPWL+gYT5HnMcqbRMhWYVxW+pMGm/Ubu/ArzALIwZazYsKBIUcZO7Hug4Dnv5/6TEYX+Sph7D+WwqoaUm8whVyroQh1yHFWkLysr9INRZp9jQuItZ5Y/05xidhLDY+88/fn0x1u9mSRIg4kgQSGBkKx/E8zSGHCDQum2fQrIqHpoloKXi8QB88u87jGXEkvEDiS8gRyHSNJVzJCYdlBnww/CO0ZoymZO5vowkDrdsCwLaI7xHXkXJLt7ml64XQ2Hw1gC6SshKCUaqvkeltH3CaGYrQTAieEFqa0NE3bSFyVcjMoYVMlCZH4z1pymhyBNcRI4zjGRpPmDLBWZPlnN/Rdlu6zQ190/DZL15bifrpxHbX8+67t6bpOTxwGge67Ya276xEX6xCVJPVTey2O272O3ZdRx9MBvCsE64JjK3j8d2Bdw8HM679juB74tjh5NbYrIzc3e3puob3jwN5GFBJVpsSM2400d1GYNNBasxz1BiJkxnU9+OZrm+IRNuXZcI1kSQT4syr6rXBT5l+iGhKeG3xLtJopuPEzide75aCwrv7R8QbWJqjWvGZgMtGCX/eSGTWG/2CNUCYlkVaSbvmUXBBzLsOcuK1ANZqFPz04n8Ri1zcyrO4/vzPYyo+EWNxd3/Pn/7Nf4UkwikJkyoPh4G37488HgfO48ThNPB4OM86lnHKTOPI+XRGj4prQtlli/6lD7Rdx+3tll9+fsN+27Dbdey3G/ZtW+jOCacjwSveJRyJrJHGO7LEhTegJXNQ1rnkBtQDAZENyIaUG45nB+3eZOtK+0TvA6hpSKS06FeuR9WorFWjtRvZXHUZwhKaaRHlkcxwHIi6yP6bgyGcHw7kU6YLHV3b0zYb8hR5GL8DFwih4ZQicRy53e+56Te8e/eOeFQ2qWd3s2ez2+GCL63/qnix0rcd+23PzX5L35vYb9d1uCZwm29nZaqvv33D7776hu3+ni503NzccXNzgxOl6xo7WfeesYQXqYRTw3AixkjbBU7DiXfvj4zDkTgOaDIhndYJ/a6361XwlJxLK0jfkaaRYTogCJ+93ht35OEbcspsN/DrX9/zJ3/yS/7qr1/x3/zPdg/+xr/612cdkJQSOVr4kqJ/1lCAbQTPGxEljJdAo6rO13Kt7XHhsQhEPvx9H3peRNBYz+n54wPwv33NX2R8EsbCBU+z30HMnN498HAaePvuwPvHE2/emZs6TplptNTiONoufD6Pc+4+ZQPmLLQwrkPXN7x923E87bi73fD65S2n2wnZbdj0JqbSOMvPBy94VZxvaANkTZbnL0xEdZlYSTxaQC0t3TqccBqUrJPpVwSFrBY/a0RT5HA42G/9QM5bxArFQuk5Uq6MtRz0Yn1IwcC7dTycF6BsdsOzkqeRKQnBBRqvOLGu72M8Q9cRR8tkdKHBFddcmgbfGOlpu93SdC2U1ohd1zGdBxzCrjR9bnxgKmlejYnhdOZwMLaqKW0rwzBxPo90oSmAZEvTdEDm1WevzcBTOBfJmirFGDk+vmNsPINXgodBII5nUlLG8YQPIEVJ3XqanCBlYh7QPEIlcHVbXr3ccfOFhzyw3wf+6K++5q/9tV/yy1/ezdfxj371elYIyyuGaYqXKev1/9WI1scLklR0z34uaX7yfP23OZDdjzIU61GNxIUS+8X4AzAWCjyOI8fTwD/++hu+/uYt794fOI+Zh8cTKgHBo9mRkjJNkTRlTufMOCqpAIPjmMgJnJsYfeY8JI6HM4fTe3bbhq/f7Li9u+H9rUnL39/e8Nl9XxrgCM4HXMjgFWLC+WxiPBkQy26IeCTnIpiqiLOSeic2weIQcS6b65kgZquaHKezgZdXxqLGuLUa1BVl6pQSAQ8ieKm3yRiPlaJd3++SlbjV44sa8SpNA4MKHm8kJ+dxTtFsWZOuqQxOKwpzdLi2mT2LpjMyWOVdjKFB1LqotbN3JgwoMY2cTiceHh44nU40TcOLF684nCZOxzPTGNli0v7ONyCZTbux723CHFvnQhL77tuvOR0fOT4GDo+WITk7hWkijVanIt7C0cqF8M4xDRYaBA/BTzRN4sV9yz/3xy9pPNzctHzxxS2//OKOu7slM3V/2+FKU2SyFuk9z5SeX6zA7Pmtd/g62tzMv+fCwKzSq88teJHNhYH40OOTz3r35PvWc8zG//qhJfiDxidhLMaY+Edff8vh8cQ//PPf8/U33/F4GMjqGCY1MMoLOUnJu5uY7GlKpEnJ2aGaiDFY1y4gigF/g8+cYub98cTb44n+zQNvd3tu91tevLjl/OvX3N903GxbthuhV0dDJqZEOzm8V2p9ZC6ZGbKSUzRuh4tAImfr93k+jyQ9mxydtHj14M/A85Nj9gicnw1J1eVMufZKsUlp5smAV4e3LMJq4jnfkrzSecfD9MCYYtmtJ1pvizI4IYrSNwHddIVWjvVbbTPtpmez3dL2LRKKcpQmKL1NQqlURdNMlpuGgfE8MJ7P9jiOuFJoFpodTTBD2XWVeu6IU6QJuRi9ZjF8xZZuuoaH99/xtl2AXhHBDycYLRsiWolQpftb1zJNZ3KGvoW+g75L3O0Df/JPfUbfeW5vOm5vWvY7T9su96PxybJqmqiqbEE82T2/UA2kXMYCLtqzTa7ex1XIcLFZPJNSva4pWR3/Q8bDJsdl1mb9uZ9rfBLG4ng882f/4P/mNIy8efPI4TQxjgklkJPDuYh3nhQzcUyMo3XRtpoCX1x+geyK4Vjt4Bma4IgRpqNyGAce30Pbnrn99sRxzNzftLy43XB32/LqfsN262h9yxQzPqVCwc2202NcDS0AhvWtVcZhQrJjOJ0ZhgOhdYTW4bwjlwKw65oAYMYqrvn+NjkEMkSNeDzZZcv6lNfJxjatXoadm5JxK5zD1J5SmkDAhwYXglWptn7uJCaAH3poPE3b4ptQ6mys2VDO2Xq1BlvY0zSRiZCVcTxbyrSc+zSODI9HxB95/Ytfzeli55xpfh4Oc53KMExI8LPkv/V+9aUmZW8uvVj2oO6aMRhnpOuMh3IezkzTxLZvS6hihuJmG7jZN9zdNbx63bHf9Gy3gcZH4EyMC/U+5YlcGjJpygRxTM7NihbPhwTLQlRqSULBuYq3+2ThX1W7XnMvNE/PEz9X1dCrJMnqDas+Je7qmM8Yn58yPg1jcR74P/7P3xBjZopq2Y/sqKLRhg0ke26CaRJSykSxPHpKmRxzSWXaIpuBKhFyMAFIFzPilEE8ekq8P57JvOF2Z0bi1f2Gh2Pk1f2G1y8bQjCXtupHdqmmtbLtagjiRpwEYnKI9KQ0MY6PNEnoVPBNJmJEJufcEwZnbQWg2SDttbHw4lDUWg2K4RbLDuzmYzpavGQmsboN1LHdWlrTSSClzJjNiIxpJDQeROn6lrCqjdnsWsZpsqKq4HC5iA/lxBQndm1L1wa8mJDx7AFNEY+y3254/fIlMStv3z0wRuXh3Tt805l3kJWUjWNxODzy1Vdfz0a06zr2t7fc39+z7Tucz1Y+HzpSf8O5PeFdmBdoxRecc6Q4Mp7ONN7RNMbHaVvYbITbvWO/D3S9o98KbSdoikzTCbdqBBRjxEko2QoTI7Zpk551/+1xMfCCtyI2KSpgaxnZK+Mwt4JcPfeE/s3lxvHcvy9G+S3r9C2ylOj/HOOTMBbjqPz5V2fb+ZwVVClF70DFZNgS5FSAmyTk7BhlNH2CbGXbo+YiHwfDFEFMVIVkhevKRCJzjBnRTBsmND/wftNwPAy8ezhyPE8MQ2S7+4wQ0+yW5qxoMRaNr3R0S+llPTDFwDgNhHbPeJx4OJx4PL1DvLUXrDesKl/X0TRNAWWNiFV3ghp/et+gOeEKXdsKvphVp6yobqk3yC5zypndzYa+6YuepdHPp5yICtHXBsdLi0GAJmakFVLOpdzbYvdcDVTxZrw3UDepkqeI88w8EhEzGsN5Yhje8+bNG16/+pz7e9MY/dWvv+TP/uzvk6aJ92/f8/79e47nE03ouL+/58XLO3a7HXe3OzYby7w0TUPb9oiYd6lOaDc99y9f473neDzy/v1bXNdYKOFg2zte3G25v9uy33qcy6Q0MU0JJRoBbmW4h7GGe3Y9hGzNo+Tp4p0fL4SM9OLRr4DnXOUfKanTtAIfnVwYC32STF3Gx0IKzZeiQev3/0EZC3BE3UIWYgrkBKqLsYgxkWLlVxhrUdUxaiqluQ41lUWcCqJLfwVxikwBr5SwJsGQCM6j2SNjy5iUb05n3v3+yPuvHvnqrmM6jtzsO7Z9oGkd3jtOzhryBjeiOs3FPM55kIZEILsDYRM4Pj7w29/9ntN55OXLf3HuMepce/HL+763Xc05mkJ7zjmTYqbJpsYVmr4IznTF2JjiVkZnafyUEuIMq2nbHu8bomYKY4mm8TS+w7cNGoygNQNiZfJ2TkmnEzlFpMjtdV07d+eSpLYrpzR3ZdOcOT4+8u7hLY/HA+fJKjc//+wFX375JeI6pslCreH4wDe/+3NaJ9zte77+3cQ0nBkOByZ3wpPIw4n3TcPhds9uv+HuZk/TBs5Hq1zVBC9efs7dzS193/P+/QOPx4PFgxppGthvHb/85Qs+e7nhs9db7m4853FgnM6A4RIi6QJsfngUZtaumtvv1BbIstiqSz/zQT88o/M1yEi5jlDLDaqBF5HZaGT5sLH42JA0PQlp6t9/UMZCEeJk3oGyigUL8SRlyEgp6rGGsFkVJ2Fmo0jRoKgtCTWbC2Y3rVyw7C2lhuA047KDWBORQlY4HRPCwO9++x3nuy03txtuthvaroEw0QZHDhbLK3FuWKMy4VyLIvgAmQOH4xsejyf2+3GmlT9XUFRl59aFUTZMBs85RxA/ewNiWVtrFVhgz5lhqQ4fAilGUqGAO+dwTcCHEltLY+nYWgxX+1TEMxRg2HmHD3Ihl299Tk2kNqvVpOSciePZrkfKjKcj5yniQ0O/zbx8dUMbdDZomiOvX9xyt9+gmnh1f8fj4yM15a1qlPPz6YDXSCDTNJ5hPKEp0Xih63p80zBME4fTEVVls9kwxCNd57m72/Pibsdua2GTw9LtNWvl1LyPNdY4Rj+zhh3ZuqmVEHQxDj984ZlD8vReL20RzehcewPrroTX42PfHXhqKOzfT8ldP3V8EsYChThpyblbA59stc2l3sGk61rfIpLJ5X8pQrS1aZBNZHu/wUHGScgx2U5BRrLOAkk5Z6aYkJKajFlImhhTZvPtiSk7puxJdPQZfJOIDfQ4UDHdBXTGEMQ5Uo6kpAzDiSmOpGmcX3+OY1HB2FnVm5UByW5G5WsdCFlLRmRF+7VuwLOXgXecHg9kbNJqMrXrFAcYR9y0yj7IoogespbO6B4XPK5UZaZ1Ok4t9ZpjtHqUKTKOZ1KaiGlkHM+czgNN2+ObjtPhkRgzNzc33N/d8Or+jqYNjONI1zgeXr+0JknRQszj4cThcODx4b0xzePEpBNxHHAofdfimx7xDbESuNqWRGZ6PLLtt9zd79nvd2w2nhAcion1mKixdQvTqOiq3YTpHluY6dRqO0QzWa9W7w9sgXfdyWI2BmITfln4ernA3U+rEFX/NPxYwpCfdMgn45MwFgvBpYi9psw4RmrrPArar2K8A5WMSsa7YGGG81Y7gIFTWqtHcy4AqAUqdTfOri4UR8RDgkktk6CaCB76YyY1CQ1K8pltVjqfGbuy++NNOctl053AMg8pwvE4cTxENDvadjtzKJ6LOVV1fr2OagjW3gZg/UrVXncS5utm52M8Ee/Fdug200hDDkuP01yxlyla3CxSDGqZWD4bSOjEuA/OMeXS/TxG8hQt9CrGYpoG4jjNzMthOJHiSBDou4bdpmN/s2M4nNE4EccTh0czasN4Yr9vadsb9ruOyhMZzhOHw4Hff1V5A2aUyJlNFwihp73ZIc7aMKoqoWvoXeb9Q6brm1lIyDkQzUzDSI4t2liomnOZJ6u+s2mGL0r2RcuVebLQ3PcYjHLMfC3hX3AOucQ+1vUcdiIfWykfHlqzWleG4uccn4SxWFI8lq2g9Mc0OfWMODHVa4kFJChEqKKgJd6hYjdfozNBWIoTqEZSIkthKjqy96Z94T0TkLIUuTi7pT4pzSEyuYlRzpxp2EZhHyb6tiouWePf4BzOwzSBc0pMwvt3Z46HieA39O2iu1AX9vVvr6nPtZu5ZgVaytA0OqqhCr5wLly+vIYuWB+SpiXjiiy+fXcW0wtNZe6GknGpqtwlD7xqWLN8fzUYqDV0qmGHeWcDwzAwDaZh0XVtUfdyxOFM04YSrkyM4cyma9hveiKm4NUFT0qFJi0g2sJnrzgPJ06nEzJmQGb9UDZbNEX6fiC0PS6O87XtOutWFmPE4YsEYEJ1Z9dgMj2QnC7d+hjz6jdnpAS01w2Blvt3xZB81oDohaG4eEUrlHnpWfhnSuKffvfTESU+ed8fKMDJEtNWklJxqWPMSCFlmTNN8RzU/pJaom5/Z0mzaIk4S//VXcIXVz06jzgPYulLXg7cAAAgAElEQVTVGe/IAIExT3z3eGbIlnKMOPZJUX9k6JrSa0NpfKYJ1qg3RtO6UNdyeBw5nxIiHV23XVzQZ4zFOhV6jbbPqUkrpyskKLE+GvUAV+k0EeE4ngtmMTCN46xDiXeMcZrj5uA8bTD1be9Avc6qT6zOod6XVFXIlFl2DiztmGOcz9d5+9z5dKJr91ZXExNRR8ZzRpPVwIR2MgXzcm9VBR8cTfB0bWOq3t4RU0PKGR8sJX7OmaZtuL295XQ68Hh4x+Pjo0kMFmXyS0Ng5QGkTHZuNhbrexFjnDELX1XPUKbrcGIVXzyvQFXuh16FF2VknoKOaz5E/onGIpOeGImfe3wSxkLEobS2cyIgHu8tlp8VkUJDnDLjNJErbz9MeBoUTxozOmU8jqbs1tX6D5IheKQJJOdwRGIc5qIn4zQUy+4F71uCBPIUOB0cmhKnw5mxPeHcidN5oms9bch0faDvW4JrTfMyTzxMkWNKVuLd9zgXcM5Uq67vY9NsitdhVG4Ttk2l6MzOLWVF1ErjRZ1l9MfJdDVrSbYIMSrDeSDmyMP7R4bB2JQxRlIpegLwBXBsGk/fd7PGZ9v4uYOZarRUawExVTMS7TpZqtURc4QMvbRMNEQdUOcINDR4Gt/SqOBipnXeOCjngXHIHB4fTbRnbkpbFhdGrtkEYdt0ID3qPFmV4/nE4+nM19/8Y969e4dz8O23v+ebb3/P6fDAP/vP/FVe3e252fd4lyycdQHXdZymdrWYyrRfZR6qkLKIXKik+njJi7mct88+Wx4WUtYFg1PEGjY/42ECs2jw+rn69+x98NRzeK5A8ecen4SxyKqMZXe60K9QS51WPoAt/iXWW/MR4NJizxWjJZYrAY31ai+7pXXdKmSp4npXTU5xgYydVzodOY8ebY7m8Xila4S2gc3Ulb6iAbwnp4nTOTJMGfEsmRjgOZCzhiE1ZZozxk5NihS156x59ipEDZMJPpBUidOESAJnrvc0TUzR2gPM/y7K2D6UGhBZyEaudDKza6WM04RLqRR25blSVkRMll9MBVtW5x5Km8YK0krJ7jQuWKFdSUVKMWo5F63RcWJMkUzGOeOctI15O6HrZw8hpsRQOC4eNUzj918xDANv375hPA80Lez21qm+aYrYjSbL3JQQ09bWU+8OFszi+qUcP7bTf8C9L3VCQBHQgWpEbO6uqNlX3+dWPIv1ucgqXKmtRerrWry9v+zxSRgLKClShUB1yRfmXIy2g9VJO3e48lxceDcveEfblN4Slg+hyr5nZO61uXz3YnDOOdNog5tM7wImavFWakaaxhD1thGa1shOwxRnRuEUHQ/HE2NMdASkqDrV81sDmfW5et7V1Z/l4PKiL1nFhsWX9oYU/CEnI/Ik2x2Pw9nUpYp2Rv1OIza19JsOVasXCU1Rp2q78n3luwtgWq9lvUZ1mAcA3jfAYiwab5wMFwKNt+da365AWisgyzmSfWRCYKAoi5lIUN8Y3XvTtKgq52lEYyTFEc2mTdp6x7brOR8fydFo7H0frNExRigTIuJMIl9VSNHCVjv/5XfUUZnf18ZC8kdW4Uc4EdZucTnYzAZQcOswRJkXv6paWFaPUT2Icr8FAb0MOWW1ef5lj0/CWNh1KxPbhdIdu5lrAVJKTOM474JL9kCXWBoKgFn4DB5kNtuXE35dviu1Wk9XvUKSwHlxHytDUcbJ6hYaR9c4uuiISRgmCCHStplxgsfjgEgDoUH9oub1Ic9i7SVVw2XnWN5b2g6KOGuBCMRkQjxZsxlAVYYcmVJknEasB4o1RA5l4XZdQ7/ZENNU5PcdKp6MszSiODMUqiUl7XDicaJMcWBRPS/Vr+W3NL6dsZeMWpWrCzQh0HfdDN7mkp0S71C81dqoI6QRHDS+McBVrPQ/akTjxDSeGYazpWjjSL9pef3ZS4bxyHl4IOfIzX5L1wQQExsSYpFZNEZqTOuuYE/5CNMHPIvnNDjX987G0/c4vWJmusWzUL3EVHQ1N+OKgl6w/Plz6/lS7sJynGeEhX/u8YkYi7qYlqa9ALnw7O1+mSqWbwKhTM6Ux3lhwXIhRYyfEVOViaNQo4tS+Kx4vdRF1PAGYErZiqiKUVl2fyXkTHvMpFaJGVKOTFFpm4YxWmHUGJ1VcTb9hWdRvaL1WFeaPld4tBSZ2cRXXWU2sul45Gw78DCYDqXGTNc1MxYhIrPn0zQeiZCSaUpUQ+pdQypCOoJN9gtSkVoYuGyR1YurHt3CmlU1CX6nrrQYsGsQdbJaFzGdVV+Iaim1pa7CzkajEomWDq81KGqErpwj5Mx209K1jq6keDfbhrZ1pnNRGlfPoGG2dorr+3BNkIvxw5mLq9k6/7V8/JmFqsWTqYYpr96bVlmvlccBluJfPAcummrNz5XPeFYen///ibGAZSGp81zSaFMB46w+wK90H6TyMLBwpN5sZXHltaQCLVZeuBxQL3Tpt+kWHMRJ5R+UQpzyd0zWFu/xnJiyY4t1LR9jZpgiTSNMU8L5Bt9tafoNuJaUaperK9ogNaZVYjZWqoq3NHA57zk1nKwhD4X3ICKcChYxTpHz+WyZDlU637DZWe/UttSH1DYIYC0HQmmxYN6UJ4TGQpto54GUbow4wOjaaJ3MhgmYO71iH2bIyRZ68HaeRIXG3uvFQ8E8IBO6hiY3dr/me5YMa0gGquZsyuwOY5x6J0xxMMmCHAnO2JheMkjCiSt3TFCsFkayMqYF4BV86Tmz3AeDJp668x9LO1689SokqT1L7T1LCLTc9w8cVBfPB6pnITOoX48pIsTympZ09l/2+GSMhQ9tqZJ0NktLvUKMlmMPoaVpmnkBOWc05UW49lIhaL17hOBm65yyNRw2w2GL2K3eG/NChrLwZDmWjiNJlWG0yk5nZh+fhZhMAyNnpWs8TejwoTPjUDzL51JplX+Ri7ezzrs7cTPnIRdPJyedVahOw4BifSHGOBE1lzCtpdv8f+y9S4wl3Xbn9Vt774jzyqys+qq+172+9rXNZyy3jWmEYQaWGIGQLCYIJqgFwgxACKkHdDMBybRgQDdqgdSSEYj2gJfEBCEkBEiIATQt6EHb7Re2ue77+F5VWZl5XhGxXwzW3hFxTmbV/V73UtftXUrlyVNx4pwTsffaa/3Xf/3XhsVSi7DGis+oLQOUWGRIORJixoeEcYl2sSTnUmqei0ByztoGsRiLqmFhxGh9CFnjP2ZpVgyxksFixBm9b86AnkSNdmMsuakGORYWqCcFSGEgRCVkpRBVuaxS64PXTuhRi9hyVo8j+F4/V2FpUuoz1LBMnpsZPdDJy5vKzc9Tna/ZsecL9Lw/bv17dsw8NZ5nBuFkPpQXqZelxXp6bfNoJPT/ps0N1DP6QY83wlhIKVFu2xZSpu/7sTFKs1ipZ9FqDr3m25umIUZbXMwwSuoBVPZjrdKEzDAMo95jiLqztssV64vVqJJdtTBjmkhRbnZDkoUcIoNPGLHQZfyQEJNorcHaRLNquHBrXLPUBsbhfsZmPkwpu7Z2Ul6yVuX1WuNwTVM0R8NEziJxHHq60iLQuobV5cVYsr12S1abtfJUkhoS0IXe971S0b1n8F1p1FxSqeuWx48fq4cQtDBp1S5Yrzcs2pbU98rkTEGBv6yFZMHHQqoSvXZZazFi2LNoOljKaIDbRtswphyIWVEQEQFjkGRJcVCpgr5nGDoO3YFu6Ig5EMkqwrxoePHiOULAEnCt8OhigbMJcirp98JMNcpKGcIAxQuKhNJoalaiHh+6P6qZUu7UK72MBxd98SweUsYaj8+neAUw9iydzl2FX22lFp2/U/nvr6Y3yOvGm2EsAIyUjlyKXSyXmoarcbdrys0q/pYvvSeqoQhn+fARLMzqpk5otKZlxThcs2CzvsQYg/ceYSDFnqpJoGnPSddQonY4z1kIPmr3kIK4h0Z3p41paZvl2HvyBEx9hWcx4RgTTmCMoXUTwShk7XxWmYc5Z8SakkVwJ4VqYg0xBy3OKxjEyMIshWVt2yIm02U1pNEP5KHD2oblcqnVuQi50c9lxNIsVgQ7EENpexi8GosQtNnSiO9YYknniQjGqWchhXKvt9sRs1f2rEAumhkhhFFsp3p01loVEEI9ECuG3faW436HcZmmcaxWDSKa+Yoxj16nXmM79hAdwYHEiWcR4in4WcOKNHocaZw7dR7Nw4LzkeKJ2zE9EjDm1HiMrxFOwg0Ac25g5nNn/g4/eJrFm2Es6iWri6BtmrJLMuIVxqK1B1GVsoahx4+77RyE1EsYQlDXt3gZuRSmGbG4tmZUtNy7gobV+GiGJZeYeeIa2BjBaXNiKQQpsu6kZNXKtLZRcdpiMHJKYKZeH+fZkPrZa1w6Tw9jdCHV3zEnYjnGOKsVo1DidB0iisFomft0vhgjoaZTrYYATbkOKrDrOfYdu91Oa27KnfFeazVa1yBGRgk8Abx36m3kKpYM4hzG2lICD26xpF0tsQgxerSXXLnrImCkdKZPhJQIBZNRYDbTpIaUoxq/GEgxklKkP+xJYWC9WrFeNlyslzijuE7OmUyA5BDryDmhvXsKfyfVazUt1kr3rgCi7uipNBuY369Jd3PqK3M2nwuo+sr5nh/Kn5TPxLxHyHScSffxlPmI+dXv91WNN8JYwGy3LBMIKHF8LMQk3QF9DPR9Vyb45EY2TXPi7sVC865jvlM1pV4jZeHY9RhRjkLfKz9B89ea085R9R5S1FYB6spO70XRnkgmY5dal+GsZdnqbj8MgwKWr7iZFays4yTdVnGWGfdiRM1n9SZ5pp0wktGyqj1lkzE1Le1cOWcBfsWUlOqCptGuYPvdgZ1sp1299H7d7Xaa4bDComlpW0cq1znGPGZoGmtxtiWUDERNwWqatXBejKi3V/EnMhL0+4ZokRS1/sVAkxtCCthkyaUvqyn329glm82K1VqbNot4aruEev00VFIAu4KOIEW4ZmYsRk4LVMxAwe/7HsDkKdbQ5TSzcs7aPHltMdzzcXL/X7Hms0gBmB8e6e81YwGMYFQfelIKo94jkghhII7MQ4Nzp8BVXXiZ0zixegug+W41QnmseYBEDL60LlQ3utaqTICpoS1AnynBZhx8cbdVZ8EitIWg1LqmAFCFup3DGAbMRw0LamyqhCcLpSw/pcRQBGc0W6KLr5bu64KYkXREGEKPS81kUEpT6JElGksrQJIa1fK6RbukM93Y42TZLFm1KzarNYdDh++OimOsl9oFPXq6ruN4PNL5oaSnDSl7YswEn0o6NxYpkaRYqDUYazFNOV5Agn6XNrdEhDh0RDS0nHuMqh5mefLkCTAoGatFQ5ycMZKUQi7F60taT2R8TRPnoip1msKeU/H1vdJ47R6ap3pcJdPNCFjZUGwUzAwXVPzidN7XtL1+UdVZed36mJLdZ0N+8Ev5jTEWoUy0pm2K3P9AjGHCIkQpwbWWQLOhdlwA9WbFsqgqEagalpCVxWmS7rqmVrKWUZsTjexQMfgM2aTSKVNojPLyDUIMnhBiaZRcGgg3LRcXF1ys1lhrCWHQ+gf3sEQ7TOnbMXszNmO+797WrImIlMIofexsowg/KIYQI6nQp02eql0b05TrODFGlT6s+IfNwmq1YrvdEkMmiNLGndFr6YNXwR07hXqHw4GXt7dst3vtXG+tMjuNw5iGIQY6P2CisnLbbHBO8QvDxDMAlHxmVKgn9GpsKuhccaP6+K0nT8gMIAPG1v8valHVsJBVy0OKbAG5BPdGQ41Z1F/FksbNxugiDg+xNKtxPinom7ANoMgdTPc7FQrHvMhtzGZUgd2soeZnlMw4+0h/j9SGUHf5ksGASLAGSTIW+BirBKWUVeNg7pLXhTZnfOpp87hz6SIrF7ScyzlHuygp0ugxZurhIbngHmNa1WDyMKJKigmoPL5tG9ZLVaZ+dHGpncEzpDLRcQ8DVPWzj6lSc1JPqiF9qb0IvqaSp65myZdUqZ0aE01GKQLNicfljBkl/Fxxs2sKGiAG7S7WHQdN/eWszYyPXanmLLcLxSi6TjGO7XbLbrcjxAExhqZZsFhtWK3acUGEkkXJ2ZTmTZlklLiV4V63tvq5Q6gGI4/GMgye9WYF4jQzZQWYsI5qLKrnVdkVlX+h/2lOtvnKF8klNVxDlnxGYBDuY07VY5nf03koUg3FdPzssRbqnL6Gh8OR0bvivncRzjzWH8R4I4yFGEOzWGKahoAQJZEtpGwgmTEFGoaeEDI5O6xpFFB0NS2HqlwNgzagGRehIWWLbRqaomG5WqrydbNssM4wDB3dcCT5HqGAbKHX+NpqvlsETF6UTt0RZxuazYJ/+B/6s7z33nss2oYUBqxJNG6hwrLBcbG4Ug5ACIQ44OLpJa8CvsYYyGZ0e40xZSJpR3YrXsueY8BklRS82e25vdvivWex3nB1pWK360drQgwYPJvVikXWfirGGFLMtK0amCzMFmNkuVrpgpaGw+HA/rDldrvjcDgQY2S9XuNa7f3Z9z277YH9fk9KRxaLBavLKxbtikXTsFysWZVmRJIiKQxkH5DGaigVgUGFjGLyxOhJ0ROD9iZNPpODqPcUMrnvSYcd8Xhg6XokdojNrNqsKmASaAq1nqShnMlWwesAg2jdSu2bS2lcVUfMmnY1lfkp6g3E8LB0/8n8vffUBHDms3RnmnkV5YnxNSIC6eFFb7Kc4BLnRw00J3/XKmryq1O+n3e8GcZCtD2eiBSAcaI5L0vq1FpLz9QPREROjIW1QkhhNBLTBRIWzYrGLVRDwbUsF5uRq5EkkrMlJgPZEUfhU6V3a2igu0Ct3kxJm/G8//77/NIv/RIXFxds72558enHWJOKKxvHGhY/6K7pvadxp7c5lUrOXFKNo9tanp+POdnMWa2d2e/33N7e4twtfd/z5MkTEpHVUhd1LShzVhdpW65zSFMvk6nnCKVATPUmKs5iYPQi4FAEZQoWkRKrRcvFesPFxYWWuBuDs1O/1iCqWZpipM9xvD+uKLGH6BWPin7EdaZa4ek61R8jWTMuJhWSmQ6DkI0UoecCNCbFEFJOIFYFcUXrimI+Pb/eNxVCrgVe6p1M87Smg0/vC2dzbgI5P8s4wUHGz3RODish9XjomW9Rvb5yrjALi16XRfk84/saCxH5z4B/Gvgk5/zz5bl/B/iXgU/LYf9Wzvl/KP/3F4F/CTV+/3rO+X/8vu9RSFkhBIbuOFZIigjr5XLkUSwWuuCnSTOBXllmaVZjZjdLWCyXtK1Sn+cSdzmnMbevC3G6werOmoms5SNhCCXrknjy7Cm/+Iu/yM///D/Ah9/7Dh8fDmy3W772zlN0g/CEs5DIe09s7xsLaxmNRR0555HFWv+ui7v+qPhLx+FwYBg8vuuJg2f38hZzdYkTw4BiF8ulKoS3rRqZ2E99Ya0YxCg3IGcNhKwxLNsF5kJYtnpvrm9e0ncenzLStKwXpZbHxdEQj2Fg8pAzvvXkCBTyHKVeJ4Sg4ZrRQq+kfpxybQo2EXLSMvycCDno32REEmI0tZoKDmERktQ+sDORYVSfNZK0crmCnzJxPgBi1vL3SCF1UYDK71srcnbPxscTZ+b0mHHWj6+ZG6OaAhU5D0VKer3yVM4+1jkD9avyJubjs3gW/znwHwO/cfb8f5hz/g/mT4jIzwH/HPBngK8B/7OI/Ex+WFJoHEbKLl8W5rz4SYHCuph1gsBMRaq058uSWCzasWBqyjroZHdtW+oBNKRISSdsP+xLpiFQJdSsCIEJT8g542NArBqPzfqSn/zmT/MLv/ALPH78mN/57d9id3tH3/csl8sCzlYBm0BTUpajYtNszElb8/HQzlT5FxWnePJkSYzqsRz2HVdXVzx58gQjhWhVsIrFeqUdyJIlkmmMNiLOUQu0pFxvawxxSEQfCN4TY8BKMRrLFW3bcjho9zFN2ZbdVDTsy7GUh4tgnJCzxfte+45AMRIen/SeGVe9mlNwLuZE7wcG35deHyrio9fVYysmI1FfK5rZyTkphpkzZEtUkgqQSZEis69eRcozDKte71L3kjOlE9k5rvF672K+UMco4IF7+CqgO+c8VUoXoHV8XQ1TCo38VXDmPaJXZm6hvtT4vsYi5/y/icg3P+P5fgX4r3LOPfD/isgfAP8I8H+87kVqGAze6+NqNACOaYrhYyFhTeCmIv8+BEXijYzA5Um44gTJiRx156jI+kjCSqotKXUhJe1wVjEPbVxkMBgOxyMffPD38/M///P89E9/wDAM7HY7bQZslXUaCq5Rd+lyHR9Mnc7rWc49i4e8ihqiqYdjtSHPlWIFV4+ueHL1mCdXl/zd735bOR5GQ7vdbkfKmbZtudpcjJNyJLVplE8OkRwiyat2hCkcCecca1NaEyDFEBaeiNHFSFlEZhQanpXcQ9m38yjB5w6Hcq8oNR4ZH5NyafzA0PeE2BVMqcfHQMypVPRoWlONRlJPIaknWa+Z8inm9R2VfVkPMyfXW9kdmp4Gc8KxuG8cHiZJTYu1nvt8ocrJc1P4+arXz85S5rzul6f/f95vRMuMZHr8FYwvg1n8ayLyLwD/F/Dnc84vga8Df2N2zHfKc/eGiPwq8KsA7UIb79QwIqU07oxDntiZo54kpzfPGEPwaSRUVe+kvk6zGnG0yiJTQ5amsaQkJcMyLdKaz7emIRlwNmnvChF+7ud+jl/4hV/kvffe4/d/93fY7XZ0XcdmvcSgxk6rJO2JjH51r+djzuWYx77nP6OxyEzehTgu1xvilWdr9trR/HhELi/42jvvMiRV9T70Hbv9vuzOHiPC0i1wSPEuCqAqU5/YpilAIJX7odemdE9VDyILi0LlDoSSkjY4qwSvSrDLAqSs7MqC/vsY2B1VeUzFc/R4HwL9EOj7nq7vCKFj8ApA+xDIRFUgK97EvNrTQOG91B9lh+ZkiMhkJequP1tEKWtxljaNqAYHOHk8/jl6GOdjXPSvCF/On6+Gor5urEXJ6QSAnZuGfP7hx/POvJFiXbKAYF/T5+yzjy9qLP4a8GvlI/0a8JeBf5GHgrT7plWfzPnXgV8H2Fxc5JEL0DSlkKykHefptFmxjx47VZ3iGTMV1VOp1GQNa2YNfKrOQtOwaIrydGCkkuekN8qaphSZgUjAh8R6dcE3f+qn+bEf/waXl5fc3Nxwc3Oj2YSlYiLOWFIB905SaGnS3qjjlH9xygKc/67fu1ZMGmNYtAuWS9XwjF7BzuuuR7zn537hz7BYr+iD56MXnzL4CTzsug7TClkMJCk8EhA3FXzlnEeAc055b5pGsaVSxFZL30V0aku5H+eFTTEHJZWh8zySyd4jMdPkRBY3Fr6FFNl3R7ruSIgdIR7p/UCMA2JyEeqZQgdroCrBQ1USq0bXkIoB12ZKqewZFknnS0hxhgmruC9U9PpQpCzYB0KM+vr5b/2/dGIsqi9aKmnGzxDPXmfGz1uub6miPjl3MRRfFRX8CxmLnPPH9bGI/CfAf1/+/A7wjdmhPwZ87/uer3xJ5xzNRqm7oxufZwzMseTYluyJ/u1DT9dP+EVKadypnHMsl8sTcLBtl2RUUWkhWnUavScMA5K1hD3azDAEbm52mv1oW1x7wU/9zM/wj/3j/wRP33rKx59+xG//9u8yHDuePH7MxWrN0HdAonWOQCLHScNiNFan1/JED/T8/0AxFF+OM02jQG+74GK9wYhl1S5YuiWffvopdzc3PP/wY34rRZ48e8rVk8e8/fgtfuz9ryHOcnt7y4ff+S7HQ8fglb9gxaiBW6toz5SRscgM++j7nqEI7Mzp5s6omlYfPc6o1xAH9WrcYmqeVD0TKOh+gQSMwJAiKfhRZLgLnj4FXQ/OYqWBVMIOE0mSMQWz0AUXyTFibUs0mRwSMRlVyUpCKszKJFltilUR5DriuGAL56HUDM3m+b17dz8MmYOWr1b+Pg9D6mtz1iwP1K6rE1/k7GVTxrUaNFsKH2fnTVmL1tIDhu+LjC9kLETk/Zzzh+XPfwb4rfL4vwP+CxH5KyjA+QHwNz/jOXVBV6IQheZbjEWMccQsqjfhnCn8BSm6DWbG+JuyEClpPxJl6RnIDSllcgrE1o3vrzhAiWtxeH/UcChknG25evyEn/77foZnz55hGsvhcORwOIyp34olRG/pS1xurQU7EaYeqguoBqMai/kONGlyKEg6iuOWa1SVpBprudxsFJxdLtmX0Ojm5ob3vv413vv611g3C+zVY5IPbG+3dPuDlpL7QEyJm9tbYt5MGaOciVlFi4dhYL/f6/Ejo1K/03rRalVsSgwhkn1WrgqRhSwmIV8RZWmK4MSRg+pk1lAlCyUrogYnQ2mh6JDYIjGccQ10MyGrToemStPMq5jS0XUh5VysUzpNN1TylHolJfNA0cWgmIEznOJVUECmZFz4DFmJucGZPzwBOEt4OPca5iSwsYXl9H6pvMb7WLCXL0/a+iyp0/8S+GXgmYh8B/i3gV8WkX8QtXXfAv4VgJzz3xGR/wb4bSAA/+r3y4RAze2XBZInQ2ELil6zG8d0oKakUoLeD0p4mi3AkeVWjEpGMx21AYQSX6a4PEav8m9GaBYLXGkoHEOvDM9mSRd7Ykw8fftdfuInvsliuR51B6qnIiI4K6wXS3ypjiVlFm1LNIyAamWk1jGlcU8rFWvmo+IFozE9q5MgQQ668y/bhZZvh0Dc+jEsO15d0e8PJB+4vLzk6+9/jePlgbu7O+7udtzeat+NEODlzc1o+DJqoKsMQO8HzSJY3fOSV4D5OHhyjkU/UtPYoTREGrwno+QzAfJYC1OAZ1GRnWym3VJ3xUJBb7SXCDGQvNWMSwH5ctIu95K190vKEcmmpEr13kesGqEa1jEDCWa6lTV1SqnL0XtSVNQ4zYRM8+yhMERn9Pzx5xm1Vy95kvzX95szU/O9s1a8iPK5a2ltjBHbuK+khP2zZEP++Qee/k9fc/xfAv7S5/kQIp1ZB0cAACAASURBVAVQy5kUToG9CVmXsR9mXUSmtOpTZmLEl36pWgQ2e4OUC9W4utfaH7NpVEFKTKZtF7TtkkW7ZL8/8vx4hx9i2ckjxlneffdd3v/6N/Q9cxgrNk2KrNrFuCOrkdO8v9LN9X1DCAxyaiyqFzV9tin7IzlrVetYzDalcufYghLUDK11mAzHkhGKJQIejh23z6/VCL77Dk+fPWOz2ZRwboVxDuMcx6Pn+fNPOA59CY1mn7VmqPLUl7UK6wxFsQtJGCdj5kNK9kZmfVPVwOk9cq0W20nW14oIkYxPkWwE6xxNA2KCsnlBsx5ZS9rJCclBiUw5TCmD8yxGsQ2psM7GbubnSy6bcW2fwqanIYecGZDp/s0ff36coBqoOuLsPc2JITqtMj39bJaUarMuS9tafIj3UvZfZLwhDM7ZF5Y4koNijJhCzqrgI0zsztV6fZZqnS5gSnaGU0B15cSAMAM4l0pNXixWNM1ilK27ubnBh6SaF2JZry545733ee+99/TzBG1Q1LgF2Q1cXl5ipIjLoGFDOOs5oWzG+zwLmOoSTjIgZbc4B0bnBoJCMkomjyXfV1dXDL4fPYvD3Za+6wghsL/bKh9ksaJdLrh49IjVZsM777zD9z78lLvdrR53PNB1h/H9QunIntLkDXmvYOnKtSQyxoBbKJ8lFe3UbKHNDSLtieaIGqpSO1LqOmo/1phrqClaTCmqzRGJhJRoapiRtDE1xFk+tAKdk4Aw1GtaKfT3u9nnXB17M1u0ZpaSnIOU83CkuhrTedRY3QczP8t4UOymeDgpZ+3Ze5YlIxvEKYg/D3WtVXX23XaP9z+EMOSHM2SqxlM640kmoV64OXsRGFOl812k/tTdz5ipaEzMlHZcLBas2gWXl5eslhvImaHvud3uuL5+WUKGgDGRpl1ydXXF+++/z1vP3tb4PCSq4lQcSsZlNqG01H4KqeY3eD7UyFVMYsqOiMxEbCrYO8M3YtRqVinnb63gnfIlvGTW67UyXwev4jRdD8B+t+PTjz9hsVyxubxgc3lFu1zQLFqePHvKN7JnGAZubm44HHYMw8Bxt1cQuBR2jT1OSwOj5x9/wvF4JElitVrRLhuc0+rRp8/eGq+/oxkNRdM0NMuFpmFLtegoMVBCBOO0N4wS5s40O2q9d93d5TwLkQqoqQzQuojrqGDm9Lf2gLW5sELRTMtDmY3XGYDzOft9MYvzc1MzdlA3kZN0LareJTUUySBGmZ0qjqRcllqCfzgcCmj8J8izqAVVOEcwqVQpptG1N8awXq+BafENQ38Chlaqt3OOvj9Sy7GttZgxn+9K16qGxliWyyWNc2y3W148f8nt7Zab213R+1QxXBFhs9nw9tvvcnFxQQwJRLGU1WqF73RRLVpzgkGMuIOdYQxnIxb5Ov1Op+y+hyZlStpJvRoQayzG6YQyxhBNwB8H/V7W4a3ThZw0lLIIx+NRZfDIxCwsg9ZzLNcbvvmTPwk5c3d3R98f2e12fPrpp2p4MwxDKEJBPYe9Us0P252Cn3Eo2qYNtlWKedO2NG2LaxqapsUgI52/Er5MUi9qDOFm2SOMht8V+qqGAWOQPDVD4uxanfNU7pGcCi4y/3u+wOvpxurT+T154P2m8xRD9Aq5bbln1Kb3B134AJiJ7zFtlrWtROIE/jSGcCaBUNfI3d0d2+32T46xMGJ4vH5UhG4igx1KEx11BauXsGg3hU1Zd1g1KEMc6LoDPvSlICliC9FLROtLFo124F4sllxstE4ihswf//Efs73RC3o89qWc2ICJtAvFUR5dbfjmT36Dn/rx98m+Y9k+QlLL5mLFW2+9RRwONI3qWXTbHTYa2tBgbEuDY28s2h3NEs/k1g5lYSNWGyORiSFgROglF/3RFolKKnPW0hgLxmkvUin8RAsRT8gBt2wwrUWiei7r1SW1BLuWqIOQtp7bm0/4pChQSbvg2bNnLFetdofHYpoly2dvj95B33Vst1tub7aYwSPOsFoJrbtks9nw5NEVq4sNm82G5WZNs16qi1yzOsUYWITVUunVoddamsNxT7/fMvQ7Li8XrDZLIonb2x2fvNxyc/uSlBJPHy9YrBLWRlojNK6lEYP02jqAPKjuhlgyLSm1xKSeJRFyKTiccZ5IrgCto/sRgTgCnCdhR93hz4z/3NjkV6QqFRe9j3+M71qrVdMUPtXjZKbbkmUSgTbZ4KQtWEWVJITDoePjT67Z7Q6k+PnCoYfGG2EsaupRqb9qAaVoSYCZ+oTIFPMq0FlSSskRwkCu/S1IRYFKd/bLzYZF0xbNTfAh0Xee4/HI8+cvuL29xXfKz2gWpVFxzmOn7eVyyeXl5ejZ1G5o7WLB5dUjtjdLrNGQpw/aRUs9HIuR15cI19RuJTjV63E+VIrfjKQvM8+ilO3spHKyCMZa2yALi0gR9PF+pDEPMRBCGsv6/XaPHwbathbbFQ5IVKwo5czxeOTu7o7dbsfh0KkcQIZVu2Cz1F6j68WycEFalus1sbyfMdpWcgSoTcnWDD2744F9d+Q49PS959mzt1guFnT9nr733N1sefHimpgCJm/YeMtymaDJOFptfC0K8ElKJ+IzCno73a0L2JzNqbhQKn1DKkZRKdVJ4kl4W6/568IRnaN2vO/nYfKrlN7P18Sr3kPODJiGrFa5FklTytFHDn1Xrqk/ExD+YuONMRY1XGiaIpXHBBIpTmERUXXr2pPTNQWfMLqgXXBoybIai6YI/64XSwRGCbjj8aB6Ddsd2+1OSV9G8/l1YqWciGiOWoldK42xi+HyQTMqV48v+fSjhWo2kEupvGCaSXFLOFWnmo956fXJzpQzrmRDsPUaTRR2EZl4AbPJK6JpyD4NSuUuamJtZbJaQzcEfOwLq1FwTaO/bQYf6b2yMxOx1M8MZRH3dH1f9E/DCKRdXVzSNg0XFxesVysWbcvCNbNmyVMq2zpHW/RSw9Bz7Dr2uwPbO9XNCF7v22Kh5LDjsePm5o6bmztub3fkDNYkBm/YrC1hZSFZpM20GExOhKwamykBEVKUieRUVdDNaefxXBXKSiPuGg44O83P+cKt2NH879mMhlfgHfePPf1/k6b3OTcTZsZCzmgWT/kXppQqKNjpw1CM+o5hCAQfeSAC/tzjjTAWwJjaMUYnmCpi1R1JJ3zjFjPdzOk1kYxzJWuSIEbFSStott1uCd6Pik6Hw17LuruhyO/VANUQYsA5Q0XFBcHWJr+tVrV2fkBSYr1ec3V1VdKciRA8pnE0KJ+AXLn5p30vz8ercIrRCFAMZvGs1EhMClhSjq3CORWYq1XSVcjFGME1LdkHQlGeykYwjcMItChoPJSy/Rg9fdCqz94PbA97ff5sZ3y03qhHsV4X8d8GV3CKtm1JZpL2G1sqAjvv2R2P7I8HDl2vXd3aRkV2mhX7wy0vXt5y/eIld3c7jgctOLvbDngPfQ9haJBosKsG2zpyNqphkYSUhCEoMemYNPwyYaKozzGLbkiliVEROqrGwmhqv/J7Rm8ulU73o4GfjIC+Np5co/k9feg+P/T7/HWvOlfOGe9DyZxF+s6PoeLx2KsQU7L3zvl5xxthLGrhWAiBtl2WiaVIeAX/nG0xrVEh2LKrDX4/Mx4l3RryqFFR063dfkfwvjTY6UdKOEao/U9rOq3yNrTvRKklKAuzbVuwhmEYWLaG1cWGi0ePcG2DP6rK08Y5JS4ZQ5y9z6uMxSmodipGY1BG6wj8Fen5es1iUb8CIKYxa0Cobraqb+l/qxUV47Q83QiIwZb3zAL4knWIiRSiNhQKg5K+MkjSBcUsnZtzprGORdPSWDdRlEs6O5dQUDMbpVo2q6Hves/h2LPvAyFpQ6mLiwsuLzdghf3Rc3uz5257pOu10M8YGIbCm8ggOeAk4Ii00mhbBGlIkvAh0h0j+z6zD72yRWs4YfJIwwc47PtZtk29DyeGMPPY5pyYyZubCFp5JG5NhuV8oxizWieToPzOebxf8w2kcjjm/xQXKZ63VHBcyYrDEDjsO3a7A0MfsNYx52980fFGGIv5hazeQu3J4IpKthHtzA2TZ9FKq+m7odeioxDGblu73Q4ftM6gPxxVOLfcqFTUmE0pXjKjMnLNrDgy2qxHgpAiowZm/ZzGOIyzLNcbLq8e8aI/qkpT2f3bxYJBhKHritHJ1M5n8zHHLPS9J2NRr81YDIcphq3Qw31Q/MIYJGkneD3pnOxVxZBVv9L3XaHIV6UsSsiXsWPV7yQGZIuC+uA9OQZ8mgrLKNTp9XLFarGkbQqXwjmatoVm1vjIzPRJBjXchyFyGCL9EBDXcHlxyeXlJW3bst3dcnu35/Zuz+HoiVE7pKdsCLFUsOoHR2JP8o5WHI0TxGaGmDgcAte3ge0+sR2K9pbMRITctIBubvfl2utmYYs0gbH+JAyZG/waWs1DlPHcdvr7/s/pvJ/OKUiaewz1uMrq1PoWpHJy6u1Wwx9iousGtrsD2/2BYzeor5ngdX1MPut4I4yFc4633nqLruvwvqC5xo0WGygCsVv63vPy5Uuur6/ph51WUfqhaEGmMcU27riFQCsjTTyPKaiUJ6XvCqaCItLG2JI20xjWp0zXe5pFS7tYIVYIMXPx6BE/9uPfZOiOHO7AFK2FpmmU8+ADttEK1Ha5wLhTd7AbepqcsI0Dr266ccppkDxhGmJUHbsW03V9j0mZLEW0t/auSBkpximG0sZxsSyGNJTf/RimpL7yJXpyyKzaBdI6rBVMEEXRk2L72bWa0iaBmSp6aypa06YL1hcb7KIlGLBNA0bG8nSfIrv9juvraz69vSMMgeSWmkl59nYR2DnwW7/3h3zrW99SRunxSAiGyArJQj94BM9eoN3BtvE8Wh/I3rFaG3BwHHqudwMffdrxycvM0W/VG6FkPg3Tjg787b/zB1PPWyx29CbSyaKe/8wB6WowxlqextwzMpWXAxPfZ6T0j+8dxw1jAvZP378+rvPcOYfvBo7HPTc3N7y8eTG2czC2Yei1veSXXqdf+gxf0ahuVy19TlmLf9SABPb7PS+vb8f6iq7ryGjqtJJudBfWm6HgU9WxPFWjmkue5VHnshR7xYyMO7su0CEG/KAVrWSjhWHGkI3g2pb1xYblekN3PGJiBFNSZ6aU3M8Yf+ehyLxE/R5QWZzVlHNh9pUKwurKFhIOqEdtChXapNLasKm7+kRmG4FWBTr0WodICsqcTKVTuWpDRO3ZKVr56oxFbBq1KY3oDmwbd/KD1Wtka8WjVEOdRrEgrUVJuFYxjov1BtNoU6a7uzs++vATPvn4OS/vbk/i9UQi4vRK5EgQ8EDfJbb7jojFLQxdTAxB6KNiWHOaQRZUL2d2K4bieRgi4BUYzmf8Dk4X7HxO3fMezEQirGPOBZrfi/m5G/ewsTg3TvPnnHOkMJRru+V4UH3UnCj4W2mGfU/m9/ONN8JYeO/56KOP6Pue/V6LsHwhZR2P/bgb7nb7E4CzglBITS3qTRKRInhTG75UgksBAAVVgK43HaMLEFXXtrPnUmJslnPsB5QZJ+PObaxltblkffGIu5uXSpZJEw7StktM6sfveg5eTfJ797Mi9fgpfi2Lu4RRKas6lHJHBWyhgIN2KC80YUFDLucm0Hf8SbMUYwFDMTLNK9HrppPztCZFJ7yGa8ZppiUbIUop7LRCyAlT4uXee7Z3d2PhGk3LatGyXq9ZLtcQEzc3N3z88cd8/PHHXF9fc+g7nCu1QyWrkkTrZkQofAcYep0rxjpao7hRSpCyJeYwxvcVMNZ5MF3nqGJbxJHoeb6w8tnvCfKY39K5AVI8Y/63nPakrZvCDJ8w+BNDcO6xnP+M7FhJxOjHNHgM+vly2XS/ivFGGIu+7/mjP/oj1ZI8dOoWF4BSEd7p2Ao4jvRwyoSJ93dn3YznKaxiwbNhvOm1eChLKfiak2nUeFSgtO98aTqcyAFSGrAZFqsV64sNzmkXeBGIKZaGPA0GP55xZKqWMReXqXUg8zRrFayVSkGexbsicuJKa0EWGm9ji3aDkI3iETVtWHGheh1todjXc8ao23HFR5DSS9Po6qwpvDqZszUo5yeTcyrtB/V1KSVtcxgj+/2em5cv2e12RB9YbzZsVguWi4YUe27utnz04ff47ne+x257S8oBZ6brNH5Poxoc1gg2R0hKdQ4hE6PS7GuImZIKAdfQUxdvOqk4hbLxpBmeMAKN9yuap8k4wxc4xRkeHpkYIsY8nNnQNGj1ZLj325wB5fWxc47GTanUJIAtVTIxat+c132szzjeGGPx7W9/G5gorWlmbUdqc2Gm1fRWbWbLK1xDfaJiEWeS6CKaATEFyRbG48imFEwpuJRSpu819BGU+ZlFtSRbZ2nbls3mksVqrRkEk5BkyKLpU+fcPeLV+PHyVDRXb3wFOOP8/6yZzJgRpJDVkCIPn3ShZqARO4nMiFZ11grUXAvXoHRgt0jbkpwDa8kxEmMgJl8KtdRri6KZDZAiwz+5yql4FMmKOiUCtryfD4EhBo7HI9ubW+5ub4mDp7GOy9WCdesgBba3t3z80Ud899vf4cPvfY/+uKNxGurEoP1kQaUMDBoqNaJelUkZm0FSJodIDJDEQkrKaowULZOaWlbPSWaU7JQovXHvF5nN75W+/ovH/yknUlV8O2NSvO68Ou91w9DPMn8+sliU0ghXDYp6xX6IJ4D5lxlvhLHIWRe+7lSpVMtNKUJTUqhV/SqVSVAZmarrWBlvduZhzHYFlNmpxqWkJmcA6liVOuMAS+kdEkKZ7NsdMSZ16yzEUECrxYrles1qtWK/25aFrKsm5zT2z3ioNmTOSK2KWdW1rEIwIUWyV0zCGIOtrqm1ugBiTWMqKBqNMjarYdJwBUJO+CFos+fyUUSk0MctYh0xD3ipndFkDDWMs5iond2lZjlcaRhUStCdc8rZcKoiTlJ25uGg2hm72zv6rmPhlHTV2Ez0R2XSfvIxH3/4XZ5/8l1ur18Qw0DTWBU0yol6K4WMpKheBQmblU7VOGHpjOoMVZyhhBzj7owtRWLFaMx7J+ZSlVpCPVPmQXrtAn54g3qVsTkfo79bN7ucRw4LnHkXopIH9f3ymA1S7VAXwVqlz9eSiBpK6Vr4TB/pteONMBbWGi4uLgoAVtiBeQIl52rdwFjxOBqUWOO+6WKqu18MBFCrEyvgV0e17mPc+ABoVXt6brfa/SvRsrAtPkYwFicZ5xraZslt2aGapkVswg8Dzk3vce5ZzI0FnAr41lGfM6Lfqxo5Ed1ls9SmegqKeu8JXl3tXBq6ptm1GWPixEkHdkp5fVsMRyoKVPVz0hRtTVeaNmuzVayowbZtg2sbkiiPwofEvjtwt71jt9UyeSMyErhif2Rf1Lw+/vBDrj95TrfbkUPPqlEdECFhGkvjCgCbNBWci/6yMbBwjs3SsVk7bBtIRlW2xOgMsILiKTkXGvccE6oPZuDhCQbx6oX/Oibm5xnz483c2yhztupxMBqLs3Cn1DJhqteXyVFng3GZGBJfQeb0zTAWKWe64ag30xTG5Az8GZHwmdV1zhGqIEqqC0D/rBkQ/Vuw5pS3MArUikBltqXimhtLignXKjJvW1Xpur6+5vnHH7K7fcl7bz1RUFEactDfbbPmydN3+N63v4WxGZaqaxl6j8tGqxAdJ0Qg0L9jzjgEiZnQDcQsNFlwbkEsu7OCWYoh5JhZNI0Cl8aowRMgW1LIpNgTvIZMFZOoHldTsIZsDSFDSJlQCvKir4bWsGxaggSGkIgxFAKbKjEJWvMSM6SQCKuEWWT6NnIk40Ni6D0+Jra3O7pDR45wsdmwWTUs2wZjA9/9g9/n+Scfsb2+4bjbMhx2LELkaQN+AX2EIIAkQs70gxKynIBJuj4a41g3jqu14/GjhJiEF0s8QuwC0VcP8Yxqf+55jhYilwxZurd5/DDGPU9mNv9PkdTJkGnGaQHGgWkUvDKBFHukqSX/BvpT4aXPO94IY6E7vxk9gNGKjmGCjMfVG/jV4Lv3xznltk4yX+jilWlau5VFMs5aLi4u6C4udHFiFVCkeBK5yvine5+7GsBs8rhzKDCXxu87gl9zULe4liklxSyyIc87ijmHMVW5a+qDWXfXigHNAWHVJVUBGim4kYhmO1KMJ6CgaiboHIxZwyexhoTBB0/fe7pBmyfnnGlbx3q1pG0EH3r67YEXL15wd3fHUDYKJa1FUobGWbAJh6g8f8wkmzAtDJ5SVXqayjTGkI0rnsGUNVNdzYdChYfl/H8Ux3madu5pa7Nxy2H/J8BYVOLTKReiPj/HFQDmwqRf7E5nYXQ18/nZC+o/r39IKdJ1R25ubrSIKifsjGtvrWW9vuCiGovy+UJUJqQVSxZDEvNgw5dUFqhSqfWAkFQyLhLHwjqT8+heiyj4R1b2pjpRtZCsdBhzjqZZjABXZYtWjEPQrIk2IY+4jFbv5kwInpC0xSFStGaoknnF4AiIUSGWirnErGnm/eHA8dABhuVywapxLBpDDB031y+4fvmc588/od/vMCnjnGClxQAmBg1+SotCooK3rSl4dRHGMokCyAopFYavrcYva31ILKK9Y2HX1PbyR8VQzL3rOuZ/T4SuqS3nuAlknQfneh5fZLwhxgKqYTg3GDUFOk8XjRfvSygWT9kPNRhjLVlOWCmFbKLszhhzUcq+43DoRost2MKLMDhnlMloNWc1UdeVzZfLLn7uZv7Ff+8/+sLf4U9HGVu06+4ffbbDv7zA3Js4pj4pqhg0bbRGNHv2ZceXP8NXNbIZf2Tse1Uo19nc+10BqS/9tg/FM4YxzVbBRx8Du+2e7XZbdtE8Aq29116fi8WKRbsCUMKWcWN3eFdTjfLmXPI/HT864xw0Pd1UqwzlaYZHmIrizoH1LzLekJlbuRAqGlIfw1RNVx/Pn/+iQyVdzdiRuvasqD/1mJFhJ5qWPB6P3N7cjWlaUD6GCuNqpmKxXhFjHsWFndMY2qAGwxjDb/yVf/cLf/Y/HV/9kB8RAz5nep7/HeOkW8sDRuLzZmgeGm9MGDLPWZ9fkIeO+XJjloY9B5pF294rH0MrEUABpOPxyPX1NZUl56q+RFRi2cI5rq6ecPviOcMQaXLDXOXZYsAogPnX//KvqQZmVDn9/fFY+m6gmhhNQ7NQzKFpmrGXaxXMXTYLHq0ucaYZpfZsqZ61iZER6ooIjTHqjg6DFhzlHLU4LFeBm0Dqo9Laj3t8GFSSPxcqOsoEnIdssRjNYw4McRg/v9aFaKHZ7fUtL6+fc/P8Y25vXjB0O6zJNK3lsoFGtD+GTQmT8hhahgKoZiNjLD5NipYYE/0Q6PwAkmlbw5O3V7jWYtySgxeeX/d8+OmBm23gZThNG1fq+I/imIPv9W81FA3Kjambq5twqj8pqdM8lzMrlOKRa1DAQq1vMKcU589wr8/Tr/Wc9fFYMyDTZIo54KzFuQY/dFgDbWM5HA783u/9Hl1/ZL15i9APLJZL/KCtAJfLlp/64AMg8dH3vkN/PLA7dlwt25GhSdIQx4rgxBCLwfExIjGMnb2OfcfRZxaLgcuLK4wztNJqqXnQStsw3LBerFk0LYM4rNVeJktxmgJOaVbyr02QB9+Tg7L6rBNyttOEMgoMtm0LkslDJqaIWKvl8AtNI2cMPgb2exUqvstaz9AuG8RZ/HEghAN3dzv+8Pf/H7Yvr0mxp7XgbMRYQ/KZaDK2CNPagv3U+2RzBlOTYrGUjLsS0kWyWEJ0Km6TYkE7B8gNpIF1u+TttzYcu0B3GGhxY7uILDJ2XDdG6fvjfJktKlMA3R/ueMjLedWnmG2qGMXZyOSkHq+uoaqp8eU/2RthLOA+4jsHO88Lq76yIXZKx1JRZai075yrBoai6F1/5HDcj3UK2UxZgKZ1hBRZX17w9Nk77Pf70smrLx28tLqzvo8kpf5aY0rtgsGUzAYouzTmoGI+3mtWwyiQGjP40imsNi1yJuJoVQaQade0aSamElUwRzMEgVRSqN5rRW0uxXvza17l/60tWhRFfKgf+oLXeLIVTFEX84OGa/vjgZvr27HDvKC1MgJYSUg25BRIWEyapWKL0Y6Fvi0y59AUtSspdRBkXGYkjkkM2GxRemrGmsyqFZYLyLswpr5MHjmcr5hPP1oeh8gpcXEqSoSaPZSv4Cu9QcZCJfE1ftS06CiuOuMWnIYi1QqfC6jOzWjxnU9Ye1XFqMyfMT07b/hTL3jAikBKdN2B/X5L3x+JUYvDIlq3kUXwIbFZX/DWu29zOO449gf6l55DN2CMYdkudbdKk0iucjCExjQqIyiq/QDq7cSooYHBYkvDpRqLDmngOBzxKeLE4JxK8dvmgtqBXqXk/KiNAZBiQJLgYjEWwRfhXk+ahRLiLNp7UdPJuYjvHPuOQ9fR9171Oi5X5JTZFyOx36uor8rhbUlDxKmeLJK1biSaiScSEWUbltRwLfiqSgKC6nZUyo0I2o2uptDFkLM2HJKccNX7dJaL9YLNeg+7qT2wigXFcTGNO3Q2VRTgC87iH9QoNUuzUWlI8+rTubGorF8RwVnzlWRD3gxjcYZTzA3COU5x8ruGGF/irfX81UBNIUvOGVKAolNZO3V33YHjcc8wdIXw1NK0RftAQJzl0dVjnr33PvvjgSFEhu3LUZtSQ5FJrWkYhnJD7YzmncgF48g5E4bIIIOSrGYVnxoyJQgDUWzhf0RsmLwJyXVCWUytjSky89Goox0ShLK711i+am0mowX7gQzBcxh6tvuj6nTmRJRM6xzd8cChO3J3t2W/33P9QgWKhj7gmOocYlT7E3wktRTtDwCld+cSpinOPWl6YERbJRjUcJTvYozgtE+X9sUVQ2OEZLSo7WKz5HKzpDFdWTyM3oqRGVXrLLv2gyL9fZVjpO0b7bpX520u80i5NBZpqkTDlxtvhrEYsyH1N6hnIbPH09G6oGoKdaLpTrf4zLO499x06SUVjQAAIABJREFUnoe4/3OPwxgpJd+iO3m359jtGWLPwq7IJmnbw1KhmcTQrJe89c7bHLojfQzc9UeMdfiku6dkra5dNnZscWhFS5dNZrzZ2TjFc0IkDJ6BfmqkJIZgpeTVdYGFlIg58KLrWK83WJk6oZmiMSq5Vm5qAZKIMiQjGZwl+KT9S4eBWOT1cvHOjv3Aru/Z9UdSzljrSKICRbd3W3wYOHRHDseO2+0d+72W8GdLASkzIlrEVqvfU5YZMdQokJrANjI6hFEAScRZ2BjL/XbGjHuuNdCKxZpGSXDWsVnB5cUS51SlPOYHQtmvKA3/wxzqleVRs0LV1DIkM5LkdLNQYPxPjmcBPGQsJgDnPMyo3oX6pRWs+qzGwhQgSHdZIRdMYnyFZKwUVXGmndz7I7vdlkNRuW7bSIymtI0LYCwxZ1rbsL644MnTp3TDQPf8+Sg0I6ZM+JTISY9VvQqDFS1K029ewMXyPb2PiHgsghSXU6tZ81itWnubOlnQpgXiWlLOeD8Qg16zxioACiBloSqPRD2nIQb66AlZl6OxyjodhoHt8cDheKTzHrGWTKaPgXDwXF9fk8js9/uihHUgaBeDkY2bxRTpOkrNSsAaO2pTGBQAThJJWUgyLwLUcMSTSvakKHGj+h1SmLKSTdHRUq+kbVo2mzXLtnSVD6WnSpkylfT35oxJDvJ8PERajDGTC7U9FY9RmDwLdQgj8hWAFm+QsZjGvB7ioXGvKOgLjBo2zN/z5HHWvqGjGleOEBP7w7aAl1N/zoqyxxiJTkvBnTFcPHrEOzmR7l7y4sULjrdbmoVWjYao6tnOOSQq5pDEkIt+po9VCg2IpeXB4BkyY2sCHdrfxMdIX3qPLpzh7rDHOW0AVBsamwwYwdHo9ylfOcZI9B6fe3zfE0LUik8jhByJIbI77Lnbbel9oI9BXf2sjWx8SOyPB1YrbYMYEWIE51C3gtLDAwVo20Y1PmtjJil0f1UaaHBGGHIYfUURZV3mnFTJGq1+NUX6LlVt0phAYvldBIcbYb1acHG5Li0OOqocpd7yuUf6ozUqbmGtFIOh2ivkqXL5devo8443w1gI975Q/ft1ufCqOZlrvqt6HvPQQrSEez4f5oSrcaKV9zNGtTUWzaSSpfiAaltIyrx4ec1+f+Cdd9/jbn8Al1Rot2nog8dkp9JyiwuevX/Jk3fe4tvf+mP+9v/+NzncbFk7x6PlGtc05BDp+8DSOKwxHIaeICqCE30pDXeli3xIDGEgZ82wVFEd4yyryw3teknf99ze7Pnu9XNqBzPlamjHN5czq8KfIEdEVE1JGwl5YhhUqaxXxbK+7/GhZD4GzZbYpiWYTN/1HI+eHHsuL6/45k//FBebR/zu7/8ed9sjx+OelCO2MeTW4nPCNS3NZlnqTHqGAjJ6hKaI6uRsENqJc1EMmzMOZwzeZbAOcU7vS0wapvmEiY6mBxsS1iSaGHmM8OxqpSrgsWffa/5ElTAqsK0z480xG/dBzZNSdsOY/taq4iL0M8PwtCSiGNCv4BO9GcZi9k3mXsMJ2PjQyx4wMOfp11f933gMjM1maiXn/PixDDhC27YqDXf9UhsCHw5jJWjtIWpySZFaivKStmZ8+vQpT5484TYk8CoZaI1VaX0pbrkIC9eMgje1x2tNhdlCGMs5Q0wEwnh9vNfsjLWWy8tLOq+4gyp3R4zpsFab/vRGyDkW3WHV6xh67fMaw1D6qxx1AQ4DIQ5qtGd9S9RbUY9nuWx59OgxH3zwAUYc3/ned/WalQTGaPiBkCJDH0AS60WplsSAWCJmpmgey73QDBUma/ovCs7Uzm+qZlYl/KPvJ3c8Z4IEQsqlwbV+Dj02EhMK9H4VBIQfyPiMYcNZn5FcMkrqkcmDc/6LjjfDWJTxKj7F5zEYD53r/NiTV5x1yda0qoJHKlBrRoZcu1yw3x95/vw5+/2e4/HIZnOJKyrXTgxZNJNgx25VCefgyZMnPH37Gf7QsX95y647smpaXBG8FTJOhOQcTU5a1Vm6qlXPR0QgarNedTO1DUCO84VgWV20PAqXHI8d3XEoKU79GQYtGZcUdVcSw1BaE8acIOWx30ouVbMKpqlcAjADzxRg22w2vP/++/zsz/4sL2/uxnDEGAMlRelDhHk1pAh9Y3Biizygw5bUbAqJGDW8qNkhALHl+4ZE9InlYkGDUwVrG4vMIpAtCa9d1zDaLqJzyiV5gLvzozbqR58MBCeUg3qQEZWNNON3/RNRon6aLj33Al4Xc72udPezv+9D56ihiYXS89N67Z364sUL9tudCs2UXPbY7FeM8gCquGoW/OBZLRreevaMw92O43bH9u6A957L1VqZSKVS1WZojcU5IZdzRxNprFNOhwgSI0OeRGuIcvIZovcsl8vSM3TgcOwZhjB6QHHwSErkkAmAL5yPoTR0jsEXdF1oCmtSRAhpkgbMMumFPn36lPe+/jXeffddbm63pbcIuLYl+l5l8YoWv8oSqnbFMVhsNrikcnhjOXo09ENPDp6a+AK9FdYmJGRioz09lo1mWkBDxCQJTyAmQ+8jMQk+ZY7HSN8PDEMiJkro+vq58v8P7vnZPIrKUQEQccxbFpy0GihY7leR7/m+xkJEvgH8BvAe+k1+Pef8V0XkLeC/Br4JfAv4Z3POL0VX2l8F/ingAPy5nPPf+j5vMrn7M0m5udjLKz7bK/9+nfExMpdhB21deKZ9OAtH6s9ut+Pq6oq7lze8fPmSEAeGrmfZLog+QMo0Tj2MtmlxVrGGlD0pweO3ntIfj+xu77Tvan8kkVm6htZZZW+mjMuCGIcXDS2cYSxGo8jJOQODD0oTF8G1jWYzho6IsGhXONeAGMQY2jaWrIontoPStqNmT1LjWEA5RyYaS0wK4FqZJiB+vjMZalvGr3/96/z4j/84m82mNJ4+TvfAGjVKlWgVIUukRbjttam1SNY6G7QZQ46JoZ818y1AXlN62HaofV1FrT4eF4615KA6lkPMdCEp2zUJISbtGh/rcjQFH3ntzHzjhswmZ/3eMWrWrGJrlW2rnt0PF+AMwJ/POf8tEbkE/m8R+Z+APwf8Lznnf19E/gLwF4B/E/gngQ/Kzz8K/LXy+7VjJJRUXoC537X6da+d/56fb/76BzGLalROXpeKxZi0PY0x+K5nuVyy3W41u7E/sHDL0cIbBGk0m1ENkgoOq3u9XK958vRtdl/bsu+O3F2/ZNdr28WnV48xBKIG11iExmohkKf0BTEGV65Pqtcnq6JV9IGEYhfZ2AJuxrGJUhXAsbYlOasehq/9VTT8qZkdZVnODXjAxzB6L6eduBxvv/cu77zzDhntVN+Vkv3aO0WbQ0fEaOPe4CER8D3YAk5rc8aivVDJRPW+R43DgwGXBZczxiRWPtINSV9X7tGQPYNXQ9GFTMiGQKmBSdr0KHOaCftRHBO2pqrfzroxnd40pVucmXrSyldgL76vscg5fwh8WB5vReR3gK8DvwL8cjnsrwP/K2osfgX4jawr9W+IyGMReb+c57XjHNw8f+6LjM/8+myoBHo1Dupqh9LQR1yDtdqc9+5uy/OPP+H6+ponj58SfcA0DblI0099QJTCbUXZkbZxbK4e8bVvfhOM8L2/+x2ef/Tx2DRITOlZ6gOpKnznhFNJKjUZM39y4ZSgVZsyhVrbYaDniPeqkBSzEqH0WmhBWcphnEiVAFfDFHLWnp+2go2m4CNmZKGKSAlzFrz99tsqK9h19H2vYsFoLw+EUqSn8gMB7ZRlkiGURjjKuUqF/KaktbaxRWE7EfKgqdhCxYkOMo4+Zg5dD8mydCpWmxjooucwJLpAMbSOIWoPlhp0ZjRRMI9E5vbjzXI4zkMT9cZy5Z8Uo62hh0P7BNuRTDdqtH7J8bkwCxH5JvBngf8TeLcagJzzhyLyTjns68C3Zy/7TnnutcbinOJdd6a51/BZPIX5/7/quXOPZXweizGqT7FYLHRHHTQrsb5YkXNmu93SdwO/+Zu/yU/8xE/wwU99wNB15BhZr9dUinVO02eMMdM0iiesL1suHj/irXfe5r0f+wZ//Id/wM3za3Yff0prtAfJ0QdCP5BMpSULDVq3EK0KAbcujy0GfNSWjsdS3BUTHO92uotmDYVy0nJvbSCUxu9+omRtMuvlasruiGGxbEhZMz3L5RJrLb5gIo8ePeLtt9/mg5/5WXIWnj9/TjcENRrek1IeM01IwWBMg7SorL1tGBv25owvWQyTE4PX7uzGaqm1SMS2C5brNU+fXbBeNdAfudle83Lbc7la8uzpE5xpEDnig9bM+GwZYsYHKTomNUFawhDyKyzDq8lRP7xx/72neS8FG9P5rBmvXFpqhPth+A/Ds6hDRC6A/xb4N3LOd69ZqA/9x72PKiK/Cvyq/mE+9+L/omj293uP+jZVeag+H3zEGjd6DbvdjufPrzkej6zX6xFrSUljbiV2qZxZtfzaZV3Vo9vlgtVmw5O3nxF94OZ7HyIx4Yp+BcayGwZ1JxFqA77G2FFqf9E0ZOdoUkNTq0KbwLH3GpYkjdklU5oZg8WRC8MvV8B0XM/C5eWF4jOHPTFkFosF6/UT/r/23i1Wkiw7z/vW3nHJy7nVtbu6ukrT3cPhXEGxqRnInLEIkBxbnBfaDwbkB5m2CVEPFGzD9gNFvRDQi21YMm3YEDAGBUi2YEKwZGhASLIuJE1bnhlqyO6Zmgtnurq7erq7um7nnDrXzIyIvbcf1t6RkVl5LnXprtPjswqFzJMZEbkjYsfaa/1rrX8VvZKtrS2MzVnqDbh48SLPPHuB8+fPU5Z99vf3IxO4m2nj0IXWAsTVMFIlNm6qTFLEB+X7SD1cczKSOeUxuCBU3mMmNW5SUTkwYrVJUt5DvIGswZYeazSXwlU1ftTgI16RiAl0jB+8DXG4tXu0cpp9VtSa8EzB9u73H7iyEJEcVRR/L4TwD+PHt5N7ISKXgDvx83eAK53dnwduzh8zhPBl4MsAxuYhfnboOI5SKMc4D4C2VFpYwMcYzAywam2OMWqOp1XV5hk7Ozu8/fbbbG5utlGBxFnhUjZn4rBIdRmd4xqb0xv0OXPuAvVozFsCtfcMrEGKTDtrVXF/I9ptK4bBjAhkWWvmG2PI2vRvR24rzclwjsZPO7r5GOFxMc8jxHElfML5GiuBrOyRZRnjakJm87bze+r3UZYlly5d4sqVK5w5cwZMxqROJDqujXikepB517J7P1tLLHW5DyG6W5nmfQTfaplQNwSZsLkdyI0nNFrot9QryfrLLJ89TzaaUEtJLXv4yiFNYFx7GlfTdH4+9VE5HLx4MDHqacqiHKQEPjs3bUmZZHptPyCAM0Y3fgv4Xgjhb3a++grwS8B/FV//UefzvyIiv40Cm1vHwSseVR43Xm5FaOYms4koeWoELDJtIehibsN4PObmzXe4ffs2y8vL9Ho9VSSxetQF5e0sigJfR5A03uy2n6lV0743GGCLHGk8ZNp2r/YVvbKMoGAsstATBtTCaKqmJW4REYosgyzDkmOxVKkfiPdt/YByYIBz04mnae1KVei9B6/jVsxkSvx69sIFLly4wGAw4OrVq1y4cIGiKLi/u0NdKzlxG80KWgmJTz3AppZGmrva9yz50937aMGq9dEQ2xN4j3Xak8S5SawlaSitIS8stZSMGkMVLI3NIetjfY0DbBbwfjS1FNs+IvrX/K+/32yTTxqDE4nNpjoBgrSNf0KKAo5nWXwe+IvANRF5NX7266iS+Psi8svAD4F/L373j9Gw6XU0dPofHf0Tj3ZCx1EURyXhLEr+Egw+NBr3j0xOznslafEoUNdox+93332bK1cuE8Iyde3JsiJWVKr/WBRTS6Wp9aFN0QQjlrIs6Q2G5EWPxo+o8fig/UgGvWEb4TBBxxKCAnXBB6Rtew4SyXMwQm49LrZ29OLx0tCk8KKxBDttV5B4QRWw7GvGowsKJmYFYjKyIifLcs6fu8iV569y5swZLj9/iSzL2N3dZX80AbEYm9O40JLGppUPiGNN6fmz36VEuNAJWTexgMPEfAgjGU6dKapGC/00UuTwVEi2z9JKg4Z0+2SZxeEINBhTae5dmKb6/6iJcr9oy4Tp6zRq8iTkONGQ/4eDsdSfW7B9AH71YQdylIvRnVxp+4c9xqLtQbAypU9Lv6Mr3jR82z1uoqobjSa89dZb/MRP/ISWAct0ZU3vvffksQ2A8x7EtynORVEgRc7y8jL9pSF7rtYKVgmQ5XGFnuaJpDMOTgvHJCgPaAsIA3jt05nFzuhNUEXiG61yNeh4SElkRsjMtIq1dg218wyWlhCbaz1IgHLQ5yMvvsCVK1cYDAYMhssKZFZNBHA1SlJVVVtPk67bvEIWiEohsVAkRaGUA9qjRPdxaGhUy8osQsAGrWDFC41vqPcrGnYoe5vkeRGbJwGSqRKVQo+dUsY711K11KLZ8XTK1o8zf+efg26H+e42T8r9SHJiMjgXyaIkKzi+GXfYdu0D2PH9ugrJGptSXwB1TTwgEZswxtA0DW+++Sbr6+ucPXuWsiw1dNg09IdDfNNQNU3b69TYiMJLZBewFivCcDjk3IXz4Bua0STmSsBkrG0L20K7AC5lUab4uUg02UMLEhoMNlicOHV9Yv6Cjw9em20a08OTZSFGeS/6Rcny8jIeAzIhiPDss8/ysY99jLW1NepaE7yappnya2Q5de3Y3d2P5fQRWwmBIFro9KCV17k/wbSEwGAINjKZBacJXQkYxeO8iT1aBUT7tIwmgdfefJteoQBxnpcMyl7bjWv25ptp5t0TfqCSvJ9g/fz2zrlogTEFbsM0yvOkTvFkKItO1GFRWDM9xN3JdpDmPOxGtElGnR8OJABtdpspGDo1030T6OU9/W0fqCYN11+7wbVvfY+V5bNcvXoV18ROWLUnt6U+4E6tjix1HxfN31C0IJCVA37sk59mZfUst27epNnYYG9vj8IqZtJUCh6WWU5uMqqmApOxU+1TO48XTXgK0U1pZDulHgFembOB3OZYhCyz2vm8s3gGgb61hH6GFAVFr6QJlvMXnuHKn/pTXLp8hV5vwP3726o4vdekMQfGeib1PnfX77C5tcH2/h5ODA5ogkFwLY6oiVcG52u8lDP3ynR1RxsdkRbX0HticbF8XbWodnL3tfKE7k9q/GiCyJ4qjWjVNbbU7m7BtQkWOocin2qnT4yIj5wQmh8yK3P0dnPfThmpukBj5/ukp2YkLlyiV2gGEA5hqtgSJttOVn1xuKk6VDw9lg/EEaX9HlNrnAxlEU/mONr4KAxi5rAHWCbz28wjyAd91z1G4tEMIXDv3r3Ys1OrPJPVAbMp6yFS5weZNXJtnrG8vEx1/lyk+9cEK2qtmExRjGRJpGNaa9Fi62hWOwVWg43cDj4yb4kmLAGRq1OVRaKXSw9ybi1ODGIteVbSK3usnT3LubMX6A8HTCK5DmguSmrNHUKgqpq2uC71gzUmi4i84YG4UzBHJgodbEqb2Dl+WpjmAB8rbyUqAOcctbUxH6GYAf5a100SDV1naF3w5IhoiDqyR0s62oPbmvab5LrqGDpWz/w16Ooj4cFBxL8lAscfWDTkg5EHS2kXKYf3O9fiIKVxEBaS2Klu3rzJxsZG64L0ej1lrIqMy97X7Wos0Uf2IhgCjaY/UA6GrK01hMbFCtGGZqLJVsF7giipToqqNEGxj1wEG4LyYYaA9eqG+JSwE893im3E1G8bq0LN9NxsCPigpDJFUTBcWWFt7Qz9pSFgYr+RQGFMWxKfiHwnkwk7Ozvs7ysPhveQZQZfJysgMqZ3FoZHncKtZanUv0gCTjvFJAbfKl1rLabozdzTKaaiNkWbIzOzOBxvPK0i6JzTA/u2z/38PE65ETHfpW2N2dku1S2F2WNNBzr/UXyeIjj8I6YsZqW7AqS/u69JcRzWku0gi2CRzCeydMfQTW4hav7k5ydwaX19nbt37zIajVqFMO0OpQuDdjvXXpTtwiCxM0W0G8vegNWznnGtVaDbe/vUrsFV+tuJTNdDZO9WNisrWt2aBYO3gImFRdHPTyS/YqbnEYzmbxiDMnmLYBqPr5XNvNcbsLKy1malNk3TXnMR5dUgMoiHEBiNRrEX7L42QoqWTxOvnWInJrrSjzd5Z8Fuiw8eIz6yjDktuJOs5TKFBy2K6TEiqOpVcczOu+MOiFnQNH3Wvo9csdGq1IN3ktUi2KuSFJ6ZOcfptgsGFWLSnQ4DLVdX8Hr6nGjZ/+PIiVEWMw/lAnm/rYp5rKKrsLq/3eZIyDQhZnt7m9u3b7O1tTVNgErVgCJYphreh4ANVn1X9Mb64BAMJs8oh0usrikrFduaFVlPGjJFrgh+2gk9uJqU8GVAqeZi5aExBhvHaUIi5o0me/CRBFfzJ3RiqvvhxzV52WO4sszKmTUGS0M9V2vpDfp6fjHMGUJgUo9pmobd3X02NzcZ7U+mxUttK8pZwuUpm/rh9+nAuZD4WkXxppQjIolajogdGC0wC35xxGCRAnnADT0wHZypQpifUxFU7n7eOjZeSDc/WX3d8Zg05zoYioqZHluY6WkKTK2quCi0neK799k9npI+McriOPKwodGDMIvDJmK398L8fmkM3eQtay27u7vcvXuX9fX1VlEky0Pp2D0Yg/VMF4mOn+lRPkoJGTYzlIM+S6sryPnzWvOxu0cg8obSQCwKkxBBwRDQ7hsGKxnWWHKTxehL3C+EaQGVUkLjfNBoZUzcIhgkyxkMl1leWWNleZWiP8BpAUK0KHwMIgS8OG0X4GF/f5/trV3tcRLAYslkGj6NdLyaHCZdIPDh72X7kMcWAIhXsx2rCs83qgIjF0cIgSpGsLr3t72PrbKYA31jFObAR2zRXJx5uDu5JISYpBOVVkALB4U2oYoOliVtfnabnB7nnt73qeo7ePFTDCRt+fjZqCdGWSyyHA6yJmbN0MVyHHCz62p0J9GilSZt212N0uTb39/nzTff5PU3XuPzX/g3GI2FwWCA8zXO1+RW2add8IhXLs9gpOUzJ2g2p/eBxmu69erZc5yTEpsVbGxsUo3GGIQ8K7Vbj2vo59pHxIcps7dpPIU3sXfotO6jBUkJ5HmGt4IJnonzVDETdBQMz3/kBV786Ec5f/FZ8l6JMwbnArVrGE80pJvnOSEbUXtPFWrqynF/c5s7d+6wtzeiaXx8GMEYG/ukKGdI8EZXRZFIO3jYpJj67tNFXDlVAxC8m6lrCSE2oraGajxBvHKjihFwml2beEunIKxBrHTmwJSmTs+h6TyOZlZxhKT540PY9jTwQIZ2aU2n4rQuSNcN8gyyzJNZaYmSAg6r5KBxDMmF1VqZdLl8wj5DAs+NWooAJmCMQ4wqPyXx9UzV0KPLyVAW8cbArCKYd00WuQXd7Y6KpnT3n/VbH7Qk5iMfoPcw8UJ0x2GMYXdvm3feeaf9bjxW+rqVlZWWni6BgsaYdmVtvJZeB6YPtAtCEEs56LO2tkavP8QEaKo6thqweO+mCotC1+08cloGyONDEfCxz4hEbk9PHb/HB1yleRGIUAz6fOzjH+fMuQv0l5bZn4zZ39vH9gpNbsoznKvZ3rkf62GE/f3A9p5aFKkepmkayrJHVVVkxupD0sE7pqXxs/ewe+0PtSLb71NERZf/hBUBZHmpWItTzCKl4acIlojEHAy0lYT4B+aVjrdoj5ksFd8BQzObtX8bifk4XpR13Dk8MQs1OMDTK3S4RQH90pDlhtxajFVa/zxFzEJolUHjPeNRJJP2TLGH4AliaGpHXqTPQDKDNRaMZXt3FAvomsXX8iHkZCgLOT4G8ahYxaPKot+bR819aNje3ubmzZsRs9CWg0VRKKntgiG3Hcw63yk2YBCvSVVZXrJ65hxrZ8+w7hzOBQwBm+ex3kNdGJGAsXkLXtJRYopHxJ6lXslwmhBoRhNGdcPY1eRFj8HSkHOXLvPM5ecRk9GEiA1YtQQSRtGtriWyn08mE/bGIyaTyQytQHAeOQSEfpISEvj/ENLeW4HY4YQHmoKGaZ6CulKCBHV7smipaG6Ei/wfjbKRO5DoLJgAxkKWCatLOUWZUeSGPBcyA8aqInV1wM7ldSSFNykrgheaAE0dcA60da4n6xUEW0fLFFzjCX5CCEKZG5x4miBtCv2jyslQFgtCp09T5le1Rf4yzLosdV1z69YtxuN9lpa0ZD2FTtvq0/YYnhDMbBIS6juHiINI0LqOYtint7SM3N+mMSNo1AXxooQ8tW8iS5QmGIXgKawl2AyJZDwhKON47Tw2N/gA40nN3niCFDkrZ8/y7LPP8uyVj9DrDxnX6tbUPsTqzE54McYyXGiiJdEwGo3aBshtLgizluBMlCGG+h69bDrwQLDwIY71gPXYDefOV6GayKsaFiwcrsHTIEHT+INHSYYCFOIUaDRQFBm9MqPXKzh7ZkgR+UPF+Jgr4hACLs8pjJ0dG1A7R1UZxZiCUFeBcVVRV3rSg0GBl0SC5BnXDtfodTYGJiEQHI9tW5wQZTErB4GPx3E3nqQclfsRQsBY9cuN0VyDmzdvsra2NkM/l7aVaDJP8Q+J5e/6eQpzBtH8B59lmADlcMBgdVlJbiYjLbXOA3lRqqlbN0oiI+qfVk4zU40YGq+uQe0bGu90hYlUc1IWDFfXuHDpOZ67+hHWLlxgc2cXL2aa8GUMYjNNdDKCeHV9fGjwkZlrMhkxHo8je7Y74D5NMZPHvi8P6oqHP0YX/zIHA95JgShuounmJkKO1kAmWvgnQf+WXN3KQaHXsCgz+v0evV7BsF8yHOTaAd5XNE2t5fyuidetoTBTPCyNMc+E3KDh4CBUpaescupK826K0uC8AFolPHDKY9J4w95YG03VNUweU1ucSGXxNOWoiMs89pHmWLq5f/Inf8Lly5c5e/ZsfJAmSGYWKp7QJuDMQu7JWnECdfAM1tZYrieM6wqAq9UoAAAgAElEQVRvBGuUUm91OKCuKvb29qijC4DzOOuwVklufBAa8YTcIFlP+5gaobeyzNmVVc5efIYLzz3LYHUVspzJaESWG4zNKKyFmF/h3dT1EhGkw5OhyU/VDA4xxSD0yZ5PRIq21CPepScjiyJkB0W/QggKrAaHMWCN0CtyitxgxGFw5LnVBzu3LJVJWSj1YFFklLmytnunvVwCFbhJ67paCQQXYpRE09yDaNf5YGJDKEy8/xm+L3iv2Ihz2m5TNVZBQDvDZbsGYY+6DmyPH+96nThlcVi22dN2VbrRkba6NEZEtKO68Nprr/GpT32K8+fPYYzgXIO1WpGZQuOpra/G8O2Bv+Uyg8UyWFuhX43pjfaRXsGg12NpMKSfZ+zv7lEjjH1DPXHK/I2ltuiKaAIhTKtKM9Nn0BuwfOYMF569xNqFCxS9AT4IVV3TGw71HI1gjCUDRqMRdaN1FYlJOgGZzqWM05rU90o6IboHlOuDdENPTQ5bGNKYna87n2lmqLGGzBpWhiWry0P6PYuxgTIX8kyjPr1sMqXjl0BuPcZ4gm+01UJd4asJodHEthbfME6bLmEg4rde2y/hfRN7gWRkRYGIpXae/f0x1ihJr1gDRtnFxGYUvZyi1KK/Wxujx7peJ0NZdKIh8CBG8DSUxKIM0gTWzYdwk8uxv7/PN77xDdbWVrl48QJXrlyZPiCCmp84QtDiJnxAYiMh04bJfGTyEkKvR1VPePvuLXb3dsmWhqxeuMDS0oBhv89oZ49+ntNkghn2Wpwkw2sfVYHMWnIjsRIzZ+3ceZ5/4SWcGPYmFZPGEYzVsnWPFrAVPbwL1FVMsIrRBLzDN0qoUkWLZlKNtK3B7i5VNW5N6IAj+KlFpeCrf2z3AVQZhS5I8Qhd0GeSr5gNkU9fBbGRtT0Rq7pG69CMEJwwGCxz/uwKeebVqrCByXhENdqAkGlRYVAVabzENglGu9ZBy0QWYuTDUGtI2TeKM8R5EUTdWMkcuTVYq02mcDWTUUUmFaYoMGTU1YQqaHHh0pkzDJdW8aHh2g9+FJQFDz6c837vwyqM+RyJ7mfdCZxwhe426e95RWVE2rBdjEOQmZwyL9jb28FaSzUZ89aNG9y5fZtzsWw9Cxbjjb4KOlF8ICtznGvIbEbtPZlVEtnR/oQ8zxlXI9bX17l1+y4hKK1dIYaxF9y4wduMMBhSljn56hrWRqVQTzkl8l7ZsnAbkzEcDtkLHu8aGl/Hc3I01YTaCWWvQCQS7gjYTMhsjnM1zajB+TqSGmubw8Y1+NBw//59BXq9U+4Jr20Nm6qe5qy0eR/TnqIz9zVGcxbdi9l5IockdXXIiDv7SJiC0VP3x8QEs04EpL23cXw+NuyRlACWEXxDVXvGVeDWrU3G4zFnV5ZYGuZUOKrJiLqqMUYbX+eZKoLaVRqZqjQ/xApY77He4j2YkFGZTBPk0nz1mj9TlKqwCnpYl9PUQl0JrsmRkaGWQHA5uc/w0uBdTRMqerubZDZlET+enBhlcZQymJ9A74fMJ10d5Mfq59oDI5nhab/d3V1u3rzJjRs3eP755xkOh61vn3z4aXadWgLjyZg8L2mcjwVYmiNx8533uHbtGltbW/R6/Zbqf2tri/3dPTY21tUtMKr0ykyZt0po3Y7l5WUuP/88q2tnyfOcqlL+fWOUCDjlEFhrldxXNNvSxorRgG/zIloMRqbp03Vds7c7Gw0JIeCDb3uStNe3vX9JCRx8Lxbd58Nc1EX7L97+QSukq5S644MpHeB8NEcCjKsJwYF3E+rxmP3lgl6ZkRmvYVaxWtQXAWyCwbnYYjGGzU1mVfU5g0ZcpyCwDWl86X7GlHyUm9SjYfA6ZmmGusbjCEbZ1FyAqqpxolwljysnRlnA0UlVx932KDnI0gDaMKeZcznSft2ELtAHvs0EjMdbX1/n9ddf5xOf+ATPPPPMjIsVQoj4hnbw1v6jDVlWMBqNVGk0DTdv3uSVb77C7/7u7zIYDFlZWWnJcne39rh1+ybvvfcezulvp27a1lqYTBgMBhRFwcWLF/nJn/xJbNbj0qVLeBMp+UQwWY/GVzFZTGtJNA25m6wWYhNk314f75v2OjWNWhWpRB9omcC895qU1b1mM5bd3H3hoOTl+H0KcR4677vK4Hj4yIPzYNba8YQ2zK2KIraJbGr260BVe6q6pqpzlpd6DPoFy3lJZrIY7YpFeCLEtq4aYkUI4nHB4CUgVnBuGl2JPP9a6GcttlAswjmtMq59wHmhcQ4Ri3fgJCA24EXTuyd1wMQm2I8rJ0NZHJGUdZCL8qTkqBVrHtTsKoZ5N2nQV4Dw7bff5t133+XKlSssLS21tSIh+LZrVAiaXFOWNloZBWWZsbGxwbe//W1+7/d+n6997essDYYsLy9rqjewtbXF7u4u2zv342/rQ5zAuPHumMFggDGGCxcu8O6te+xPHD/zMz/DcLjUEgv3+znGZvjoKmTWttZLNwqgCmJaRds0WjqfiuU2NrQlgnOdzNj4ZM+HSgPM5DXMfM5iC3JaqXmMm9kRTXeOULLEC9Uey8xvPP39mYivFvR0x+CFSMVowCuDelXDaNIgtiZgWLIFRnIM4HygcTXGCCaDLIukzo2m0QfvINb1zGa3av6MEUtWaEzWe0/lPbVzNMHijNBIwESqA2MFBcL03jW1x2oY5eEv4JycDGURjs6teD/dkK7J2k72OYtifvtU3ZneO6cgbVGohfDO2+9y/fp1XnrpJVZXV2PTohQy1GNYoyuzUvgHssyyubnNH//RK/zB//V/881XXmV3e4ftzR16vfttu4Fu8pPNdDWqqkmLU3hrGDU1VVUxcYFJ/Sq9wTIvfvTHefHFF2lcoGpqyv6QrOiROT2HjGkp+vx/5xyTSlstjsdj9vf3WwW4vr7eWhXqXk2vm6Ytd+pqxEdo4mg+i0dVEkfKA1mSh/+IsmnFqFVUOj6IWk9BY0CVAyaBhoq6CaxmPazNKEqrwLZrNJENVTRBlHhHS0ECIl4tAjqkwsYgmURgU7N7Q/B4HHXwcVtLEyvLMoFCLMZYPA7nDI1vKIygvVceLxJ1MpQFR6/u8xGIx5GDsjO7xz8oIau7jTGziiwxZI3HY+7cucPr19/gvc/c4oWPvEg2zKLprhPVORdR8BA5MjK2t7f5+tf+kK985Sv8q6/+v+zs7Cmvp6/jNjnGCIPBUkvVFwTqZoINOVlRqMUSXQBkhAtw884dXv3WNT756jc5f/EZ1tbW1BJID60k10FzH+YVRTrHyWQS3aaq7UoGcP/+fWDat8R7j2S27XzWtS6SNZaAyoPkoHYeiqMcfv9nQGo0eiMLLQqZex/P1Qtt2nd7jztbBhNT7TMCjiYo1uRr7f1SNzU7ZQ5ZgCxDTAnWEfyYEBoqH7GcGOUkaJha+9NOM36TaynClH7AmrZZVWzwgItWBWIRm0dWNIMNnqpucGLiXP0RURaLkO/575+UVXGYsujSmqVJ3R1Tl8vCe9fS4PX7fUQsGxv3KQptOnTt2jVWV1e5evUqL+QvkBcZvV4vZnvWiLH0eiVV7fmjP36F3/md3+Gf/tN/xhtvvMF4PIagvUVXVlbweDxKkKv5GrliDSZgJNPuWyFE01YVSVn2SR3Svv/97/Obv/mbrK+v85f/0q+AD9STClcbJqMxoSh08kXgMrkjjau19mNvh9FoWv9RFCXGWDbW77O+vtlWNqaSaMFQew3zAR0OjM5170Y/525t90/tIqDuwVG4xnRnaZPCQwtaChw6h6LC6ICc81G1YGzcTCNhqfE0Eqh8g69r9ht4K4zo7TQMl8YMBzlFz5KZgkHf4nyFiXZBitpYMRhrKDqFa9bGuhTRe+gF8B4rASMBH1NZjYAttGCv8ZqnIVmOBOVG9Y0nZIvzeR5Gnm4K3Zx0FcLU1JeZB/QgpXGYJXDYdt3P53+n65p0x9LFLlIValIy6iJohWLTeN56621+8IMfsLe3N9NUeDKZYAxUtR7r+9//Pl//+r/m5s2bLaZRZCWTSU0IQlH02irJbgTGSkZqhktE4K1AU00wBIrMYgi4uuLtt27wnWvfYnP9LitLA5pqTFONKXOLwbfnlRRFAm+bRis1g49dzhrfukR37tyN+00jK91rvCirM1lTrQJZcEtENIktJbLNY0Pzlk9nTxarE/18Zr9gpv8fkNmQOqDsYtAOuPFa9ekRnIdARpb3MbZkrwpsTRo2dkbc2dplc3fMuAGTl+TlEGMLjag5kCDkxlKIjX1sc4osJzOxk7zzWEkeUAw/O2XkzYwaQcZCXqSGWHULqhIS583jL7QnzrI46H1XSXRX/YMe/sPcmkXg5HzYdH67+VCcvp9mRiaux6IoWoXSNA2bm5u89tprvPzyy1NMwXuyXDusV1XFrVu3cS5w9vx5xFpGeyOyrMA4Icuytqw6WSzd80hmv6sb6tTCzit+sLe7refiPK6uCK7m2jdf4a0332B1eYlhzNacgpjpIXRt2DSds/Jqeq18bBqWl5fZ2Nhga2uH8bhqLawUeg0xfOBBF/QwGzY9StyhQIVHxBygKB6UBxaYpBwWbj51Rw6TxMSd8jR8iFhEpMCqvFA7TzVxlB5qb4CCleUeZaZs6xgQmRChSazNsSafVjVHfMcTu6sEVVCapwM4hw+a/m+MRySxqE8XJWM65txjyolRFosSqJIswhUO2v84UZXDAMx5pTBv0UyjGolt22Ktb/34oiiii6KRgu3tbV577TU2Nzc1dOknZFlGUZbUdcPurjJi/9RnP8vy6ipV1fDVr36Vra0tlvrL5ISWhwE8ZVmqPyuCZHaG61OCug9FrEWpxxNym2njHSNk1vDO2z/k9p1bjMYfZWVpyO7enuZolCXjWKPQVSCJlLjLVu6aQL83ZOv+W9y5fa8l3qnrmjwrQGYzcoG2TQEi7dydrwaHqSWR1vpF96ZllGuVedq43Yl0lBD/2XDEHApm8YDSdzOjmo5NsVFVMB51JyDgTQ54vKtxPij/iKlY26+xg5JMLJk1hMwiIWBNSVH0EBctV7Q3i48d8IwJMRnOadPo6GMF11BYyHJtvO0iN0ciAhaRtp/M48qJckO6Mg+uPcp+R20zbykc9JtpYnUb8iRloA+rYG3e3ti0b0quun37Nq+//noMZU3p3XZ399ja2iKEwNraGh//+Cf5+Mc/zsrKGtVo0gKi+vsRLPSexlUEHJmhbWqcXJcsy7TKcFJRVxOdwjJtI2Ct5Rtf/0PeeO16tHQU7W+aKuYE+JY0xzlHVY1jijJRMeakVfDevQ3u3l2fumOdB3KGzIgHc1bmpetydO8JMMUe9CAz2xx8TDOzTTr+9L/p/I+fxavc3UabO8uB/xePRVrXUCQnBGFSw/6eY2NzxM5ezaQKeJ9jTB9je2BybJa39yg12zbGtEl3yY01QVMwjNEFIi8Mea40hkY0Pd3Ee+Bjot88Z+ejyIlQFoHZh3URGv/APnOfH0dJHBTl6FoK3dejJCmMLuem7g8aHdBin52dHV555ZV2EmQ2ZzQac+/ePQUL+8oqVRQFly5d4tyF8/SWl2YUUvvfT/uKeO+1J6tX3opMjFL+h4CEQCYWXGC8t894b78N01777ne48fYP2R3ttg9GMvudb1r3w/umLRJLom5XwWg04fbtu2xv72KtJc+KGRcpXe9F79N17z6885JW7UV3oas8H1b0AT4I7DvscZjlH5GgdouEpGJoOTyUr2SayOUdNDWMR3B/c8zGvT3u3x+zP3ZUHpAcbIE3FpNnZGWhhWLWxsjHNOFO/xusFazVKEee52pNBYf4KVm0q2qaWpm13GMS38AJc0OOwh8WafJFFsKibY/z+/PHTm5H+nvetJ7ff37bBBY2jeX69esAlGVJ7RTLuHv3LisrK/Tz5RgWDQyXV5RCv2koyiKWfgdEAtY5jFusWIHIsWBig+bYGNl76rrBI5RZwd7eHk3TxAjHiF5PO6whFqFp3ZoQXPs+rXb63jIYDFi/t8Gd23cZjyY0tWtXwiRJeXbv0VELwMz1POy7FEg5ELLoPPQJfzq02OwwMtvjradWEqNW0Lof0ZIAvEeCQYIjeKgmcN+PtaRcBAYleZ5hipKsV1JEC9B75UWVmANjYp6FtapQcvGIsZrQJTl11bm2PuCbEFsyEHGVHxGAU5iyarefzaHf81bBYsDx8NXsgd/tAJfzx+v2AU3H70ZC5o8TQmizMhPwmLqT7ezs8NZbb/Hd736Xq1evcnf9Hs45tTTKguFwyP7+mMYHLl68qH1Ti17rEpSlHrdyFdQp+9PRVHU0NV10gaYFW9s7OzpuIxEMbNja2uLCMxf587/wJT7+iU9Q1TV5USgHQvCI04naNJU2PZ5MAK/kw5EzIQRPr+zzB6/+K65d+w7r6xvs7+0xXFqiKIpo8aRoUDNVsJ2oRjtvDzEOjlL60sE+jpSHrUo9hKPPhNlhKxnONKSODwTxSK2Fh8bk2LLAxhLzyWSfegLOaQi6QSgHfbLBkKWza5jxHvWkYjwaM2lqghGKskc5yPC+Ie/lDI3gvOBdRt0PBJ8z2dew6aRucF6rVfFCkWkv2jIvgJ2Huw5zciKURWBKUdd+1sEOuhTuSXsuWrEWmbpHhVQP8jsPC9HOkwt3w4GJGDaFFr33WNGuWTdu3KAsy9YdGQ6XAaPgpQk0VUVZ5hpfNxpN8TggYhHeYo0ls4U2Om55FU1b8CWZxYvHFpGgdjJpFV9RFLz0wov8m1/4PM8//7yCmE0DDeSSLIGpGaulCVkMiXrqekRZ9tnd3eW9Wz9kUu2DOHr94UxjoaKwNE2FtVo4lfj0Ja62LeWeLMaPZhaKEGbuhR4jKfa0z7Qxj97kub8PFT/3yoyiWISjpGnRtSZ9tCrECiFYyJXiEDzSpMO61CieKhi296H2NUE8Zb/HyuoZeqFWAmAKmjDGETTaZjOwGWDJcrAOmtqTe2VaG3un3K3W4qoGP6nJrEPKBmsFTM3jyolQFkkOegjTg3iQHBQdmbcWFsmikCnMJl8d5/fmjzfbUsCzu7vL66+/zuXLl7l48aLyYcYKQmMMmRGsVeWSgEpd2TvAKp1Wg1EZpfGEENnD65rxaNQqtfRaFAVXrlzh5Zdf5sUXX6TX67UJVsldSpM/uRxVVbXuxWQyoSxLnHPcvXuX+/fvt1WzafsZst5juhsfNjmue9td7HwItHzukZBII1we52qsNfR6Baury4hRBneJ2ZhKAaKAsipgq7UlDoxoCBkHvcZRVQ11PWqfFWstxgpZZlCd9nhUWSdCWbSRrwWTa9EDv8gFOWybeYsl/d19oLvbJaxinuviMNN4/jfmlcVkMuH69et8+tOf5vLly4iNK2a0QvLM0jR6k3u9nlaX7u4utLZSp7H0cCeFkIq7JpMJ/X5/pk/GpUuX+Pmf/3l++qd/mqWlpdZFSuBlXWvWZ57b1v1JSipZSP1+n83NLd555x3W19fbSbmoQneRHKbAu58fhl89WTkoVHqwG9KVRefSnSPz0TUvYKzS4hECDo+vYWt7B4ywtLREM6jJc4vNMwqG1M0IsRZMRuMrsiynzEqcCzhxZFlBaAJFNYkg5jT/RJVFLG1/AiXqJyIaAtMHFKbhuynYdnCYc/7z+YrJ+e2POkYax0HWStqmq2QOW0G7E399fZ13332XqtIErhSSBChiXYeINijq9Xqdxspeke24+neVmtYOTEvlE06QmugAnDt3js985jP83M/9HJ/73Odai2UwGLTnWxRFe+1TElhZlm3CWbome3t73Lx5k52dnQie1u2Y5i2zeddx/hp2r/n8ZydBDruvh415Hvua/x/QKg0fOTarBjbvb/PDd97l5u173N8ZE6SkN1imv7xG2VsCyXDeYG2JLUqyLMdmBXlWYrKCPC9bizRFTbIsaxeedH8fR06GsuiEhrrl313SlUUuSvp70efzk7MrCyMJC/afVz4HHe/g05rmQBhj2N3a5a233ub+/fsUWc4ougsAmZmGxspSb7wxRtm+O2PtXossyxS76IRwQwgdQNKxtLTET/3UT/HFL36RT3/60zz33HOt1ZDGlcaoisG3CiR5fkmJhaDK4vbt2+zu7s9cn+41m7/Wh70/iYoihEA4BHxN2yQ5SmGISCxIM7iYaNU4r8laCC7A/gRu3dvgvTubbGztMq4cJu/R76/SH6wSyAhEMgzJwBSa8ZkXZFlBURTtgpPZvHUnh8MhZS+nKPLHvi4nxg1Job6u2dt9UNMqOrPfAROtO4kfZhLOm/yLJv5hOMgicFRElJSkCWxubvLuu++ysbHBSy+9xHA4bC2HtG2bWDW/SkvsnB40szLP8xZLSBmW3XEVRcHS0hKf+MQn+OIXv8jP/uzPcu7cOUajURvWTBZGit7MYxP7+/vkuU648XhMVVVsbW3FNoV7HWtwWny3WMkuBqBPvITYGHlOZsHWxXOhe0/bwwHBx1R1o+n0EiCVs9SNZ2PLY/JdBisjsl6fpeUeRZljfEOW1SAWQgbiMVlOnvUQPNa6GH43M89MUWSx38gH0JFMRK4Afxd4Fp0VXw4h/Pci8hvAXwLuxk1/PYTwj+M+fxX4ZdTa+k9CCP/nEb/Rrl4w+7CnmoSUG9B1EZLyeJxJ2LUoFgGr3W3S2Ob3nx/D/DbeB3q9Hrdu3cJay+///u/zzDPPcPHiRSZ1xWQ0our1kABLS0uRL1NJXZumATft3E7H7QghsL+vrQN92xHLU9eez372s3zpS1/iC1/4AlevXuX8+fNMJpP22mZZRl3X9Pv9lswmKZwmkslqJa0wHlcURY/r169z/fp17ty5NxP50XOcdo2fv4bhgGV60UN3HFD68eSwfIoHw+LHcUXmJYSAzaQ99+A7LpqxOO8xxiKS0XglABYRgrXsNzV3NkdMwk229isuP3eBS89dYLh0RovPIpOWkRxjDSbrEVyNMRnG1BR5ydLSbHPusiyOLOs/jhzHsmiA/yKE8Mcisgz8kYj88/jdfxdC+G+7G4vIJ4G/AHwKeA74FyLysaAMIotlDifoPpgJ9e+CcfPbzE/S7vdpm+5rAh/nf7OLm3T3PcgFOcqETg8mHpZWlhmPK3Z29njjjRtcv/4GzzxzCcEyGVcMBktsb9/HEJSAN0+ZhrPdvtss0Fhg1uI8jTbDLcsSV1d85jOf4bOf/Syf+tSnlKR3T7kxxuNxe021vaJvJ1aKmij5bqAoCiXQmUyw1rK+vs6NGzfaornUCsDarPN+qkDaa9cJNc5fu/nredC17lomi6y+o2WuVuWAscwvFI/yjD2g8GSW6EcibhHQqlUx2myqbjxZgMoHdvbGcG+DssxZWlpi6dIapffUk4rQOIIIIhYxGWVhGWVjbUuRKatWcjHrZp/aNfR6H4AbEkJ4D3gvvt8Rke8Blw/Z5ReB3w4hTIA3ReQ68Dngq4f9Tnc16l7sBOClbR4VP1j0W/MK5v0SY4zS/ouoKb+xycbGBjs7O2QxkSttZ61t8YvOEZiHl7QtoZuxwkzQc7l69Sof/ehHee655xgMBu02h52niDBbK/4gnLW7u8v29i6j0Wjq9gR5pAfqZMphmZzvg4QH2auC116mo1AhEtjd3Wc0Gcd5P6vUjER3NbG65wVFocdLlroPkxgReXzEQR4SsPsI8AfAp4H/HPgPgW3gG6j1sSki/yPwtRDC/xr3+S3gn4QQ/ve5Y/0K8Cvxzx8H1oF7j3EuH6Sc58MzVvhwjffDNFb4cI33x0MIy4+687HVjYgsAf8A+M9CCNsi8reAv47iNn8d+BvAf8zideYBjRRC+DLw5c7xvxFC+DMPN/ynIx+mscKHa7wfprHCh2u8IvKNx9n/WKFTEclRRfH3Qgj/ECCEcDuE4IKiV/8z6moAvANc6ez+PHDzcQZ5KqdyKk9fjlQWoo7ubwHfCyH8zc7nlzqb/bvAt+P7rwB/QURKEXkB+DHgD5/ckE/lVE7lachx3JDPA38RuCYir8bPfh3490XkT6Muxg3gLwOEEL4jIn8f+C4aSfnVQyMhU/ny0ZucGPkwjRU+XOP9MI0VPlzjfayxPhTAeSqncir//5WTke59KqdyKidenrqyEJE/LyLfF5HrIvJrT3s8i0REbojINRF5NSHKInJWRP65iLwWX888pbH9bRG5IyLf7ny2cGyi8j/Ea/0tEXn5hIz3N0Tk3Xh9XxWRL3W++6txvN8XkX/7Ax7rFRH5PRH5noh8R0T+0/j5ibu+h4z1yV3b+aKqD/I/2hPudeBFoAC+CXzyaY7pgHHeAM7PffbfAL8W3/8a8F8/pbH9OeBl4NtHjQ34EvBP0PD2nwW+fkLG+xvAf7lg20/GOVECL8S5Yj/AsV4CXo7vl4EfxDGduOt7yFif2LV92pbF54DrIYQ3QggV8NtoBuiHQX4R+Dvx/d8B/p2nMYgQwh8AG3MfHzS2XwT+blD5GrA2F9V63+WA8R4kbTZwCOFNIGUDfyASQngvhPDH8f0OkLKXT9z1PWSsB8lDX9unrSwuA293/n6Hw0/waUkA/pmI/FHMPAV4JmgqPPH14lMb3YNy0NhO8vX+K9F0/9sdl+7EjDdmL/8k8HVO+PWdGys8oWv7tJXFsbI9T4B8PoTwMvALwK+KyJ972gN6RDmp1/tvAS8BfxqtQ/ob8fMTMd757OXDNl3w2Qc63gVjfWLX9mkriw9FtmcI4WZ8vQP8H6i5djuZmPH1ztMb4QNy0NhO5PUOJzgbeFH2Mif0+r7fmdZPW1n8a+DHROQFESnQ0vavPOUxzYiIDEVL8xGRIfBvodmqXwF+KW72S8A/ejojXCgHje0rwH8QUfs/C2wlc/ppyknNBj4oe5kTeH0/kEzrDwqtPQTF/RKK3L4O/LWnPZ4F43sRRY2/CXwnjRE4B/xL4LX4evYpje9/Q83LGl0tfvmgsaGm5/8Ur/U14M+ckPH+L3E834qT+DnVUBYAAAB6SURBVFJn+78Wx/t94Bc+4LF+ATXNvwW8Gv9/6SRe30PG+sSu7WkG56mcyqkcS562G3Iqp3IqHxI5VRanciqnciw5VRanciqnciw5VRanciqnciw5VRanciqnciw5VRanciqnciw5VRanciqnciw5VRanciqnciz5/wALAj/Xp5FT4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d2c109f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[0])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The `detectMultiScale` function executes the classifier stored in `face_cascade` and takes the grayscale image as a parameter.  \n",
    "\n",
    "In the above code, `faces` is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as `x` and `y`) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as `w` and `h`) specify the width and height of the box.\n",
    "\n",
    "### Write a Human Face Detector\n",
    "\n",
    "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Human Face Detector\n",
    "\n",
    "__Question 1:__ Use the code cell below to test the performance of the `face_detector` function.  \n",
    "- What percentage of the first 100 images in `human_files` have a detected human face?  \n",
    "- What percentage of the first 100 images in `dog_files` have a detected human face? \n",
    "\n",
    "Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  You will see that our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays `human_files_short` and `dog_files_short`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n",
    "(You can print out your results and/or write your percentages in this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of humans in humans dataset: 98\n",
      "No of humans in dogs dataset: 17\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "human_files_short = human_files[:100]\n",
    "dog_files_short = dog_files[:100]\n",
    "count_h=0\n",
    "count_d=0\n",
    "for i in range(100):\n",
    "    res_human=face_detector(human_files_short[i])\n",
    "    res_dog=face_detector(dog_files_short[i])\n",
    "    if res_human==True:\n",
    "        count_h+=1\n",
    "    if res_dog==True:\n",
    "        count_d+=1\n",
    "    \n",
    "print(\"No of humans in humans dataset:\",count_h)\n",
    "print(\"No of humans in dogs dataset:\",count_d)\n",
    "    \n",
    "\n",
    "#-#-# Do NOT modify the code above this line. #-#-#\n",
    "\n",
    "## TODO: Test the performance of the face_detector algorithm \n",
    "## on the images in human_files_short and dog_files_short.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest the face detector from OpenCV as a potential way to detect human images in your algorithm, but you are free to explore other approaches, especially approaches that make use of deep learning :).  Please use the code cell below to design and test your own face detection algorithm.  If you decide to pursue this _optional_ task, report performance on `human_files_short` and `dog_files_short`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (Optional) \n",
    "### TODO: Test performance of anotherface detection algorithm.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a [pre-trained model](http://pytorch.org/docs/master/torchvision/models.html) to detect dogs in images.  \n",
    "\n",
    "### Obtain Pre-trained VGG-16 Model\n",
    "\n",
    "The code cell below downloads the VGG-16 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# define VGG16 model\n",
    "VGG16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an image, this pre-trained VGG-16 model returns a prediction (derived from the 1000 possible categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Making Predictions with a Pre-trained Model\n",
    "\n",
    "In the next code cell, you will write a function that accepts a path to an image (such as `'dogImages/train/001.Affenpinscher/Affenpinscher_00001.jpg'`) as input and returns the index corresponding to the ImageNet class that is predicted by the pre-trained VGG-16 model.  The output should always be an integer between 0 and 999, inclusive.\n",
    "\n",
    "Before writing the function, make sure that you take the time to learn  how to appropriately pre-process tensors for pre-trained models in the [PyTorch documentation](http://pytorch.org/docs/stable/torchvision/models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "def VGG16_predict(img_path):\n",
    "    '''\n",
    "    Use pre-trained VGG-16 model to obtain index corresponding to \n",
    "    predicted ImageNet class for image at specified path\n",
    "    \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        Index corresponding to VGG-16 model's prediction\n",
    "\n",
    "    '''\n",
    "    data_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n",
    "                                      transforms.ToTensor()])\n",
    "    im=Image.open(img_path)\n",
    "    img=data_transform(im)\n",
    "\n",
    "    vgg16=models.vgg16(pretrained=True)\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.requires_grad=False\n",
    "    \n",
    "    output=vgg16(img.unsqueeze_(0))\n",
    "    #print(output)\n",
    "    #print(output.shape)\n",
    "    \n",
    "    index=np.argmax(output.detach().numpy(),axis=1)\n",
    "    #print(index)\n",
    "    ## TODO: Complete the function.\n",
    "    ## Load and pre-process an image from the given img_path\n",
    "    ## Return the *index* of the predicted class for that image\n",
    "    \n",
    "    return index # predicted class index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Write a Dog Detector\n",
    "\n",
    "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained VGG-16 model, we need only check if the pre-trained model predicts an index between 151 and 268 (inclusive).\n",
    "\n",
    "Use these ideas to complete the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    ## TODO: Complete the function.\n",
    "    dog_pred=VGG16_predict(img_path)\n",
    "    if dog_pred>=151 and dog_pred<=268:\n",
    "        res=True\n",
    "    else:\n",
    "        res=False\n",
    "    \n",
    "    return res # true/false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Dog Detector\n",
    "\n",
    "__Question 2:__ Use the code cell below to test the performance of your `dog_detector` function.  \n",
    "- What percentage of the images in `human_files_short` have a detected dog?  \n",
    "- What percentage of the images in `dog_files_short` have a detected dog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dogs in humans dataset: 0\n",
      "No of dogs in dogs dataset: 71\n"
     ]
    }
   ],
   "source": [
    "### TODO: Test the performance of the dog_detector function\n",
    "### on the images in human_files_short and dog_files_short.\n",
    "count_h=0\n",
    "count_d=0\n",
    "for i in range(100):\n",
    "    res_human=dog_detector(human_files_short[i])\n",
    "    res_dog=dog_detector(dog_files_short[i])\n",
    "    if res_human==True:\n",
    "        count_h+=1\n",
    "    if res_dog==True:\n",
    "        count_d+=1\n",
    "    \n",
    "print(\"No of dogs in humans dataset:\",count_h)\n",
    "print(\"No of dogs in dogs dataset:\",count_d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest VGG-16 as a potential network to detect dog images in your algorithm, but you are free to explore other pre-trained networks (such as [Inception-v3](http://pytorch.org/docs/master/torchvision/models.html#inception-v3), [ResNet-50](http://pytorch.org/docs/master/torchvision/models.html#id3), etc).  Please use the code cell below to test other pre-trained PyTorch models.  If you decide to pursue this _optional_ task, report performance on `human_files_short` and `dog_files_short`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (Optional) \n",
    "### TODO: Report the performance of another pre-trained network.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_!), and you must attain a test accuracy of at least 10%.  In Step 4 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.\n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have trouble distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  \n",
    "\n",
    "Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun!\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dog_images/train`, `dog_images/valid`, and `dog_images/test`, respectively).  You may find [this documentation on custom datasets](http://pytorch.org/docs/stable/torchvision/datasets.html) to be a useful resource.  If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](http://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d3cc73358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0))) \n",
    "    #print(\"showing\")\n",
    "    #print(img.shape)# convert from Tensor image\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "transform=transforms.Compose([transforms.Resize([256,256]),transforms.RandomCrop(224),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])])\n",
    "batch_size=10\n",
    "\n",
    "train_data=datasets.ImageFolder(root=\"/data/dog_images/train\",transform=transform)\n",
    "test_data=datasets.ImageFolder(root=\"/data/dog_images/test\",transform=transform)\n",
    "valid_data=datasets.ImageFolder(root=\"/data/dog_images/valid\",transform=transform)\n",
    "\n",
    "data_transfer={'train':train_data,'valid':valid_data,'test':test_data}\n",
    "train_list=np.arange(0,len(train_data))\n",
    "#print(train_list)\n",
    "test_list=np.arange(0,len(test_data))\n",
    "valid_list=np.arange(0,len(valid_data))\n",
    "train_sampler = SubsetRandomSampler(train_list)\n",
    "valid_sampler = SubsetRandomSampler(valid_list)\n",
    "test_sampler=SubsetRandomSampler(test_list)\n",
    "\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_data,batch_size=batch_size,sampler=train_sampler)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid_data,batch_size=batch_size,sampler=valid_sampler)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_data,batch_size=batch_size,sampler=test_sampler)\n",
    "\n",
    "#print(len(train_loader))\n",
    "#print(train_loader)\n",
    "#for data,target in train_loader:\n",
    "#    print(\"data:\",len(data))\n",
    "#    print(\"Target:\",len(target))\n",
    "dataiter=iter(train_loader)\n",
    "images,labels=dataiter.next()\n",
    "#print(\"Load images:\",images[0].shape)\n",
    "images=images.numpy()\n",
    "fig=plt.figure(figsize=(25,4))\n",
    "'''for idx in np.arange(10):\n",
    "    ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
    "    #p=images[0][idx]\n",
    "    imshow(images[idx])\n",
    "    #print(images[idx].shape)\n",
    "    #print(\"done moving next\")\n",
    "    #ax.set_title(labels[idx])'''\n",
    "loaders_scratch=dict()\n",
    "loaders_scratch['train']=train_loader\n",
    "loaders_scratch['valid']=valid_loader\n",
    "loaders_scratch['test']=test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Describe your chosen procedure for preprocessing the data. \n",
    "- How does your code resize the images (by cropping, stretching, etc)?  What size did you pick for the input tensor, and why?\n",
    "- Did you decide to augment the dataset?  If so, how (through translations, flips, rotations, etc)?  If not, why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  Use the template in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=50176, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        ## convolutional layer (sees 32x32x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 8x8x32 tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64 *28 * 28, 500)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, 133)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.size())\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.size())\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #print(x.size())\n",
    "        \n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 28* 28)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "print(model_scratch)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/stable/optim.html).  Save the chosen loss function as `criterion_scratch`, and the optimizer as `optimizer_scratch` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.SGD(model_scratch.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_scratch.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -29.32593822479248\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 3.0627918243408203\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: -1.581130027770996\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -4.10099983215332\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -3.8818788528442383\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 6.031198501586914\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: 1.4137554168701172\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -0.8062601089477539\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 3.912794589996338\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -2.015862464904785\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: 2.9169249534606934\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: -7.915499210357666\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 0.4860997200012207\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 6.31312370300293\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: -1.7980766296386719\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -8.603262901306152\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 2.420508861541748\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: -0.36988019943237305\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: 11.434202194213867\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -1.9474053382873535\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: -19.983408451080322\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: 9.562416076660156\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 6.872062683105469\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: 5.984683036804199\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -13.452739715576172\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 5.124111175537109\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 6.253247261047363\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: -8.825101852416992\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: 0.02552032470703125\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -8.954133987426758\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 24.16188359260559\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: -8.992005586624146\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: -10.604686737060547\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 8.006956577301025\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -1.1074280738830566\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 0.4689979553222656\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 4.339869022369385\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 0.5772209167480469\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: -1.0639595985412598\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 5.293798446655273\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -6.360080242156982\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -10.25707483291626\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 7.345647811889648\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -6.868531703948975\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: 8.432888984680176\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -9.189152717590332\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 6.002843379974365\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 0.15743494033813477\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -1.6077494621276855\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: 2.7280211448669434\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: 4.33943510055542\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 1.1102795600891113\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: -1.7385601997375488\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -16.44670009613037\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: 11.87563419342041\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 2.3857903480529785\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -4.803133010864258\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: 5.428752899169922\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -2.7848052978515625\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: 2.931489944458008\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: -5.042290687561035\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: 4.996612071990967\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 3.4667062759399414\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -6.378726959228516\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 8.45651626586914\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: -9.836339950561523\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: -8.896503448486328\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: 6.9261980056762695\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 5.437066555023193\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: 4.102609157562256\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: -5.543794631958008\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: 2.0025181770324707\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: -8.27418565750122\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 3.6946630477905273\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -3.980395793914795\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: 9.41735029220581\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: -3.5030174255371094\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: 7.219269275665283\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 5.066903829574585\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -13.167411088943481\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: -0.17796039581298828\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -3.8361501693725586\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: 6.04440450668335\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -5.028591156005859\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: -0.17577886581420898\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: 13.744103908538818\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -11.318633556365967\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -9.672255516052246\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: 15.320801734924316\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -4.104166030883789\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: -6.981351375579834\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 10.699679851531982\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -2.6851654052734375\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: 0.01691579818725586\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 0.5186772346496582\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: 1.9573283195495605\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 0.41043758392333984\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: 3.8742446899414062\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -7.817080020904541\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 4.650454521179199\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: -8.02520751953125\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 9.504752159118652\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -2.8174996376037598\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -10.33315658569336\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 15.370960235595703\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -1.5603327751159668\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: -14.88213062286377\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 1.3766098022460938\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: 10.805070400238037\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: -2.8892087936401367\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -7.810266017913818\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: 8.251922130584717\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: -0.29709815979003906\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -2.7513718605041504\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: 4.951732158660889\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -2.2969675064086914\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: -3.7201857566833496\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 0.24637222290039062\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: 9.717917442321777\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -8.023161888122559\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 4.72919225692749\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 2.6526308059692383\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: -2.146329879760742\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -4.456055164337158\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 4.483580589294434\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -4.236321449279785\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: -5.333387851715088\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: -3.8744163513183594\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: 6.174824237823486\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -3.419208526611328\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 4.3485283851623535\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: 0.0641489028930664\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 3.5001564025878906\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -2.418360710144043\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 3.954041004180908\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -0.7772254943847656\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -1.7597198486328125\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 3.889346122741699\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: -8.502755165100098\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: 10.599818229675293\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: -1.5395069122314453\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 1.500544548034668\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: -11.663718223571777\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 4.306068420410156\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -2.8760886192321777\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 4.117007255554199\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -7.943580150604248\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 14.54458236694336\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -12.653751373291016\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 9.099960327148438\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -6.53285026550293\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -2.491638660430908\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 7.803518772125244\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -2.8464794158935547\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: -7.704331874847412\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: 7.935318946838379\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: 4.564864635467529\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 0.7158637046813965\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: -0.6167244911193848\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -5.162973403930664\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: -5.203888416290283\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: 8.172097206115723\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -7.527430057525635\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: -0.6585144996643066\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: 5.791716575622559\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 0.3736710548400879\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 3.8414525985717773\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: -3.439788818359375\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: 0.0990915298461914\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: -3.319516181945801\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: 2.5115394592285156\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: -1.2741780281066895\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: 1.5247321128845215\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: 7.918188571929932\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: -7.641181945800781\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: -0.4899477958679199\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: 2.6184582710266113\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 1.2461376190185547\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -2.521183490753174\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: 7.274801731109619\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: -6.933531761169434\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -3.812689781188965\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 3.903634548187256\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: -5.716290473937988\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 4.526166915893555\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: -8.025650978088379\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 2.795991897583008\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: 11.185662746429443\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: -16.170294284820557\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: 5.258984565734863\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: 6.0303544998168945\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 1.8905925750732422\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: -4.467501640319824\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 10.366172790527344\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -16.4803409576416\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 17.183914184570312\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -14.740643501281738\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 4.435579776763916\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 1.6437983512878418\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -2.819955348968506\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: 2.2339367866516113\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: -2.7794647216796875\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -0.3767561912536621\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: 2.8165268898010254\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: -3.7847495079040527\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: 8.788743019104004\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: -8.182306289672852\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -5.621485710144043\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 6.936771869659424\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: -4.45178747177124\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 10.633533000946045\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -0.9411883354187012\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: 2.762627601623535\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: -3.583071231842041\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -2.393200397491455\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 3.5662055015563965\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 3.595266342163086\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -1.94014310836792\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -9.472050666809082\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: -1.1023449897766113\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 8.934481143951416\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -8.364760875701904\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -2.8468847274780273\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 9.4083833694458\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -11.19067907333374\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: 8.712155818939209\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: 8.907091617584229\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -12.889575958251953\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -0.05383729934692383\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 10.564746856689453\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -15.02387523651123\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 9.267210960388184\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 6.156065464019775\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -8.495771884918213\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: -0.3510570526123047\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -6.100494861602783\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: 5.90423583984375\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -2.16127872467041\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 4.572453498840332\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -6.279504299163818\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 5.481255054473877\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: -6.277015209197998\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -1.890864372253418\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: 1.627650260925293\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: 10.504653453826904\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 1.3199210166931152\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 2.0688438415527344\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: -11.503453254699707\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 8.253905773162842\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -7.709319591522217\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -0.6240463256835938\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 8.460605144500732\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -6.903860569000244\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -3.8335609436035156\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 14.786696434020996\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -4.886062145233154\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 4.010415077209473\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: -12.848923206329346\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 12.107462882995605\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -7.258343696594238\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 3.0762481689453125\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: 3.6320877075195312\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -13.188552856445312\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 9.63895559310913\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -10.305392742156982\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: 1.7275381088256836\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 1.4556074142456055\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 6.337227821350098\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 1.1150169372558594\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 11.900100708007812\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -18.20302963256836\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: -1.9904446601867676\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 2.341587543487549\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: 2.232365608215332\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: 5.722060203552246\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: -11.610832214355469\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 15.75183629989624\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: -13.556878566741943\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: 3.022751808166504\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: -0.20812034606933594\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -1.5093183517456055\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 9.295573234558105\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -2.303457260131836\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -4.633188247680664\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -2.246370315551758\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: 1.979823112487793\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -4.19907808303833\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: 3.110661506652832\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -4.588818550109863\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 9.859225749969482\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -8.061480522155762\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: 4.0961527824401855\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 4.769730567932129\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 0.21584272384643555\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: -10.080173015594482\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 5.140902996063232\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -5.268993377685547\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -2.699289321899414\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: 1.5293526649475098\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 12.582826614379883\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -3.316802978515625\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: 0.7252860069274902\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 8.990188837051392\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: -6.103156805038452\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -4.6010589599609375\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -3.977184295654297\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: 5.376913547515869\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 1.5980339050292969\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: -9.00289535522461\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -0.4118037223815918\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 4.322006702423096\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: -8.802142143249512\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 11.53038740158081\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: -4.761092662811279\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 3.4276199340820312\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: -5.388214588165283\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: 1.5825581550598145\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -5.901889801025391\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 4.427967071533203\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 6.07792854309082\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 1.6476631164550781\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -4.405708312988281\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -7.1196699142456055\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 4.727809429168701\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 0.7607388496398926\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 7.342202663421631\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -4.050791263580322\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 7.552242279052734\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: 9.514453411102295\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: -13.701646327972412\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: 6.8721699714660645\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: -9.401254653930664\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 0.7119488716125488\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -1.2106847763061523\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -0.9204220771789551\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: -0.5830740928649902\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 2.85247802734375\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: 7.0749592781066895\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: -2.599608898162842\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: -6.079535484313965\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: 0.23512840270996094\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -2.3707199096679688\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 4.225864410400391\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -6.914935111999512\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -9.794650077819824\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 18.482110500335693\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: -9.017477035522461\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: 0.8735990524291992\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: -0.08066177368164062\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -1.3472509384155273\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: 10.806944370269775\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -8.641932010650635\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 0.5082201957702637\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: -5.8704376220703125\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: 10.659995079040527\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: -5.457708835601807\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 2.9372406005859375\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -2.3486709594726562\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: 8.254053592681885\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -5.153658390045166\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 2.866945266723633\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -1.455245018005371\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -13.885462284088135\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 15.693914890289307\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: 9.171818494796753\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: -18.75348210334778\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: 2.6118087768554688\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 1.523573398590088\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: 8.946871757507324\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: -0.5370712280273438\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: 0.2642369270324707\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -4.872756004333496\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: -2.9445838928222656\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: 3.251626491546631\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: -8.191616535186768\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: 4.55601692199707\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -0.1601123809814453\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 1.4759135246276855\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: 0.8286237716674805\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: -6.865477561950684\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: 11.64710283279419\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: -1.0873699188232422\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -9.3544340133667\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 8.139851093292236\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -9.974281787872314\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: 11.500530242919922\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: -0.765070915222168\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -2.3506617546081543\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: -5.0791096687316895\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 6.178169250488281\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: -10.297470092773438\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: 4.259276390075684\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: 6.43864631652832\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 1.6206717491149902\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: -6.168696880340576\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -0.6564188003540039\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 2.0226550102233887\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -2.949533462524414\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 2.845578193664551\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 9.055376052856445\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -18.490259647369385\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: 9.054110050201416\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 0.37371158599853516\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -0.7279849052429199\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: 3.1911253929138184\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: 9.293389320373535\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: -5.777373313903809\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -8.485686779022217\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 3.050971031188965\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: 3.8036298751831055\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: -0.9348583221435547\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: 0.34775733947753906\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: -8.958392143249512\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: 3.63936185836792\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 9.122586250305176\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: -6.899693012237549\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -3.1357574462890625\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -1.9031834602355957\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 0.569913387298584\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: 8.233880996704102\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -10.716078281402588\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: 5.922291278839111\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: -1.376347541809082\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: -5.1367950439453125\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 4.215407371520996\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -2.42431640625\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 10.604565143585205\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -3.6855649948120117\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 2.799687385559082\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: -3.104405403137207\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -3.589141368865967\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: 4.198901653289795\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: 4.7217583656311035\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: -7.025783061981201\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: -10.331676006317139\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 13.970654010772705\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 0.8046722412109375\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -4.613149166107178\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: -1.5883207321166992\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: 2.8423023223876953\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: 7.872905731201172\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: -9.263308048248291\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -8.392531871795654\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: 16.030921936035156\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -8.64635944366455\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 5.508861541748047\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: 4.590108394622803\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: -9.64665174484253\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: 7.179784774780273\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: -5.030508041381836\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 4.450197219848633\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: -11.418991088867188\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: 3.7263917922973633\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -4.734477996826172\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 2.1434855461120605\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: 6.5486836433410645\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: -1.191728115081787\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: 0.23492097854614258\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: 7.327291965484619\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -18.0633807182312\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 12.61979341506958\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 5.760049819946289\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: -2.1973085403442383\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: -8.645591735839844\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -6.650087833404541\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 9.578390121459961\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: 0.5393481254577637\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -3.747565746307373\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 0.8204364776611328\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 3.829007148742676\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -7.8795647621154785\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 1.0467720031738281\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 4.26771879196167\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: 5.865869522094727\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: -8.861737251281738\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: 2.974522113800049\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 1.6282105445861816\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: -1.7967867851257324\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: 4.565134048461914\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -1.0460305213928223\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -2.0548439025878906\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -1.6603374481201172\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: -2.217552661895752\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -1.5241694450378418\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 2.6271462440490723\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: -3.48508358001709\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: 11.747195720672607\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: -2.379920482635498\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -8.291423320770264\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 2.6346349716186523\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: -5.230698585510254\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 3.2190299034118652\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -0.04814863204956055\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 3.048727512359619\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: 7.635657787322998\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -1.4899134635925293\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -1.0846567153930664\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: -6.949937343597412\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: 4.954862594604492\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -7.142424583435059\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -7.981109619140625\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 10.240254402160645\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: 10.004720687866211\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -9.639232158660889\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: -2.250397205352783\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: 8.991050720214844\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: -4.5301008224487305\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: 0.9587478637695312\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: 5.5547261238098145\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: -4.313607215881348\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: -5.951225757598877\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: 9.64935302734375\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -4.14517879486084\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: -5.258171558380127\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: 3.00825834274292\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -1.7846250534057617\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 5.299782752990723\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: -1.6740727424621582\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: -7.458004951477051\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 8.644592761993408\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: 8.101811408996582\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -10.778725147247314\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 1.4099526405334473\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: 8.480491638183594\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: -22.14054584503174\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: 16.862797737121582\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: 0.5643773078918457\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -7.529633045196533\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: 0.7181787490844727\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: -1.3273096084594727\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -0.988771915435791\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: -5.019443035125732\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 5.123462677001953\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: 8.221921920776367\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: -7.145259380340576\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: 3.2096505165100098\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 3.291611671447754\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -4.266977310180664\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -5.53178071975708\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: 10.873866081237793\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -16.047251224517822\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: 8.151779174804688\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 7.245533466339111\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -1.2842178344726562\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: -4.4017839431762695\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: 1.5848684310913086\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -2.360210418701172\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: 0.9897685050964355\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: -2.565596103668213\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: -11.605174541473389\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 21.033740043640137\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: -1.2916994094848633\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: -16.894898414611816\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 10.929887294769287\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: 2.510707378387451\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 6.377701759338379\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -6.0895586013793945\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: 2.5061869621276855\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -6.6681623458862305\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: -5.8164381980896\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 11.974127292633057\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -4.186458587646484\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: 4.60205078125\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: 2.004857063293457\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: -9.457676410675049\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: 5.320498943328857\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: 6.650087833404541\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: -12.503805160522461\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 0.8716797828674316\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 12.755191326141357\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -14.144885540008545\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: 2.4634933471679688\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 2.8106236457824707\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: -3.1961870193481445\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -3.5349345207214355\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 10.042378902435303\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: 5.578606128692627\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -12.095844745635986\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 2.897040843963623\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: 2.6671481132507324\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -3.5748672485351562\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: -0.822601318359375\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: -1.1557698249816895\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: 4.254612922668457\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: 4.099318981170654\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 0.3654026985168457\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: -5.876724720001221\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 5.771336555480957\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: -15.228753089904785\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 6.934611797332764\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: -0.10329008102416992\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 1.0108757019042969\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -0.36921262741088867\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 9.308655261993408\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: 1.7170476913452148\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -4.815495014190674\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: -11.088004112243652\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 4.255783557891846\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 7.989301681518555\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: -5.104665756225586\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: -4.9277472496032715\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 7.460525035858154\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 2.752695083618164\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -9.18027639389038\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: -2.0690560340881348\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 1.9477486610412598\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 9.0797758102417\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: -3.347156047821045\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: -3.700990676879883\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: -3.6178183555603027\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: 1.756279468536377\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: 6.23760461807251\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: -3.1912946701049805\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: -7.939589023590088\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 10.680487155914307\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: -7.69273042678833\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 7.158000469207764\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: -2.3997902870178223\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: 7.44396448135376\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -4.239685535430908\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -9.93492603302002\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: 8.519372940063477\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -0.68389892578125\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -2.041049003601074\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 2.229785919189453\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 1.2890839576721191\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 4.590935707092285\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -1.2700414657592773\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: -4.996349811553955\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: 2.5272274017333984\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -3.552250862121582\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 11.160507202148438\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -8.261430263519287\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -1.9844317436218262\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -3.0698442459106445\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -0.7404541969299316\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 2.889411449432373\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 5.3401947021484375\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -4.189248085021973\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -15.48715591430664\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 15.580391883850098\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -13.00053596496582\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: 7.177362442016602\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: 7.867672443389893\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: -4.325778484344482\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: 1.2875652313232422\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: -5.506587028503418\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 9.235527515411377\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -3.869788646697998\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: -9.063758850097656\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: 9.42667007446289\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: 0.7189369201660156\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 0.04962444305419922\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: -0.4350852966308594\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: 5.184197425842285\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: -4.678478240966797\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: -0.37600040435791016\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: 8.02741289138794\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: -9.91438627243042\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 0.5105781555175781\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: 5.226104259490967\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -9.669530391693115\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 2.1470189094543457\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: 0.16845464706420898\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 3.877427577972412\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -7.217605113983154\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: -3.8012266159057617\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 7.90724515914917\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -39.46110486984253\n",
      "batch_going: 1\n",
      "change in Valid loss: -35.0010347366333\n",
      "batch_going: 2\n",
      "change in Valid loss: -31.058382987976074\n",
      "batch_going: 3\n",
      "change in Valid loss: -37.671494483947754\n",
      "batch_going: 4\n",
      "change in Valid loss: -36.43510818481445\n",
      "batch_going: 5\n",
      "change in Valid loss: -40.810813903808594\n",
      "batch_going: 6\n",
      "change in Valid loss: -39.47944164276123\n",
      "batch_going: 7\n",
      "change in Valid loss: -40.6235408782959\n",
      "batch_going: 8\n",
      "change in Valid loss: -36.45481586456299\n",
      "batch_going: 9\n",
      "change in Valid loss: -38.710525035858154\n",
      "batch_going: 10\n",
      "change in Valid loss: -37.378997802734375\n",
      "batch_going: 11\n",
      "change in Valid loss: -38.43283414840698\n",
      "batch_going: 12\n",
      "change in Valid loss: -44.55106258392334\n",
      "batch_going: 13\n",
      "change in Valid loss: -44.01033878326416\n",
      "batch_going: 14\n",
      "change in Valid loss: -38.98595094680786\n",
      "batch_going: 15\n",
      "change in Valid loss: -50.50567150115967\n",
      "batch_going: 16\n",
      "change in Valid loss: -39.87900495529175\n",
      "batch_going: 17\n",
      "change in Valid loss: -31.935067176818848\n",
      "batch_going: 18\n",
      "change in Valid loss: -37.8493070602417\n",
      "batch_going: 19\n",
      "change in Valid loss: -35.434348583221436\n",
      "batch_going: 20\n",
      "change in Valid loss: -51.054110527038574\n",
      "batch_going: 21\n",
      "change in Valid loss: -38.95359754562378\n",
      "batch_going: 22\n",
      "change in Valid loss: -47.385878562927246\n",
      "batch_going: 23\n",
      "change in Valid loss: -37.522053718566895\n",
      "batch_going: 24\n",
      "change in Valid loss: -45.01142501831055\n",
      "batch_going: 25\n",
      "change in Valid loss: -39.78864669799805\n",
      "batch_going: 26\n",
      "change in Valid loss: -40.46751022338867\n",
      "batch_going: 27\n",
      "change in Valid loss: -46.88694953918457\n",
      "batch_going: 28\n",
      "change in Valid loss: -46.52998447418213\n",
      "batch_going: 29\n",
      "change in Valid loss: -39.1768217086792\n",
      "batch_going: 30\n",
      "change in Valid loss: -41.86379432678223\n",
      "batch_going: 31\n",
      "change in Valid loss: -44.7440242767334\n",
      "batch_going: 32\n",
      "change in Valid loss: -48.90308380126953\n",
      "batch_going: 33\n",
      "change in Valid loss: -42.610883712768555\n",
      "batch_going: 34\n",
      "change in Valid loss: -34.647254943847656\n",
      "batch_going: 35\n",
      "change in Valid loss: -46.26620292663574\n",
      "batch_going: 36\n",
      "change in Valid loss: -44.75208759307861\n",
      "batch_going: 37\n",
      "change in Valid loss: -43.8784122467041\n",
      "batch_going: 38\n",
      "change in Valid loss: -44.01638984680176\n",
      "batch_going: 39\n",
      "change in Valid loss: -41.08231544494629\n",
      "batch_going: 40\n",
      "change in Valid loss: -40.171566009521484\n",
      "batch_going: 41\n",
      "change in Valid loss: -48.78641128540039\n",
      "batch_going: 42\n",
      "change in Valid loss: -44.319772720336914\n",
      "batch_going: 43\n",
      "change in Valid loss: -42.88245677947998\n",
      "batch_going: 44\n",
      "change in Valid loss: -40.52990913391113\n",
      "batch_going: 45\n",
      "change in Valid loss: -31.98176860809326\n",
      "batch_going: 46\n",
      "change in Valid loss: -46.58383369445801\n",
      "batch_going: 47\n",
      "change in Valid loss: -36.451783180236816\n",
      "batch_going: 48\n",
      "change in Valid loss: -41.268205642700195\n",
      "batch_going: 49\n",
      "change in Valid loss: -34.16620969772339\n",
      "batch_going: 50\n",
      "change in Valid loss: -39.724838733673096\n",
      "batch_going: 51\n",
      "change in Valid loss: -35.275206565856934\n",
      "batch_going: 52\n",
      "change in Valid loss: -44.24363613128662\n",
      "batch_going: 53\n",
      "change in Valid loss: -37.33015060424805\n",
      "batch_going: 54\n",
      "change in Valid loss: -36.53141736984253\n",
      "batch_going: 55\n",
      "change in Valid loss: -36.92290544509888\n",
      "batch_going: 56\n",
      "change in Valid loss: -45.13415336608887\n",
      "batch_going: 57\n",
      "change in Valid loss: -43.79916191101074\n",
      "batch_going: 58\n",
      "change in Valid loss: -44.24064636230469\n",
      "batch_going: 59\n",
      "change in Valid loss: -37.52136945724487\n",
      "batch_going: 60\n",
      "change in Valid loss: -33.6225962638855\n",
      "batch_going: 61\n",
      "change in Valid loss: -38.58236789703369\n",
      "batch_going: 62\n",
      "change in Valid loss: -30.43606996536255\n",
      "batch_going: 63\n",
      "change in Valid loss: -45.704007148742676\n",
      "batch_going: 64\n",
      "change in Valid loss: -43.411827087402344\n",
      "batch_going: 65\n",
      "change in Valid loss: -40.189313888549805\n",
      "batch_going: 66\n",
      "change in Valid loss: -36.23220920562744\n",
      "batch_going: 67\n",
      "change in Valid loss: -44.20304298400879\n",
      "batch_going: 68\n",
      "change in Valid loss: -43.6788272857666\n",
      "batch_going: 69\n",
      "change in Valid loss: -39.56898212432861\n",
      "batch_going: 70\n",
      "change in Valid loss: -39.74330425262451\n",
      "batch_going: 71\n",
      "change in Valid loss: -41.87521934509277\n",
      "batch_going: 72\n",
      "change in Valid loss: -46.597609519958496\n",
      "batch_going: 73\n",
      "change in Valid loss: -40.85216522216797\n",
      "batch_going: 74\n",
      "change in Valid loss: -33.54422092437744\n",
      "batch_going: 75\n",
      "change in Valid loss: -37.04169511795044\n",
      "batch_going: 76\n",
      "change in Valid loss: -36.56064987182617\n",
      "batch_going: 77\n",
      "change in Valid loss: -39.449896812438965\n",
      "batch_going: 78\n",
      "change in Valid loss: -39.53864336013794\n",
      "batch_going: 79\n",
      "change in Valid loss: -55.09284973144531\n",
      "batch_going: 80\n",
      "change in Valid loss: -42.90522575378418\n",
      "batch_going: 81\n",
      "change in Valid loss: -46.477389335632324\n",
      "batch_going: 82\n",
      "change in Valid loss: -38.9812707901001\n",
      "batch_going: 83\n",
      "change in Valid loss: -14.85379934310913\n",
      "Epoch: 1 \tTraining Loss: 31.458466 \tValidation Loss: 40.443082\n",
      "Validation loss decreased (inf --> 40.443082).  Saving model ...\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -24.063701629638672\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: -6.3175201416015625\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 7.70251989364624\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: 1.1051726341247559\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -11.467123031616211\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 5.496699810028076\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -1.9865083694458008\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: 1.267075538635254\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 7.563903331756592\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -14.79426622390747\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: 17.450342178344727\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: -10.99905252456665\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 1.817333698272705\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 3.0878043174743652\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: -19.02736186981201\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: 9.762988090515137\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 1.2468171119689941\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 2.880241870880127\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -3.746941089630127\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: 3.193936347961426\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 5.812664031982422\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: 0.5177402496337891\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: -5.717411041259766\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: 14.100902080535889\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -20.9708309173584\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 9.553720951080322\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 1.3421082496643066\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: -0.2620410919189453\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -2.943401336669922\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -4.814891815185547\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 4.249601364135742\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 7.3777031898498535\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: -10.73075532913208\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 8.976786136627197\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -1.9080424308776855\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: -10.040361881256104\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 3.945629596710205\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: -0.820765495300293\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 5.013790130615234\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: -3.299088478088379\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: 5.614206790924072\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -5.280485153198242\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 6.241142749786377\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: 7.11780309677124\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -15.555129051208496\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: 10.396583080291748\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: -16.573920249938965\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 0.6914448738098145\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: 12.29668378829956\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -17.018136978149414\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: 12.50058650970459\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: -1.5459179878234863\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 1.8241643905639648\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -6.743049621582031\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: 6.774260997772217\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 2.138550281524658\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: 0.1881861686706543\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -7.486422061920166\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: 5.484602451324463\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: 4.758617877960205\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: -0.9392356872558594\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -12.796740531921387\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 12.111735343933105\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -8.929710388183594\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 1.2795329093933105\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 3.08657169342041\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 9.712779521942139\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -2.537505626678467\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: -8.840293884277344\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: 9.043068885803223\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: -7.129526138305664\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -4.6353983879089355\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 7.8163909912109375\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: -14.388377666473389\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: 15.9775710105896\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -3.8120627403259277\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 1.954789161682129\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: 5.868799686431885\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: -4.709818363189697\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -14.88290786743164\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 20.296802520751953\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -8.551092147827148\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: 6.699838638305664\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -9.060091972351074\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 5.163631439208984\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -4.471843242645264\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -0.3011345863342285\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -4.563755989074707\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: 0.9400367736816406\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: 3.0213356018066406\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 11.852505207061768\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: -12.528064250946045\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: 1.3415336608886719\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: 1.2587857246398926\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 6.384177207946777\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: 1.6125297546386719\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: -8.45177412033081\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: 3.363964557647705\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -7.3346781730651855\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 10.57657241821289\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: -16.380553245544434\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 4.297780990600586\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: 11.470873355865479\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -9.201858043670654\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 11.02165937423706\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -8.896896839141846\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 4.31826114654541\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: -5.4834747314453125\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: 17.223387956619263\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: -8.055692911148071\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -1.2891149520874023\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -8.196492195129395\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 12.780964374542236\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -5.6058502197265625\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -5.3920722007751465\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: 1.2965202331542969\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 2.619466781616211\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: -3.2959938049316406\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: 11.053335666656494\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -20.11423349380493\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 16.334543228149414\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: -4.267871379852295\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 5.471096038818359\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -17.11615800857544\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 10.470798015594482\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -4.717843532562256\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: -0.9439563751220703\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 9.994897842407227\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -8.635034561157227\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: 8.134348392486572\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: -4.8982834815979\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -3.1061458587646484\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 8.219077587127686\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -3.809976577758789\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: -2.9297804832458496\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -6.2459564208984375\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -0.6301665306091309\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 14.335582256317139\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 1.8599867820739746\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -13.18911075592041\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 8.396604061126709\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: -6.033220291137695\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 5.916919708251953\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: -6.211214065551758\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: 7.768335342407227\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: -3.710205554962158\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: 2.9247379302978516\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: -1.6419672966003418\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -0.8322572708129883\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: -0.8329963684082031\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: 3.811466693878174\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -0.7302761077880859\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 0.5012726783752441\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: 2.5168848037719727\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: -6.085991859436035\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -5.958950519561768\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: 6.7761969566345215\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: -7.916274070739746\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 10.964250564575195\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -5.704739093780518\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 2.2478747367858887\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -6.167469024658203\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: 12.03434705734253\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: -10.6032395362854\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: 7.4593353271484375\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: -4.397895336151123\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 3.420083522796631\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: -3.3878159523010254\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: 8.133604526519775\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 0.7993149757385254\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -11.097550392150879\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 10.090625286102295\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -10.020198822021484\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -4.468288421630859\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 9.545860290527344\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 0.3756380081176758\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -3.1876420974731445\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 3.8787412643432617\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -5.920913219451904\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -0.03617048263549805\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 4.0033674240112305\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: 0.344088077545166\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: -2.5678563117980957\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 7.17099666595459\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: -6.195979118347168\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 10.179376602172852\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: -12.373294830322266\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -0.38782358169555664\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 4.115276336669922\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -9.454708099365234\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: 3.9731621742248535\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 2.8707075119018555\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 4.240024089813232\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 2.1053099632263184\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -3.730301856994629\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 3.717465400695801\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -5.6369733810424805\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 0.1267862319946289\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 0.7563114166259766\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: 8.057799339294434\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -10.178577899932861\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 1.2500739097595215\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -11.83112621307373\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: 9.142093658447266\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 1.289527416229248\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: 8.492658138275146\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: -6.562466621398926\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: 8.595888614654541\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: -8.716762065887451\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 1.4120078086853027\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 0.9024810791015625\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -11.303098201751709\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: 4.157459735870361\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 9.065501689910889\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -5.3694868087768555\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 7.091724872589111\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: -15.066463947296143\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: 12.993266582489014\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -6.186707019805908\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 5.657749176025391\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 0.07937431335449219\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -4.116067886352539\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -5.786318778991699\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 6.651215553283691\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -0.31226634979248047\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: 6.050858497619629\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -0.7301521301269531\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -4.845144748687744\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: 3.787996768951416\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: -1.740877628326416\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: 7.192566394805908\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: -14.935894012451172\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 9.608683586120605\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -12.47365951538086\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 10.138964653015137\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: 5.616121292114258\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -8.498976230621338\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -6.816775798797607\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: -5.083012580871582\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: 6.796305179595947\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 2.4631333351135254\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 0.643613338470459\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: 9.841663837432861\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -5.621230602264404\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -1.8703603744506836\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 4.3981099128723145\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: -3.046426773071289\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 3.3955788612365723\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: -3.311774730682373\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -16.02034091949463\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: 21.610186100006104\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: -4.50871467590332\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -9.07871961593628\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -0.26471376419067383\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 8.242995738983154\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: 3.7294673919677734\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 4.72883939743042\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: -9.78109359741211\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 1.0176348686218262\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: 1.1890459060668945\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 2.441112995147705\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -7.082159519195557\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: 3.3370041847229004\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 10.491160154342651\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -2.0938456058502197\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -9.74146842956543\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: -1.2165117263793945\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: -3.068554401397705\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 1.9713997840881348\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 5.220010280609131\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: 2.7193737030029297\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: -4.225265979766846\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 0.3532123565673828\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -8.370323181152344\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: 7.717316150665283\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: -0.22806167602539062\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 6.183416843414307\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: -2.205953598022461\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: 6.915370225906372\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: -6.264983415603638\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -0.6503987312316895\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: -6.380646228790283\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -3.3308029174804688\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: 1.9710779190063477\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: 3.2222819328308105\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -3.3446812629699707\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: 7.28792667388916\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -6.469438076019287\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -5.775909423828125\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 12.28055715560913\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -17.917537689208984\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: 16.906042098999023\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: -2.737133502960205\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 0.8344602584838867\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 3.8755083084106445\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 1.3501524925231934\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -3.661491870880127\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -8.609943389892578\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: 13.047044277191162\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: -11.642560958862305\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: 15.541989803314209\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -18.79430055618286\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 11.54306411743164\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 7.70931601524353\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -3.9799344539642334\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -16.74530029296875\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: 6.901066303253174\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: -1.4702296257019043\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 2.6045799255371094\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: 7.757463455200195\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: -12.275686264038086\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 4.397170543670654\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 3.0908632278442383\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 3.4968972206115723\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: -0.4808187484741211\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: -3.884763717651367\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -0.5025982856750488\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: 2.157738208770752\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: -2.9544878005981445\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 1.5118741989135742\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: -2.1987533569335938\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: 1.9182014465332031\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -7.512524127960205\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 7.046816349029541\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 2.857522964477539\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: -1.2111568450927734\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -3.7148094177246094\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: -5.681445598602295\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: 7.671074867248535\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 5.487654209136963\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: 1.221470832824707\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: -4.626944065093994\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 2.125372886657715\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -0.0494074821472168\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -2.5252246856689453\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: -5.3151655197143555\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 2.065150737762451\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: 9.120700359344482\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: -5.66286563873291\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 3.348066806793213\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: -7.823848724365234\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: 4.619126319885254\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 7.976527214050293\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -4.3297529220581055\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -11.949987411499023\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: -5.606191158294678\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 12.54143238067627\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: 1.9526863098144531\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 0.9650230407714844\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -1.5010738372802734\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -7.9875922203063965\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -2.9446029663085938\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 7.95940637588501\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 2.510190010070801\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: -10.554723739624023\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: 7.392909526824951\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 7.153027057647705\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: 1.3856697082519531\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -4.988985061645508\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -1.396036148071289\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 1.151895523071289\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -0.11669635772705078\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -4.791409969329834\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 4.342169761657715\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: -5.536556243896484\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: 7.8546953201293945\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: 3.6527180671691895\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: -3.1655454635620117\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: 0.43624401092529297\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 1.4715170860290527\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -15.555946826934814\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: 11.753573417663574\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 6.458292007446289\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -10.139524936676025\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: 4.995462894439697\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: -3.705568313598633\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: 0.5585670471191406\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 5.191161632537842\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: -18.82986307144165\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 14.299707412719727\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: -10.33513069152832\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 12.320291996002197\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: 1.5277647972106934\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 6.13893985748291\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -9.873874187469482\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: 3.989856243133545\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: -7.382602691650391\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -6.0262250900268555\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 8.789961338043213\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 8.268654346466064\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: -7.10413932800293\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -6.060998439788818\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: 1.0031676292419434\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 5.8103179931640625\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: 3.211946487426758\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: 1.0037779808044434\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: -3.206651210784912\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -8.674407005310059\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 1.4052343368530273\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 9.585919380187988\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -8.663818836212158\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: 9.1233491897583\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: -0.3659224510192871\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: 0.09500503540039062\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -3.967134952545166\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -7.795822620391846\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 16.559429168701172\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -10.60840129852295\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 3.656148910522461\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -3.6525988578796387\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 7.7625274658203125\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -8.151371479034424\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 0.7451343536376953\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -2.5878334045410156\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: -1.171865463256836\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: 2.5649452209472656\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: 4.512841701507568\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -4.221603870391846\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 3.8547754287719727\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -5.65340518951416\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: 7.71240234375\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: -8.954358100891113\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 18.149287700653076\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: -12.27893590927124\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: -1.6624641418457031\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -4.1237688064575195\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 6.115555763244629\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: 1.1542892456054688\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: -4.337759017944336\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: -1.30324125289917\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: 0.9508466720581055\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: -0.2893519401550293\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: 11.064670085906982\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: -3.3356642723083496\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: 0.9161615371704102\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: -6.08494758605957\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: -1.3264274597167969\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: 5.825109481811523\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: -7.263906002044678\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: 2.9492688179016113\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -0.07122039794921875\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 4.315896034240723\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: 1.9382190704345703\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: -11.702659130096436\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: 5.326979160308838\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 3.101348876953125\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: -8.661470413208008\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 10.269694328308105\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -1.9518017768859863\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: -12.790427207946777\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 17.649681568145752\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: -3.878509998321533\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -2.9410910606384277\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: 3.950817584991455\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 4.5551300048828125\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: 2.4305343627929688\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: -10.384056568145752\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: 3.6188173294067383\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: -17.792482376098633\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: 7.528853416442871\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 2.3098373413085938\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: -4.642438888549805\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 8.704891204833984\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 3.229093551635742\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -5.034646987915039\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 2.227487564086914\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: 1.509084701538086\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -10.065546035766602\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 1.1834144592285156\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 8.379900455474854\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -0.02123117446899414\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: -6.779675483703613\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 8.83908748626709\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -12.208404541015625\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: -0.2050924301147461\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: 10.16505241394043\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: -4.738774299621582\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 4.457592964172363\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: -5.4856085777282715\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: 2.926766872406006\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: 5.687201023101807\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -11.823201179504395\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: 12.089905738830566\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -6.035313606262207\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 7.168304920196533\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 1.1728978157043457\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: -16.19931936264038\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 9.036591053009033\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -3.593935966491699\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 0.3502964973449707\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: 10.888891220092773\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: -4.844615459442139\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -2.123751640319824\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 4.472520351409912\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: -5.0421833992004395\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -0.21169424057006836\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -7.460665702819824\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 4.905898571014404\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: 7.228186130523682\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -4.75651741027832\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -2.952899932861328\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 4.854185581207275\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -1.0680747032165527\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: 3.811347484588623\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: -5.428621768951416\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -7.350935935974121\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: 11.125349998474121\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -10.857000350952148\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: 6.499879360198975\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: -6.297945976257324\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: 10.49670934677124\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: -6.036500930786133\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -6.056671142578125\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: 5.125076770782471\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: 7.510221004486084\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -1.1607861518859863\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: -9.711549282073975\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: 7.184267044067383\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: -8.397595882415771\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 6.930427551269531\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -2.8900527954101562\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -0.22939682006835938\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 2.783195972442627\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -3.6234402656555176\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: -1.5053701400756836\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: 1.9025945663452148\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: 11.669929027557373\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -16.784636974334717\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: 6.341583728790283\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 9.368445873260498\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -1.6212725639343262\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: -1.8467473983764648\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: -3.5853052139282227\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: 7.9203081130981445\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: -1.5003204345703125\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: 0.8202266693115234\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: -6.343626976013184\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: 2.824385166168213\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -11.071653366088867\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: 5.087268352508545\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -3.390927314758301\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: 7.716999053955078\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 4.4100236892700195\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -8.625984191894531\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: -3.484072685241699\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: 3.935878276824951\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: 0.9027695655822754\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: 5.305135250091553\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: 3.0072760581970215\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: -0.3182554244995117\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: -2.8584718704223633\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: 4.040093421936035\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: -13.109817504882812\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 5.247592926025391\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -3.117830753326416\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 7.909090518951416\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -7.197146415710449\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: -3.591899871826172\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: 11.1250901222229\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: -11.917130947113037\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 7.748878002166748\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -3.2483339309692383\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: 4.714398384094238\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -9.654507637023926\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 8.416974544525146\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: 5.393979549407959\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -5.237643718719482\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: -14.904537200927734\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 12.359848022460938\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 4.647467136383057\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -4.563686847686768\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: -0.3329181671142578\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 3.204469680786133\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: -3.197782039642334\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: 1.3322997093200684\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 1.4351797103881836\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: 0.5248451232910156\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -4.2891693115234375\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 0.2931642532348633\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: 3.990640640258789\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -2.0351457595825195\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 3.964419364929199\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: -1.5908193588256836\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: 4.511904716491699\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -6.334221363067627\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 4.275057315826416\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 0.1469588279724121\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: -10.573041439056396\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: 4.241704940795898\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: -4.525976181030273\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: -0.8000397682189941\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 7.178928852081299\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -0.4718208312988281\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: -11.40228271484375\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: 14.764049053192139\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -6.3140153884887695\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: 4.9648261070251465\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: -5.7399797439575195\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 1.3936424255371094\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: 4.012577533721924\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: -4.9105048179626465\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: -1.572425365447998\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 9.38138723373413\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: 0.3658485412597656\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: -13.169736862182617\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 9.050517082214355\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: -1.7709088325500488\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: 8.490233421325684\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: 0.5194807052612305\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: -11.693098545074463\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -2.434532642364502\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: 6.670112609863281\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 4.620726108551025\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: -13.775465488433838\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 13.382675647735596\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: -6.670989990234375\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 8.131742477416992\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: -1.574866771697998\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -2.6615548133850098\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -4.320328235626221\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: 2.7730393409729004\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -7.745208740234375\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -0.05829811096191406\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: 20.392205715179443\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: -20.555131435394287\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: -4.919075965881348\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 8.502750396728516\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: 1.3565444946289062\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 8.315904140472412\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -8.90007495880127\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -3.995480537414551\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 5.070168972015381\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -10.007505416870117\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: 13.747432231903076\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -4.690859317779541\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -2.1456146240234375\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 0.2324533462524414\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: -2.326080799102783\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: 7.888979911804199\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: 3.524339199066162\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: -5.9796881675720215\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -0.36611080169677734\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -2.7691054344177246\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: 13.277604579925537\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: -6.466233730316162\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -3.784651756286621\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 1.6330599784851074\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: -1.4604830741882324\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: 1.6365551948547363\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: -4.884438514709473\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: 12.674229145050049\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -5.414209365844727\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: -11.883659362792969\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 3.880026340484619\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: 8.886311054229736\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 0.011830329895019531\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: -8.551976680755615\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: 1.2566018104553223\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: -0.7820725440979004\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: -4.3511271476745605\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: 15.247950553894043\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: 0.5210351943969727\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: -1.6053056716918945\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -11.446235179901123\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 5.7894110679626465\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -7.366623878479004\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 4.435908794403076\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 1.3964605331420898\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -47.40211486816406\n",
      "batch_going: 1\n",
      "change in Valid loss: -32.83350467681885\n",
      "batch_going: 2\n",
      "change in Valid loss: -37.682881355285645\n",
      "batch_going: 3\n",
      "change in Valid loss: -41.23570442199707\n",
      "batch_going: 4\n",
      "change in Valid loss: -38.47940921783447\n",
      "batch_going: 5\n",
      "change in Valid loss: -34.81881618499756\n",
      "batch_going: 6\n",
      "change in Valid loss: -44.357614517211914\n",
      "batch_going: 7\n",
      "change in Valid loss: -35.11489391326904\n",
      "batch_going: 8\n",
      "change in Valid loss: -49.87104892730713\n",
      "batch_going: 9\n",
      "change in Valid loss: -48.44787120819092\n",
      "batch_going: 10\n",
      "change in Valid loss: -43.04484844207764\n",
      "batch_going: 11\n",
      "change in Valid loss: -39.74796772003174\n",
      "batch_going: 12\n",
      "change in Valid loss: -54.69604969024658\n",
      "batch_going: 13\n",
      "change in Valid loss: -44.18323993682861\n",
      "batch_going: 14\n",
      "change in Valid loss: -44.86269950866699\n",
      "batch_going: 15\n",
      "change in Valid loss: -37.72632598876953\n",
      "batch_going: 16\n",
      "change in Valid loss: -34.768898487091064\n",
      "batch_going: 17\n",
      "change in Valid loss: -34.563775062561035\n",
      "batch_going: 18\n",
      "change in Valid loss: -38.862056732177734\n",
      "batch_going: 19\n",
      "change in Valid loss: -41.90786361694336\n",
      "batch_going: 20\n",
      "change in Valid loss: -40.58650016784668\n",
      "batch_going: 21\n",
      "change in Valid loss: -42.304725646972656\n",
      "batch_going: 22\n",
      "change in Valid loss: -39.799556732177734\n",
      "batch_going: 23\n",
      "change in Valid loss: -39.049460887908936\n",
      "batch_going: 24\n",
      "change in Valid loss: -47.23527908325195\n",
      "batch_going: 25\n",
      "change in Valid loss: -51.99251651763916\n",
      "batch_going: 26\n",
      "change in Valid loss: -42.42283344268799\n",
      "batch_going: 27\n",
      "change in Valid loss: -40.80584526062012\n",
      "batch_going: 28\n",
      "change in Valid loss: -43.99737358093262\n",
      "batch_going: 29\n",
      "change in Valid loss: -35.91806411743164\n",
      "batch_going: 30\n",
      "change in Valid loss: -31.984286308288574\n",
      "batch_going: 31\n",
      "change in Valid loss: -37.389512062072754\n",
      "batch_going: 32\n",
      "change in Valid loss: -41.46254539489746\n",
      "batch_going: 33\n",
      "change in Valid loss: -39.459426403045654\n",
      "batch_going: 34\n",
      "change in Valid loss: -51.567254066467285\n",
      "batch_going: 35\n",
      "change in Valid loss: -41.31686210632324\n",
      "batch_going: 36\n",
      "change in Valid loss: -34.226956367492676\n",
      "batch_going: 37\n",
      "change in Valid loss: -51.29854202270508\n",
      "batch_going: 38\n",
      "change in Valid loss: -33.30772399902344\n",
      "batch_going: 39\n",
      "change in Valid loss: -45.62840938568115\n",
      "batch_going: 40\n",
      "change in Valid loss: -46.51580810546875\n",
      "batch_going: 41\n",
      "change in Valid loss: -43.35028648376465\n",
      "batch_going: 42\n",
      "change in Valid loss: -41.46527290344238\n",
      "batch_going: 43\n",
      "change in Valid loss: -43.99674415588379\n",
      "batch_going: 44\n",
      "change in Valid loss: -38.772971630096436\n",
      "batch_going: 45\n",
      "change in Valid loss: -43.16296100616455\n",
      "batch_going: 46\n",
      "change in Valid loss: -40.56907653808594\n",
      "batch_going: 47\n",
      "change in Valid loss: -47.15953826904297\n",
      "batch_going: 48\n",
      "change in Valid loss: -40.657033920288086\n",
      "batch_going: 49\n",
      "change in Valid loss: -44.2840576171875\n",
      "batch_going: 50\n",
      "change in Valid loss: -35.56076765060425\n",
      "batch_going: 51\n",
      "change in Valid loss: -40.06722450256348\n",
      "batch_going: 52\n",
      "change in Valid loss: -47.60956287384033\n",
      "batch_going: 53\n",
      "change in Valid loss: -37.47642993927002\n",
      "batch_going: 54\n",
      "change in Valid loss: -40.54502010345459\n",
      "batch_going: 55\n",
      "change in Valid loss: -43.13767910003662\n",
      "batch_going: 56\n",
      "change in Valid loss: -44.543166160583496\n",
      "batch_going: 57\n",
      "change in Valid loss: -45.44834613800049\n",
      "batch_going: 58\n",
      "change in Valid loss: -37.78740406036377\n",
      "batch_going: 59\n",
      "change in Valid loss: -36.83912992477417\n",
      "batch_going: 60\n",
      "change in Valid loss: -47.6677942276001\n",
      "batch_going: 61\n",
      "change in Valid loss: -39.39539670944214\n",
      "batch_going: 62\n",
      "change in Valid loss: -44.73029136657715\n",
      "batch_going: 63\n",
      "change in Valid loss: -45.2605676651001\n",
      "batch_going: 64\n",
      "change in Valid loss: -27.53824234008789\n",
      "batch_going: 65\n",
      "change in Valid loss: -35.800182819366455\n",
      "batch_going: 66\n",
      "change in Valid loss: -36.02257490158081\n",
      "batch_going: 67\n",
      "change in Valid loss: -45.19223690032959\n",
      "batch_going: 68\n",
      "change in Valid loss: -49.017791748046875\n",
      "batch_going: 69\n",
      "change in Valid loss: -45.49036979675293\n",
      "batch_going: 70\n",
      "change in Valid loss: -38.33603620529175\n",
      "batch_going: 71\n",
      "change in Valid loss: -44.141340255737305\n",
      "batch_going: 72\n",
      "change in Valid loss: -42.42362976074219\n",
      "batch_going: 73\n",
      "change in Valid loss: -40.627384185791016\n",
      "batch_going: 74\n",
      "change in Valid loss: -42.42722511291504\n",
      "batch_going: 75\n",
      "change in Valid loss: -34.36323881149292\n",
      "batch_going: 76\n",
      "change in Valid loss: -40.15244960784912\n",
      "batch_going: 77\n",
      "change in Valid loss: -51.00884437561035\n",
      "batch_going: 78\n",
      "change in Valid loss: -42.45223045349121\n",
      "batch_going: 79\n",
      "change in Valid loss: -30.241737365722656\n",
      "batch_going: 80\n",
      "change in Valid loss: -44.54236030578613\n",
      "batch_going: 81\n",
      "change in Valid loss: -29.029295444488525\n",
      "batch_going: 82\n",
      "change in Valid loss: -43.14819812774658\n",
      "batch_going: 83\n",
      "change in Valid loss: -20.476670265197754\n",
      "Epoch: 2 \tTraining Loss: 29.964374 \tValidation Loss: 41.128522\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -24.296958446502686\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: -1.4691519737243652\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 5.309438705444336\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -6.902761459350586\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -7.0990705490112305\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 10.63244342803955\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: 2.235405445098877\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -9.29863452911377\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 15.501426458358765\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -8.940979242324829\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -2.242906093597412\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 0.9184789657592773\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: -3.163771629333496\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 2.30790376663208\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 2.5673365592956543\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: 6.825318336486816\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 0.9455001354217529\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: -9.897438287734985\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: 3.1746578216552734\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -3.569927215576172\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: -5.121424198150635\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -1.5136337280273438\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 13.508524894714355\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -1.97831392288208\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -14.539906978607178\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 16.800975799560547\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: -7.526593208312988\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 0.6558394432067871\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -4.244604110717773\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -1.3144183158874512\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 9.37122106552124\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: -10.761914253234863\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 3.6670947074890137\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: -2.5725317001342773\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: 8.297998905181885\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: -2.9505038261413574\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 2.5990962982177734\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: -0.4532933235168457\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 5.775084495544434\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: -3.207695484161377\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -6.499543190002441\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -3.7777233123779297\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 4.6790337562561035\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: 0.36663055419921875\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: 4.89882230758667\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -1.1544227600097656\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: -12.209994792938232\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 3.907184600830078\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: 4.439606666564941\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -2.9606199264526367\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -3.34261417388916\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 0.7055997848510742\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 10.268678665161133\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -4.798600673675537\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: 2.5229620933532715\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 7.190158367156982\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -1.5772056579589844\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -7.045700550079346\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -7.608761787414551\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: 9.616522789001465\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: -14.661328792572021\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: 13.361372947692871\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 3.491532802581787\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -4.243860244750977\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 0.5678176879882812\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 2.681407928466797\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: -3.6748600006103516\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -5.232610702514648\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: -2.5817251205444336\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -4.670097827911377\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 6.459853649139404\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: 0.5261349678039551\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 1.34413480758667\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 0.27904510498046875\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: 6.665482521057129\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -3.469359874725342\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 3.8604235649108887\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: 8.288747072219849\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: -13.91734004020691\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: 6.571331024169922\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: -14.564311504364014\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: 15.301554203033447\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -0.7358694076538086\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -9.57592487335205\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 0.22762775421142578\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: 10.367319583892822\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: 3.974175453186035\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -9.835484027862549\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: 3.0452322959899902\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -5.987656116485596\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 6.652050018310547\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: -5.857362747192383\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: 8.996708393096924\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -3.037405014038086\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: -11.192009449005127\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: 15.568852424621582\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: -14.201397895812988\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: 10.82909345626831\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -4.456522464752197\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 0.3823065757751465\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 0.7237434387207031\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 5.157468318939209\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -0.8133935928344727\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -3.6029958724975586\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: -11.717362403869629\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: 6.110789775848389\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 7.998456954956055\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: -5.382473468780518\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -3.1334948539733887\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 7.45741605758667\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: 6.891969442367554\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -9.717670679092407\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: -1.3989782333374023\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: 3.3487510681152344\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -1.455674171447754\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -1.6047430038452148\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 4.88743782043457\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: -5.593762397766113\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: 2.847905158996582\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: 0.46173095703125\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: -7.412922382354736\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 3.785083293914795\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 8.371009826660156\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -14.6433687210083\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 5.508432388305664\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -1.411449909210205\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 2.8426218032836914\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 7.899322509765625\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -0.25232553482055664\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -7.324931621551514\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 8.824284076690674\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -10.683188438415527\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 4.7863078117370605\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -7.888355255126953\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: -0.6642913818359375\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: 9.547851085662842\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -5.142784118652344\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 3.9522814750671387\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: -0.5150961875915527\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -4.432635307312012\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 9.064714908599854\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: -1.49550199508667\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: -3.719797134399414\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 7.5945258140563965\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -14.548020362854004\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 7.78367280960083\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -5.656144618988037\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 3.254070281982422\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: 1.4990639686584473\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: -4.115631580352783\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: 8.906962871551514\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -17.92116641998291\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 20.98618745803833\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -15.343525409698486\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: -1.4670491218566895\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: 10.808155536651611\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -2.677435874938965\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 0.7881903648376465\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 3.9406180381774902\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -3.51564884185791\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: -0.03636598587036133\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -7.058827877044678\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -7.467808723449707\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 13.906242847442627\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -17.70237684249878\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 27.75214672088623\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: -17.243874073028564\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 3.4649157524108887\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: 4.334812164306641\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 0.31749725341796875\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -7.646887302398682\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 6.726953983306885\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -1.0087203979492188\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: 0.9747695922851562\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 2.7209043502807617\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 3.150148391723633\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -8.688380718231201\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: -1.0117268562316895\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: 16.118885278701782\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -20.685898065567017\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 12.561664581298828\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -1.8718886375427246\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 1.0705971717834473\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: -14.46502685546875\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 0.5942440032958984\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 4.120113849639893\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 10.842006206512451\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -1.0202240943908691\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: -7.679314613342285\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: 3.844292163848877\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -0.5538678169250488\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 4.433388710021973\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: -2.6049041748046875\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 2.4386143684387207\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -1.674351692199707\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: -0.28464794158935547\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -9.99490737915039\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 11.714997291564941\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: -12.093756198883057\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: 18.652687072753906\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -4.616663455963135\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: -3.0139565467834473\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: 3.540163040161133\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -16.744401454925537\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 15.813672542572021\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -4.875199794769287\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: -8.822989463806152\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: 14.098849296569824\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: -3.565535545349121\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: -1.1391210556030273\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: -2.4681568145751953\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: 2.6068925857543945\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -4.252464771270752\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 8.25117826461792\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -7.1701860427856445\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 11.322637796401978\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: -18.04005742073059\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: 11.598167419433594\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -8.417363166809082\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 3.5462570190429688\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: -5.095207691192627\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: 6.708405017852783\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -3.876330852508545\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: -0.013036727905273438\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: 2.4578022956848145\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -2.826213836669922\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: 6.1478424072265625\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -3.839278221130371\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -0.5667996406555176\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 3.1130456924438477\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: 8.38441252708435\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: -18.11527371406555\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 9.365878105163574\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -3.8624000549316406\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 1.8506932258605957\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -6.331937313079834\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: 13.675081729888916\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -5.6378960609436035\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: -1.0490775108337402\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: 0.7933497428894043\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: -3.985910415649414\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 2.7939796447753906\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -8.5406494140625\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: 8.554277420043945\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: 2.5991106033325195\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 5.372767448425293\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 2.481173276901245\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 2.871429920196533\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: -19.51039433479309\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: 12.809922695159912\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -2.3713183403015137\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 2.0980095863342285\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -8.46458911895752\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: 1.538844108581543\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: -7.457621097564697\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: 12.160377502441406\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: -1.0541439056396484\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 0.8365535736083984\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: -7.647609710693359\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: 13.466681241989136\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: -1.8311798572540283\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -10.893676280975342\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: 4.107706546783447\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: -8.083808422088623\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: 9.005718231201172\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: 4.058139324188232\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: -9.98058557510376\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 2.1201300621032715\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 8.060190677642822\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: -13.399598598480225\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: 3.6565756797790527\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 8.283593654632568\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: -7.699007987976074\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: 9.294459819793701\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -6.185455322265625\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: -9.160773754119873\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 14.395442008972168\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: -7.0992350578308105\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -0.5941081047058105\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 3.2925963401794434\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: 3.3277463912963867\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: -8.883681297302246\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: 6.295952796936035\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -0.1603555679321289\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: 12.04195261001587\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -13.240735530853271\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -5.5770063400268555\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: 2.097330093383789\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: 5.676939487457275\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: -7.702758312225342\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: 17.110328674316406\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -11.671395301818848\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 1.5045642852783203\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: -11.47104263305664\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 13.847579956054688\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: -0.074462890625\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -1.1000251770019531\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: 2.0241141319274902\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -2.0023560523986816\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 5.0687360763549805\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -4.166529178619385\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: 6.365725994110107\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: -11.91232681274414\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 4.023163318634033\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -7.564256191253662\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: 3.3809757232666016\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -1.1025285720825195\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: -0.45521974563598633\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 4.22257661819458\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -2.9411840438842773\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 11.163277626037598\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: -10.395359992980957\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 1.223745346069336\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 2.181832790374756\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 0.23890972137451172\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 4.180850982666016\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -4.063959121704102\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: 0.5333495140075684\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 2.01218843460083\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: -11.467812061309814\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 13.119544982910156\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -1.085357666015625\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -4.247992038726807\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 0.9105420112609863\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: -2.0925188064575195\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 5.182011127471924\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: 2.6108312606811523\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: -6.268332004547119\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: 1.8195843696594238\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: -2.5850796699523926\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -4.084129333496094\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 8.213286399841309\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 2.5467514991760254\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -13.601229190826416\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: 5.541930198669434\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: 2.039303779602051\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 3.849003314971924\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: -6.454148292541504\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: 0.5439090728759766\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: -0.058481693267822266\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: -1.4235877990722656\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: 13.120518922805786\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: -2.0475971698760986\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -7.296123504638672\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -3.233180046081543\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: -5.536448955535889\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 14.999475479125977\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -8.528525829315186\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 7.335159778594971\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -10.721144676208496\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: 12.184276580810547\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -13.762924671173096\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 3.431074619293213\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: -1.3770055770874023\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: 4.355428218841553\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: -2.352018356323242\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 6.40688419342041\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -3.1858015060424805\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -7.077903747558594\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: 8.475303649902344\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: -11.9047212600708\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: 7.418529987335205\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -0.22725343704223633\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: -4.452033042907715\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: 6.269383430480957\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: 1.7024636268615723\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: 5.354607105255127\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 0.979914665222168\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: -9.036307334899902\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 10.074942111968994\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -7.55704402923584\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: 4.528903961181641\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: -10.21618366241455\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: 8.621482849121094\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: -3.159503936767578\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: 2.9691672325134277\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -14.925148487091064\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 0.13401031494140625\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: 5.4528045654296875\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 11.125566959381104\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: -11.85159683227539\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 1.3922429084777832\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -2.9021859169006348\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 3.3111977577209473\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: 3.9917993545532227\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: 1.6446971893310547\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: -3.4385180473327637\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: 8.983228206634521\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: -3.8264918327331543\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 3.788135051727295\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: -9.332342147827148\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: 4.4072699546813965\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -8.769078254699707\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 5.980889797210693\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: 4.938631057739258\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: 0.831146240234375\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: -3.8083338737487793\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -6.027216911315918\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 9.83210563659668\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 2.541186809539795\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -0.5249810218811035\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -12.548205852508545\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 4.9350666999816895\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -14.248785972595215\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: 21.03867530822754\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -0.34937620162963867\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 5.917139053344727\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -3.048391342163086\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: -4.787027835845947\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -7.647500038146973\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 1.2090539932250977\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -0.4556918144226074\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 0.03459453582763672\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: 6.024301052093506\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: -11.287970542907715\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: 0.17181873321533203\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -1.6118192672729492\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: 0.1619863510131836\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 12.455439567565918\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -6.868257522583008\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: 9.852545261383057\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: -8.00365686416626\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 1.0677599906921387\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 7.606678009033203\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 0.1002645492553711\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -8.081920146942139\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 0.03320932388305664\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: 6.210031509399414\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: -10.316612720489502\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: 6.521933078765869\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: 6.997120380401611\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: -12.669143676757812\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: -0.3377103805541992\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: 8.584198951721191\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: -9.15794849395752\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: -2.757549285888672\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 20.086987018585205\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -17.76395082473755\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: -3.2158517837524414\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: 7.7913641929626465\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: 7.479655742645264\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: -0.4602384567260742\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -11.47726058959961\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: 9.697651863098145\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: 0.887143611907959\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: -0.17163515090942383\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: 0.122833251953125\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 4.255707263946533\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -0.8412289619445801\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: -20.382332801818848\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 11.867232322692871\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 6.44831657409668\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -15.445520877838135\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: 12.193448543548584\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 0.711214542388916\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: -2.894885540008545\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: 5.185103416442871\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: -5.165596008300781\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: 4.241139888763428\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -8.7062668800354\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 5.679531097412109\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: -5.242061614990234\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 11.926424503326416\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: -14.283013343811035\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -0.15851736068725586\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 8.232202529907227\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: -2.205677032470703\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -0.0600433349609375\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: -3.947739601135254\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 8.50999116897583\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -9.903144836425781\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: -10.603582859039307\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 17.735419273376465\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -1.5032672882080078\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: -0.1631307601928711\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -4.058933258056641\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 4.3399810791015625\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 8.348376750946045\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: -5.385196208953857\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: 5.878779888153076\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -13.022456169128418\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -3.045063018798828\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: 5.275731086730957\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: 1.8732476234436035\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 1.7217135429382324\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 0.43582916259765625\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: 1.9752740859985352\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: -3.967716693878174\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -12.193365097045898\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 16.099348068237305\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: -6.166620254516602\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 2.508871555328369\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -6.406097412109375\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 5.855932235717773\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: 8.479350805282593\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: 1.728200912475586\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -18.167542219161987\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: -1.0610651969909668\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: 14.992880821228027\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -5.684022903442383\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -1.7340850830078125\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: -5.286312103271484\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: 10.592575073242188\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -2.051208019256592\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: -1.2718868255615234\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -5.0362324714660645\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: 8.706045150756836\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -6.10774040222168\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: -2.2911643981933594\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: -1.28737211227417\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: 8.497254848480225\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: 3.7361669540405273\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -16.59506320953369\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: 11.7488694190979\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -2.1680355072021484\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -7.465648651123047\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 3.3643031120300293\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: 4.792108535766602\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: -4.447534084320068\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 7.897663116455078\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -8.186602592468262\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -0.7206416130065918\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 12.177414894104004\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -8.224868774414062\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 3.2590341567993164\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -2.156989574432373\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: 8.4144926071167\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -9.43814754486084\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: -12.359654903411865\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 4.179215431213379\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: 10.43187141418457\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: -1.4706778526306152\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: -1.7277789115905762\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: -8.85129451751709\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 14.592597484588623\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: -9.489943981170654\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 4.453935623168945\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -1.7013835906982422\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -2.318897247314453\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: -0.632176399230957\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: 0.9278416633605957\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -4.047372341156006\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 5.337574481964111\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: 8.046185970306396\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: 1.1357617378234863\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: -2.262256145477295\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -6.032085418701172\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -1.0413837432861328\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: 2.817986011505127\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 2.848057746887207\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: -16.402018070220947\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: 18.83305549621582\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: -15.138566493988037\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 8.12105417251587\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -3.3605170249938965\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 1.908423900604248\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: 7.909862995147705\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: -10.711274147033691\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: 6.143345832824707\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: -3.7157821655273438\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 7.383978366851807\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: 0.5028700828552246\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: -1.4492583274841309\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -6.810972690582275\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 3.34108829498291\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: 0.860755443572998\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -3.2989120483398438\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: 13.268071413040161\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: -5.38091778755188\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 0.3625369071960449\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: 0.2775883674621582\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: 0.28100013732910156\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: -12.34816312789917\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: 6.549642086029053\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: 2.393198013305664\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: -2.9207897186279297\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: 1.7583465576171875\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -2.9778146743774414\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 6.2366533279418945\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -5.917882919311523\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: 4.566187858581543\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: -8.012228012084961\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: -2.0421934127807617\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: 3.4937047958374023\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: 0.6675028800964355\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 7.8672099113464355\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 4.775853157043457\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: -13.611373901367188\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: 4.646289348602295\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: -1.1884665489196777\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: 3.9266324043273926\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 0.7125258445739746\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -5.101189613342285\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 0.3116273880004883\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: 0.6647348403930664\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: 3.396749496459961\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: -0.7728052139282227\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 1.157999038696289\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: -10.397467613220215\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: -7.6923418045043945\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 5.925860404968262\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 7.859671115875244\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 1.1556720733642578\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: 1.4543771743774414\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: -7.465808391571045\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 0.7587838172912598\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 9.946963787078857\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: -7.407636642456055\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: 0.334014892578125\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: -1.7404556274414062\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: 6.109499931335449\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: -6.612071990966797\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 4.774947166442871\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 1.5588617324829102\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: -3.6037611961364746\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 5.801236629486084\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 6.0018885135650635\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: -6.427842378616333\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -0.9304523468017578\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: 2.759237289428711\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -8.347246646881104\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -10.086114406585693\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: 13.109264373779297\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: 3.9577865600585938\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: -7.312870025634766\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 5.635044574737549\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: -0.9295392036437988\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -6.222975254058838\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 7.967019081115723\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -9.978570938110352\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: 10.144898891448975\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: -9.993705749511719\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: 13.461852073669434\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -5.29266357421875\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -5.347912311553955\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: 5.656309127807617\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 8.300247192382812\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: -4.52409029006958\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -1.7297172546386719\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -15.898265838623047\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 8.246927261352539\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: 9.191479682922363\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -0.21886110305786133\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -0.7529425621032715\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: -9.565637111663818\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: 0.5654740333557129\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 9.427342414855957\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: -8.237221240997314\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: 3.054337501525879\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: -2.435321807861328\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -4.326844215393066\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: 0.9967803955078125\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 4.345979690551758\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 10.022001266479492\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -6.99122428894043\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: -2.62723445892334\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 5.235145092010498\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -6.954810619354248\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 2.3743414878845215\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 2.922334671020508\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -6.259026527404785\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: 6.694495677947998\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: -17.206270694732666\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: 18.276631832122803\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: -7.925922870635986\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -1.06658935546875\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 6.8489766120910645\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 2.5811147689819336\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -43.729214668273926\n",
      "batch_going: 1\n",
      "change in Valid loss: -33.718693256378174\n",
      "batch_going: 2\n",
      "change in Valid loss: -45.79001426696777\n",
      "batch_going: 3\n",
      "change in Valid loss: -43.2559871673584\n",
      "batch_going: 4\n",
      "change in Valid loss: -38.19595813751221\n",
      "batch_going: 5\n",
      "change in Valid loss: -49.49563503265381\n",
      "batch_going: 6\n",
      "change in Valid loss: -40.42550086975098\n",
      "batch_going: 7\n",
      "change in Valid loss: -40.34435272216797\n",
      "batch_going: 8\n",
      "change in Valid loss: -38.77243518829346\n",
      "batch_going: 9\n",
      "change in Valid loss: -56.339454650878906\n",
      "batch_going: 10\n",
      "change in Valid loss: -45.89454174041748\n",
      "batch_going: 11\n",
      "change in Valid loss: -42.03445911407471\n",
      "batch_going: 12\n",
      "change in Valid loss: -33.99676561355591\n",
      "batch_going: 13\n",
      "change in Valid loss: -37.77035474777222\n",
      "batch_going: 14\n",
      "change in Valid loss: -40.44781684875488\n",
      "batch_going: 15\n",
      "change in Valid loss: -34.12567615509033\n",
      "batch_going: 16\n",
      "change in Valid loss: -36.03257417678833\n",
      "batch_going: 17\n",
      "change in Valid loss: -50.23540496826172\n",
      "batch_going: 18\n",
      "change in Valid loss: -39.74480390548706\n",
      "batch_going: 19\n",
      "change in Valid loss: -31.676979064941406\n",
      "batch_going: 20\n",
      "change in Valid loss: -37.49460220336914\n",
      "batch_going: 21\n",
      "change in Valid loss: -44.24242973327637\n",
      "batch_going: 22\n",
      "change in Valid loss: -42.63178825378418\n",
      "batch_going: 23\n",
      "change in Valid loss: -38.817763328552246\n",
      "batch_going: 24\n",
      "change in Valid loss: -36.879756450653076\n",
      "batch_going: 25\n",
      "change in Valid loss: -41.593942642211914\n",
      "batch_going: 26\n",
      "change in Valid loss: -42.978620529174805\n",
      "batch_going: 27\n",
      "change in Valid loss: -48.09441566467285\n",
      "batch_going: 28\n",
      "change in Valid loss: -46.552414894104004\n",
      "batch_going: 29\n",
      "change in Valid loss: -44.08156394958496\n",
      "batch_going: 30\n",
      "change in Valid loss: -43.82248878479004\n",
      "batch_going: 31\n",
      "change in Valid loss: -43.17108631134033\n",
      "batch_going: 32\n",
      "change in Valid loss: -54.06431198120117\n",
      "batch_going: 33\n",
      "change in Valid loss: -47.65594482421875\n",
      "batch_going: 34\n",
      "change in Valid loss: -41.7757511138916\n",
      "batch_going: 35\n",
      "change in Valid loss: -38.979103565216064\n",
      "batch_going: 36\n",
      "change in Valid loss: -36.74546718597412\n",
      "batch_going: 37\n",
      "change in Valid loss: -47.21579551696777\n",
      "batch_going: 38\n",
      "change in Valid loss: -36.85602903366089\n",
      "batch_going: 39\n",
      "change in Valid loss: -28.378310203552246\n",
      "batch_going: 40\n",
      "change in Valid loss: -49.23024654388428\n",
      "batch_going: 41\n",
      "change in Valid loss: -50.912208557128906\n",
      "batch_going: 42\n",
      "change in Valid loss: -50.57260036468506\n",
      "batch_going: 43\n",
      "change in Valid loss: -42.35822677612305\n",
      "batch_going: 44\n",
      "change in Valid loss: -45.789618492126465\n",
      "batch_going: 45\n",
      "change in Valid loss: -46.15252494812012\n",
      "batch_going: 46\n",
      "change in Valid loss: -30.301966667175293\n",
      "batch_going: 47\n",
      "change in Valid loss: -32.595112323760986\n",
      "batch_going: 48\n",
      "change in Valid loss: -44.10234451293945\n",
      "batch_going: 49\n",
      "change in Valid loss: -50.066118240356445\n",
      "batch_going: 50\n",
      "change in Valid loss: -40.70021152496338\n",
      "batch_going: 51\n",
      "change in Valid loss: -56.141929626464844\n",
      "batch_going: 52\n",
      "change in Valid loss: -36.00175142288208\n",
      "batch_going: 53\n",
      "change in Valid loss: -52.88249969482422\n",
      "batch_going: 54\n",
      "change in Valid loss: -56.5838623046875\n",
      "batch_going: 55\n",
      "change in Valid loss: -52.912468910217285\n",
      "batch_going: 56\n",
      "change in Valid loss: -39.91561412811279\n",
      "batch_going: 57\n",
      "change in Valid loss: -50.50626277923584\n",
      "batch_going: 58\n",
      "change in Valid loss: -34.19342517852783\n",
      "batch_going: 59\n",
      "change in Valid loss: -55.30412197113037\n",
      "batch_going: 60\n",
      "change in Valid loss: -52.747979164123535\n",
      "batch_going: 61\n",
      "change in Valid loss: -45.425472259521484\n",
      "batch_going: 62\n",
      "change in Valid loss: -41.38495922088623\n",
      "batch_going: 63\n",
      "change in Valid loss: -49.48441505432129\n",
      "batch_going: 64\n",
      "change in Valid loss: -42.31076717376709\n",
      "batch_going: 65\n",
      "change in Valid loss: -42.285165786743164\n",
      "batch_going: 66\n",
      "change in Valid loss: -56.55231475830078\n",
      "batch_going: 67\n",
      "change in Valid loss: -36.23755693435669\n",
      "batch_going: 68\n",
      "change in Valid loss: -50.32809257507324\n",
      "batch_going: 69\n",
      "change in Valid loss: -40.66594123840332\n",
      "batch_going: 70\n",
      "change in Valid loss: -35.974907875061035\n",
      "batch_going: 71\n",
      "change in Valid loss: -34.62188005447388\n",
      "batch_going: 72\n",
      "change in Valid loss: -53.0259370803833\n",
      "batch_going: 73\n",
      "change in Valid loss: -49.05223369598389\n",
      "batch_going: 74\n",
      "change in Valid loss: -38.272507190704346\n",
      "batch_going: 75\n",
      "change in Valid loss: -35.75810194015503\n",
      "batch_going: 76\n",
      "change in Valid loss: -37.26902723312378\n",
      "batch_going: 77\n",
      "change in Valid loss: -47.65599250793457\n",
      "batch_going: 78\n",
      "change in Valid loss: -42.90513038635254\n",
      "batch_going: 79\n",
      "change in Valid loss: -45.57986259460449\n",
      "batch_going: 80\n",
      "change in Valid loss: -43.11622142791748\n",
      "batch_going: 81\n",
      "change in Valid loss: -48.598361015319824\n",
      "batch_going: 82\n",
      "change in Valid loss: -28.098206520080566\n",
      "batch_going: 83\n",
      "change in Valid loss: -19.07240867614746\n",
      "Epoch: 3 \tTraining Loss: 28.203802 \tValidation Loss: 42.829819\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -22.640206813812256\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: -5.202133655548096\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 5.213174819946289\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -2.6694345474243164\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: 6.052396297454834\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: -14.52744722366333\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: 9.610207080841064\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: 4.669742584228516\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: -0.9613037109375\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -4.399878978729248\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: 2.0901107788085938\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 3.282374143600464\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: -5.77628493309021\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 2.8011417388916016\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 7.2933220863342285\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -2.6047003269195557\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: -11.696637868881226\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 10.354211330413818\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: 1.5197181701660156\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -4.786677360534668\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: -3.3061647415161133\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: 0.3497767448425293\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 2.4665403366088867\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: 2.2579479217529297\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -6.1853766441345215\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 0.3556180000305176\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: -7.431139945983887\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 11.925604343414307\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: 1.5415692329406738\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -2.4518537521362305\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: -7.826282978057861\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: -5.024898052215576\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 13.144426345825195\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: -4.014408588409424\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -2.411208152770996\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 0.5060386657714844\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 7.740631103515625\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: -9.014272689819336\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 7.521467208862305\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 1.7014098167419434\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -4.948270320892334\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -5.041990280151367\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 5.665397644042969\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: 6.6457438468933105\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -10.233805179595947\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: 3.7133097648620605\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: -1.6342711448669434\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 9.343973398208618\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -10.181313753128052\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: 0.39432525634765625\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -0.05520820617675781\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: -2.255570888519287\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 1.2919807434082031\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: 12.954094409942627\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -15.348141193389893\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 7.888672351837158\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: 0.30265331268310547\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: 0.3043842315673828\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -3.7900257110595703\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -5.500459671020508\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 6.771879196166992\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: 2.2203469276428223\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: -6.097118854522705\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: 2.625706195831299\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: -2.873506546020508\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 8.556215763092041\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 1.4587903022766113\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -9.810190200805664\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: -9.92588996887207\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: 5.285747051239014\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 11.552293300628662\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -5.764145851135254\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 6.125805377960205\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: -12.366082668304443\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: 18.312325477600098\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -10.519170761108398\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 6.586310863494873\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -4.171617031097412\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: -4.695689678192139\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: 3.566291332244873\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 4.780620336532593\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: 0.3365969657897949\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: 0.0068247318267822266\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -3.8649964332580566\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 1.7589449882507324\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: 1.9645202159881592\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -4.553319215774536\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -1.1730384826660156\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -2.4741411209106445\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: 4.457032680511475\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 4.3994224071502686\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: -6.664856672286987\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -0.6771659851074219\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: 3.6575794219970703\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: -4.7184014320373535\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -10.343430042266846\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 15.664217472076416\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -2.011556625366211\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -0.9986114501953125\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 4.141302108764648\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: -4.043228626251221\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 8.233139514923096\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -8.468883037567139\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -4.629220962524414\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: -4.011361598968506\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: 2.1542787551879883\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 2.504560947418213\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: -0.8540725708007812\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: 5.300111770629883\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: -13.48597764968872\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: 3.9800000190734863\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: 8.161778450012207\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: -3.575625419616699\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: 10.234818458557129\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -1.1350822448730469\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -8.545851707458496\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 7.359910011291504\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: -12.392754554748535\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: 9.29081916809082\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -2.8056907653808594\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 1.4789104461669922\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: -10.566728115081787\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 17.83622980117798\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -3.6742591857910156\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: -0.9921693801879883\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -8.517923355102539\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 12.7076256275177\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: -3.3245980739593506\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: 7.895907163619995\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -14.21627163887024\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 4.2467474937438965\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: 0.03225088119506836\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: -5.464456081390381\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: 0.6685781478881836\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 10.512040853500366\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -0.8141171932220459\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -5.6098246574401855\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 0.2702808380126953\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 8.389052152633667\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -14.161654710769653\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 5.071074962615967\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: -15.357394218444824\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 15.676038265228271\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: -2.8862524032592773\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: 7.395808696746826\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: -2.6027798652648926\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -8.627068996429443\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 4.769270420074463\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -1.0875439643859863\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 13.190579414367676\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -15.801026821136475\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: 11.861776113510132\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: -7.698310613632202\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: 2.4657607078552246\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 0.8167243003845215\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -7.741680145263672\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: 4.203705787658691\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 2.4097681045532227\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 2.253291606903076\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -12.279455661773682\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 3.5213732719421387\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: 12.409660816192627\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -9.831035137176514\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 0.9625887870788574\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: 3.638145923614502\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 3.985651731491089\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: -8.38347315788269\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 3.167285919189453\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -3.12467098236084\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 1.3954734802246094\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -0.9367704391479492\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 14.077101945877075\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -7.284919023513794\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -6.3543701171875\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: -6.3611578941345215\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 7.72540807723999\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: 1.6653728485107422\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: -10.541620254516602\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: 15.86987018585205\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -7.751963138580322\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: -1.032397747039795\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: 8.948062658309937\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: -6.6091883182525635\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 2.8963541984558105\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: -9.95856761932373\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 9.039111137390137\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 3.913595676422119\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -4.0172505378723145\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 5.181639194488525\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -7.509770393371582\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: 11.953115463256836\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: -21.51273012161255\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 1.8520402908325195\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: -0.5278491973876953\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: 5.966396331787109\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: -6.086630821228027\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: 10.005185604095459\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 0.8560347557067871\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: -4.364585876464844\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -0.706932544708252\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: 1.4217805862426758\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 2.058889865875244\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: 7.012004852294922\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -7.660501003265381\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: -0.5942082405090332\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -6.121830940246582\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 12.74350643157959\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -0.05762815475463867\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: -13.298757076263428\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 13.008837699890137\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 0.08875250816345215\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -0.012969970703125\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -14.251717329025269\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 4.164638519287109\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: 9.911549091339111\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: -17.80491590499878\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 6.24467134475708\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: 3.33770751953125\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -4.864671230316162\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 11.174676418304443\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: -15.154979228973389\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: 22.79200792312622\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -8.682317733764648\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 6.30689263343811\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -5.63987135887146\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -7.034485340118408\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -1.3116908073425293\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -4.3988776206970215\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: 14.229037761688232\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: -1.3701319694519043\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -11.172435283660889\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 3.780958652496338\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 5.116481781005859\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -8.209280967712402\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 5.155892372131348\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -1.0498666763305664\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: 7.310547828674316\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -5.753393173217773\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 0.7657790184020996\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -1.3674449920654297\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 1.0363578796386719\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 4.075887203216553\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -3.397541046142578\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -2.8505873680114746\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -6.313681602478027\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 4.258067607879639\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 7.490088939666748\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 0.26361942291259766\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 4.003978967666626\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: 2.3706114292144775\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -16.418063640594482\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 8.953533172607422\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -2.4726414680480957\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: 4.580106735229492\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 2.561614513397217\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: 0.3467583656311035\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: -7.289109230041504\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: -0.06780862808227539\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 2.4578309059143066\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -5.704212188720703\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 2.3348426818847656\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: 0.10078668594360352\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: 1.6326665878295898\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 6.044636964797974\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -18.497344255447388\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: 13.646011352539062\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 1.1434364318847656\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 2.927379608154297\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: -0.8795619010925293\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 0.8896350860595703\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -5.2132248878479\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: -2.3686957359313965\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: -3.740108013153076\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -5.360310077667236\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: 4.234306812286377\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 9.773554801940918\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: -2.243986129760742\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 0.9050941467285156\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: 1.8147039413452148\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: -6.89532995223999\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -0.30414819717407227\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 0.5191373825073242\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: 6.085515022277832\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -3.8347291946411133\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: 7.9564690589904785\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -9.114313125610352\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -1.3466835021972656\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: 10.001922845840454\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -3.3113253116607666\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 4.967083930969238\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -8.029201030731201\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -4.906880855560303\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 3.5982656478881836\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 4.693772792816162\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: -3.462996482849121\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 2.187685966491699\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -2.449653148651123\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -3.294041156768799\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -7.692692279815674\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 1.1065220832824707\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: 14.599735736846924\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -9.243505001068115\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 11.928578615188599\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: -7.922748327255249\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -14.295713901519775\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: 23.18002939224243\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -3.1308341026306152\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: -8.666930198669434\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 1.12382173538208\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: 13.926868438720703\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: -2.2150087356567383\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: -15.192704200744629\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: -1.4924907684326172\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 11.636004447937012\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: -9.588773250579834\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 2.2114205360412598\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: 6.395447254180908\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: 1.4120101928710938\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: -14.382500648498535\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 6.259098052978516\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: -2.3695826530456543\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: 0.4740595817565918\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -1.5249395370483398\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 7.982919216156006\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 2.004268169403076\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 1.4315056800842285\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -5.958702564239502\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 11.266295909881592\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -7.8388190269470215\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 2.468569278717041\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: 9.324202537536621\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: -18.387415409088135\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 5.0695037841796875\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: 8.999009132385254\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -7.218670845031738\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: 0.4738497734069824\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: -7.646796703338623\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: 0.6271839141845703\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: 4.302668571472168\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 9.19351577758789\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: -6.905629634857178\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -17.475287914276123\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 18.25730323791504\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -1.6307592391967773\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -8.27730655670166\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 3.605349063873291\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 9.908583164215088\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -1.1660385131835938\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: -6.08426570892334\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -4.656734466552734\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: 5.198450088500977\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -5.646626949310303\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 4.798719882965088\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 7.63248085975647\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: -10.783630609512329\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: -1.1118173599243164\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 1.498422622680664\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: 4.0616607666015625\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -2.0128726959228516\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -4.801878929138184\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 10.41250467300415\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -1.3367819786071777\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: 9.197767972946167\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: -12.612437009811401\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: 3.7455368041992188\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: -6.986041069030762\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: -0.32984256744384766\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 1.1485075950622559\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: 16.10897421836853\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: -20.69860577583313\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: 7.32327938079834\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -7.453601360321045\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 6.341509819030762\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -0.5866074562072754\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: 12.83200979232788\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: -2.210794687271118\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -8.247710466384888\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 0.6308484077453613\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: -3.1354665756225586\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: -3.5561466217041016\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: 7.959284782409668\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 1.4108633995056152\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -4.195656776428223\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 6.820380687713623\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -6.656551361083984\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: 0.4210519790649414\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 3.8685035705566406\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -7.950153350830078\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 4.172358512878418\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: -3.8752174377441406\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: 7.347450256347656\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -7.027833461761475\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -0.39092540740966797\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 10.473027229309082\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: -9.08700704574585\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -0.9857034683227539\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 6.879317760467529\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -6.597933769226074\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 4.394547939300537\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: -14.356510639190674\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: 15.276341438293457\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -8.371415138244629\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: -0.12222528457641602\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: 13.061860799789429\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -6.805588006973267\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -6.912293434143066\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 12.192933559417725\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -3.186330795288086\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 1.3753652572631836\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -0.9887075424194336\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: -7.332901954650879\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: 0.9786152839660645\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 13.01959753036499\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -15.920860767364502\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 6.591091156005859\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: -3.6109089851379395\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: 6.115458011627197\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -4.963829517364502\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 7.64178991317749\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -4.289233684539795\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -7.35278844833374\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: 3.3121442794799805\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 0.9691715240478516\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 1.765434741973877\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: -14.670145511627197\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: 9.334712028503418\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 7.484138011932373\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -2.4318575859069824\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 2.158203125\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: -3.712916374206543\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -6.554269790649414\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: 1.2617802619934082\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: 14.902948141098022\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: -5.904918909072876\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: 1.9318723678588867\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: -8.236992359161377\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 5.596094131469727\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: 3.5314583778381348\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: -1.8867087364196777\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -4.757330417633057\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -6.765403747558594\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: -0.5724501609802246\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: 11.55566930770874\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: -2.5856781005859375\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -3.2922887802124023\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 5.117282867431641\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: -15.07436752319336\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 13.58741283416748\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -3.946092128753662\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: 6.305027008056641\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 0.04880189895629883\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 0.67535400390625\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -0.2686309814453125\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -4.046158790588379\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 2.2100830078125\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: -3.1507158279418945\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: 12.353570461273193\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: -0.9859216213226318\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: -7.930325269699097\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: 4.4293928146362305\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: -8.589756488800049\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 0.2209162712097168\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 0.5122160911560059\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: -1.2739038467407227\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: 4.033200740814209\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: -5.458440780639648\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: -1.2325382232666016\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: 3.445136547088623\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 10.021390914916992\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: -14.022433757781982\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: 8.470325469970703\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 5.153682231903076\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: -0.11043190956115723\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -12.89328932762146\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 5.953235626220703\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -1.0271787643432617\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: -6.84633731842041\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 16.651272773742676\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: -9.725344181060791\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: 1.1706781387329102\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -4.822030067443848\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: 5.118081569671631\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: 2.6745247840881348\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -3.522946834564209\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: -2.1619629859924316\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 2.0427513122558594\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: -4.546298980712891\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 3.5290026664733887\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -7.66911506652832\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 8.338394165039062\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: -6.537075042724609\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 9.46458101272583\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -2.2258853912353516\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 4.705746173858643\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: -1.4806818962097168\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: 6.567569971084595\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -3.182593584060669\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 1.4673447608947754\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -7.824063301086426\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -0.35866737365722656\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: 1.8366122245788574\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 1.921553611755371\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -2.3499584197998047\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -0.829930305480957\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 6.1174702644348145\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -9.706504344940186\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: -8.380837440490723\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: 14.844512939453125\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: -4.633960723876953\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: -1.8900680541992188\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: 1.2794971466064453\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: -9.060502052307129\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: 3.244924545288086\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: 10.4361891746521\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -0.7769107818603516\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -8.69830846786499\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 8.03495168685913\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: -2.073969841003418\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: 0.30378103256225586\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: -3.8698554039001465\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: 0.41115522384643555\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -3.3189010620117188\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 17.35183596611023\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -9.65664029121399\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 3.168044090270996\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -6.205122470855713\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: -5.324063301086426\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: 13.864459991455078\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: -9.002900123596191\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 7.940669059753418\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -7.766740322113037\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 3.0748772621154785\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 5.764334201812744\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: -11.612846851348877\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 4.303455352783203\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: -2.3781871795654297\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: -3.858919143676758\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: 3.1511640548706055\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: 5.793445110321045\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: -4.072518348693848\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: 0.9392333030700684\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: 8.728179931640625\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: -16.9736909866333\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: 14.76456880569458\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: -7.059729099273682\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: -3.787567615509033\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: 5.094234943389893\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: 11.25441312789917\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: -13.274245262145996\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 7.560775279998779\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: -10.113732814788818\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: 11.780271530151367\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: -7.894937992095947\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 1.579751968383789\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: 6.550483703613281\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: -11.88234806060791\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: 7.521166801452637\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: 6.9987571239471436\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -9.36061978340149\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: 0.3689289093017578\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: -2.6239371299743652\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: 12.06409215927124\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: -12.327797412872314\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: 9.302163124084473\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: -2.8043031692504883\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: -2.8379106521606445\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -1.8015122413635254\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: -10.701637268066406\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 11.742465496063232\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: -1.9202780723571777\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -9.397287368774414\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: 9.001994132995605\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 2.2482800483703613\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: 1.4295125007629395\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -1.730351448059082\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 5.711705684661865\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -13.955433368682861\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: 12.989494800567627\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: -2.2446703910827637\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: 0.4354095458984375\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -7.469110488891602\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 3.894782066345215\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: 0.029070377349853516\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: -0.520942211151123\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -0.34306764602661133\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 1.705322265625\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: -0.9390950202941895\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 2.600259780883789\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: -5.2258992195129395\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 5.848500728607178\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: -3.610711097717285\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 2.8882455825805664\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -4.683973789215088\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 10.639760494232178\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: -11.1118745803833\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: 7.3889851570129395\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: -7.052316665649414\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: -5.482814311981201\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 10.021648406982422\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: 2.266523838043213\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: -1.1980390548706055\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: -0.5003809928894043\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: -2.9906845092773438\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -16.374270915985107\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 19.86689329147339\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 2.9640746116638184\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: -3.3395910263061523\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: 6.542608737945557\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: -16.20845079421997\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: 8.822696208953857\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -0.6889796257019043\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: -0.683445930480957\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 1.5773534774780273\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 2.116527557373047\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: -17.767739295959473\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 15.7145357131958\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: -3.444681167602539\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 8.246197700500488\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -6.70985221862793\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -8.485641479492188\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: 11.243259906768799\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: 0.35841941833496094\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -7.395529747009277\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -4.8279571533203125\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 6.752336025238037\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 4.510481357574463\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: -5.181534290313721\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: 4.711151123046875\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 4.68846321105957\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -5.645129680633545\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -0.947263240814209\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 2.2943878173828125\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -5.679805278778076\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: 4.894857406616211\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: 5.6510162353515625\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -0.24230718612670898\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: -1.5805459022521973\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: -6.927030086517334\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: 1.5515422821044922\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -4.85027551651001\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: -1.0047149658203125\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: 7.804086208343506\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -5.390715599060059\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -4.222860336303711\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 10.860443115234375\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -5.966205596923828\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 1.921854019165039\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: -4.521129131317139\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -1.8445539474487305\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 6.848499774932861\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: 1.449427604675293\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -2.339916229248047\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 4.642624855041504\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: -1.597604751586914\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -7.375998497009277\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 12.731389999389648\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 1.8414521217346191\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -12.187449932098389\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 1.1612129211425781\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: -2.796928882598877\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: 11.723284721374512\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -7.183279991149902\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: -0.06086111068725586\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -2.432830333709717\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 6.306698322296143\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -1.0922002792358398\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 1.618342399597168\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: -5.694072246551514\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -44.55395698547363\n",
      "batch_going: 1\n",
      "change in Valid loss: -43.0893611907959\n",
      "batch_going: 2\n",
      "change in Valid loss: -40.4821252822876\n",
      "batch_going: 3\n",
      "change in Valid loss: -38.88981342315674\n",
      "batch_going: 4\n",
      "change in Valid loss: -35.13153553009033\n",
      "batch_going: 5\n",
      "change in Valid loss: -48.031272888183594\n",
      "batch_going: 6\n",
      "change in Valid loss: -46.474080085754395\n",
      "batch_going: 7\n",
      "change in Valid loss: -41.05713367462158\n",
      "batch_going: 8\n",
      "change in Valid loss: -46.01344108581543\n",
      "batch_going: 9\n",
      "change in Valid loss: -41.68130397796631\n",
      "batch_going: 10\n",
      "change in Valid loss: -30.070006847381592\n",
      "batch_going: 11\n",
      "change in Valid loss: -43.526878356933594\n",
      "batch_going: 12\n",
      "change in Valid loss: -51.80835247039795\n",
      "batch_going: 13\n",
      "change in Valid loss: -49.061264991760254\n",
      "batch_going: 14\n",
      "change in Valid loss: -52.227349281311035\n",
      "batch_going: 15\n",
      "change in Valid loss: -42.81405448913574\n",
      "batch_going: 16\n",
      "change in Valid loss: -42.27696418762207\n",
      "batch_going: 17\n",
      "change in Valid loss: -42.46314525604248\n",
      "batch_going: 18\n",
      "change in Valid loss: -31.178784370422363\n",
      "batch_going: 19\n",
      "change in Valid loss: -40.85713863372803\n",
      "batch_going: 20\n",
      "change in Valid loss: -52.64223575592041\n",
      "batch_going: 21\n",
      "change in Valid loss: -62.336015701293945\n",
      "batch_going: 22\n",
      "change in Valid loss: -35.30916690826416\n",
      "batch_going: 23\n",
      "change in Valid loss: -39.301960468292236\n",
      "batch_going: 24\n",
      "change in Valid loss: -38.09851884841919\n",
      "batch_going: 25\n",
      "change in Valid loss: -54.505205154418945\n",
      "batch_going: 26\n",
      "change in Valid loss: -54.724364280700684\n",
      "batch_going: 27\n",
      "change in Valid loss: -60.719594955444336\n",
      "batch_going: 28\n",
      "change in Valid loss: -48.429388999938965\n",
      "batch_going: 29\n",
      "change in Valid loss: -47.27073669433594\n",
      "batch_going: 30\n",
      "change in Valid loss: -47.15907573699951\n",
      "batch_going: 31\n",
      "change in Valid loss: -42.35306739807129\n",
      "batch_going: 32\n",
      "change in Valid loss: -36.893227100372314\n",
      "batch_going: 33\n",
      "change in Valid loss: -50.20829677581787\n",
      "batch_going: 34\n",
      "change in Valid loss: -38.66605281829834\n",
      "batch_going: 35\n",
      "change in Valid loss: -30.907235145568848\n",
      "batch_going: 36\n",
      "change in Valid loss: -44.3992805480957\n",
      "batch_going: 37\n",
      "change in Valid loss: -45.49050331115723\n",
      "batch_going: 38\n",
      "change in Valid loss: -48.8736629486084\n",
      "batch_going: 39\n",
      "change in Valid loss: -44.03313159942627\n",
      "batch_going: 40\n",
      "change in Valid loss: -50.771074295043945\n",
      "batch_going: 41\n",
      "change in Valid loss: -45.16677379608154\n",
      "batch_going: 42\n",
      "change in Valid loss: -41.356515884399414\n",
      "batch_going: 43\n",
      "change in Valid loss: -41.88657760620117\n",
      "batch_going: 44\n",
      "change in Valid loss: -34.94643449783325\n",
      "batch_going: 45\n",
      "change in Valid loss: -40.40999412536621\n",
      "batch_going: 46\n",
      "change in Valid loss: -41.13334655761719\n",
      "batch_going: 47\n",
      "change in Valid loss: -38.07481288909912\n",
      "batch_going: 48\n",
      "change in Valid loss: -55.29294013977051\n",
      "batch_going: 49\n",
      "change in Valid loss: -39.46130037307739\n",
      "batch_going: 50\n",
      "change in Valid loss: -33.605918884277344\n",
      "batch_going: 51\n",
      "change in Valid loss: -49.14523124694824\n",
      "batch_going: 52\n",
      "change in Valid loss: -41.82454586029053\n",
      "batch_going: 53\n",
      "change in Valid loss: -37.08617448806763\n",
      "batch_going: 54\n",
      "change in Valid loss: -34.37541484832764\n",
      "batch_going: 55\n",
      "change in Valid loss: -37.80766725540161\n",
      "batch_going: 56\n",
      "change in Valid loss: -38.30036163330078\n",
      "batch_going: 57\n",
      "change in Valid loss: -47.3311710357666\n",
      "batch_going: 58\n",
      "change in Valid loss: -44.78915214538574\n",
      "batch_going: 59\n",
      "change in Valid loss: -45.251240730285645\n",
      "batch_going: 60\n",
      "change in Valid loss: -50.08175849914551\n",
      "batch_going: 61\n",
      "change in Valid loss: -41.827731132507324\n",
      "batch_going: 62\n",
      "change in Valid loss: -40.868773460388184\n",
      "batch_going: 63\n",
      "change in Valid loss: -38.3051061630249\n",
      "batch_going: 64\n",
      "change in Valid loss: -45.83749294281006\n",
      "batch_going: 65\n",
      "change in Valid loss: -32.085349559783936\n",
      "batch_going: 66\n",
      "change in Valid loss: -39.68085765838623\n",
      "batch_going: 67\n",
      "change in Valid loss: -37.25449085235596\n",
      "batch_going: 68\n",
      "change in Valid loss: -37.12277173995972\n",
      "batch_going: 69\n",
      "change in Valid loss: -43.507704734802246\n",
      "batch_going: 70\n",
      "change in Valid loss: -40.842599868774414\n",
      "batch_going: 71\n",
      "change in Valid loss: -41.77958965301514\n",
      "batch_going: 72\n",
      "change in Valid loss: -45.993242263793945\n",
      "batch_going: 73\n",
      "change in Valid loss: -29.884047508239746\n",
      "batch_going: 74\n",
      "change in Valid loss: -43.31677436828613\n",
      "batch_going: 75\n",
      "change in Valid loss: -46.26932144165039\n",
      "batch_going: 76\n",
      "change in Valid loss: -42.55393028259277\n",
      "batch_going: 77\n",
      "change in Valid loss: -38.192992210388184\n",
      "batch_going: 78\n",
      "change in Valid loss: -37.3323130607605\n",
      "batch_going: 79\n",
      "change in Valid loss: -40.41708946228027\n",
      "batch_going: 80\n",
      "change in Valid loss: -43.29742908477783\n",
      "batch_going: 81\n",
      "change in Valid loss: -41.70265197753906\n",
      "batch_going: 82\n",
      "change in Valid loss: -38.14950466156006\n",
      "batch_going: 83\n",
      "change in Valid loss: -25.34311294555664\n",
      "Epoch: 4 \tTraining Loss: 26.300134 \tValidation Loss: 42.543714\n",
      "Validation loss decreased (42.829819 --> 42.543714).  Saving model ...\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -25.330042839050293\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 2.8846383094787598\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: -1.4234495162963867\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: 6.255878210067749\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -5.320903062820435\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 10.894663333892822\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -8.504102230072021\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: 1.048349142074585\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 3.2322847843170166\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -0.003070831298828125\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -9.49831485748291\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 12.764283418655396\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: -13.078359365463257\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 2.474830150604248\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 5.855299234390259\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -8.35835576057434\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 4.521818161010742\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 1.8556475639343262\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -1.6599416732788086\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -1.8255424499511719\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: -0.9976601600646973\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -2.28060245513916\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 8.51641297340393\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -3.148871660232544\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: 2.6844286918640137\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 0.755772590637207\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: -13.386461734771729\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 13.798613548278809\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -4.160094261169434\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -2.307283878326416\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 6.2047624588012695\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: -13.024466037750244\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 4.777507781982422\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 1.9544672966003418\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: 2.746598720550537\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: -9.42392110824585\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 0.13969182968139648\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 13.344593048095703\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: -7.454373836517334\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 3.057234287261963\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: 10.970733165740967\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -17.155954837799072\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 8.295437097549438\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -3.0087316036224365\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -1.667182445526123\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -1.5378856658935547\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 0.5200648307800293\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 8.18313717842102\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -4.466818571090698\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -5.249903202056885\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: 0.8726763725280762\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 3.794586658477783\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: -4.108035564422607\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: 2.650589942932129\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -4.518132209777832\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 11.210465431213379\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -3.2487523555755615\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -3.345714807510376\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: 3.2824206352233887\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -8.049864768981934\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 5.065789222717285\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -13.860173225402832\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 11.128599643707275\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: 8.033030033111572\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: -7.71254301071167\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 6.041358709335327\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: -7.032836675643921\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: 2.366766929626465\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 7.761366367340088\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -9.388725757598877\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: -3.4174251556396484\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: 15.00417947769165\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: -3.346860408782959\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: -4.107990264892578\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -6.272242069244385\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -0.1380300521850586\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 9.38952922821045\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -6.746723651885986\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 8.815983533859253\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -1.8270361423492432\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: -7.642979621887207\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -4.041087627410889\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: 10.40547490119934\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -5.230542421340942\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 9.09671664237976\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -0.5739688873291016\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -6.8151891231536865\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -0.5096077919006348\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -2.64467716217041\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -0.2061915397644043\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: -4.641678333282471\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 6.949646472930908\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -3.023195266723633\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -1.826169490814209\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 10.468294620513916\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -1.3366889953613281\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: -6.025543212890625\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -6.825435161590576\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: 12.13688611984253\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: -6.501834392547607\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 5.897789001464844\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: -6.2351179122924805\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -2.928156852722168\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: 9.637346267700195\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: -2.2128820419311523\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: 3.6965930461883545\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: -3.751136064529419\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 4.893839359283447\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -5.994770526885986\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 2.74061918258667\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -2.056102752685547\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: 7.1477556228637695\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: -12.764408588409424\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: 9.775078296661377\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -2.360565662384033\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -4.9353718757629395\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 4.809134006500244\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 2.5239741802215576\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -10.131176710128784\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -3.304934501647949\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 9.860491752624512\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 4.777874946594238\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: -7.933971881866455\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: 6.125097274780273\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: -1.8440508842468262\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -5.971202850341797\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 5.459635257720947\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 1.4737820625305176\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: 2.4765098094940186\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -9.013375043869019\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 7.683882713317871\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -5.833554267883301\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 2.4689674377441406\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -3.005213737487793\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 17.59551227092743\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -7.556343674659729\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -11.653841733932495\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: -3.1160902976989746\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 0.32477855682373047\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: 7.353765964508057\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 3.673144578933716\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: -6.206620931625366\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 1.8668746948242188\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 6.979303359985352\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -7.051513195037842\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: -1.5317869186401367\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: 10.700404644012451\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: -7.019345760345459\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -0.41682004928588867\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 3.414275646209717\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -5.3938889503479\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -5.542051792144775\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 10.446267127990723\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: 3.4968924522399902\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 1.803908348083496\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -10.283598899841309\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -1.885228157043457\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: -1.1322283744812012\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 9.615263938903809\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -7.680253982543945\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 0.6973433494567871\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: 1.981339454650879\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -4.783391952514648\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 6.4675116539001465\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -10.061333179473877\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 3.8780927658081055\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 8.665777444839478\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: -4.665588140487671\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -1.9454073905944824\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 9.631189107894897\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -19.19679045677185\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 9.96976375579834\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: 5.4541015625\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -7.009272575378418\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 1.0520124435424805\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 9.561092853546143\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -13.157789707183838\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 4.038290977478027\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -0.7991123199462891\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -3.318514823913574\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 9.048717021942139\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -15.392227172851562\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 5.412189960479736\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 8.364157676696777\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: -2.467489242553711\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 2.8205370903015137\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 2.270374298095703\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -3.6967873573303223\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 7.644511461257935\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -7.452179193496704\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -1.8486785888671875\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: -0.15751123428344727\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 5.059657096862793\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 2.6417219638824463\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -12.120939493179321\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 2.742593288421631\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: 0.18825054168701172\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: -1.1589932441711426\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 15.211477279663086\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -16.707184314727783\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: 0.7210469245910645\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 10.659245252609253\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -10.271035432815552\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: 0.12476444244384766\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 6.442406177520752\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -2.8485608100891113\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 8.131392002105713\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -6.244268417358398\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: -2.770664691925049\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: -3.5283660888671875\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 1.9031095504760742\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: 11.079133749008179\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -8.842953443527222\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: -4.374451637268066\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -2.950735092163086\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 8.765010833740234\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 11.667511463165283\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -9.510929584503174\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -13.258533477783203\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 8.941428661346436\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 4.701700210571289\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -8.098232746124268\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: 9.047880172729492\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 0.511019229888916\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: 0.1118314266204834\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -0.07626771926879883\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -11.777440309524536\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: 16.38264298439026\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -6.038473844528198\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: -7.522540092468262\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: 2.336418628692627\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 3.6518049240112305\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 3.3084869384765625\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -7.244527339935303\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 11.792317628860474\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -10.52888035774231\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -2.1536707878112793\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -5.553832054138184\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 12.196112871170044\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -16.592787504196167\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 3.588986396789551\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 9.64231014251709\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -7.552914619445801\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: 11.624288558959961\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -7.105746269226074\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: -2.424442768096924\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 7.760136127471924\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: -6.140434741973877\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 5.409152507781982\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -7.059664726257324\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: 4.151194095611572\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 2.0983052253723145\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: 0.6287384033203125\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: 3.045412302017212\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: -0.6501829624176025\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -10.706696510314941\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 11.880882978439331\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: -10.53714632987976\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 2.3572254180908203\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -1.1995792388916016\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 0.1793956756591797\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: 6.928349733352661\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -22.88746953010559\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 20.83980083465576\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -15.713450908660889\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: 18.24120283126831\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: -11.003499031066895\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 10.763728618621826\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 2.996034622192383\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: -11.956431865692139\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -1.1133050918579102\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 3.0143117904663086\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 10.72952389717102\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -9.372891187667847\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: 0.6979680061340332\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 4.519393444061279\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: -5.331366062164307\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 3.0580711364746094\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -1.0120034217834473\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: -0.4026198387145996\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: 0.14199256896972656\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 0.15036344528198242\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -3.9287829399108887\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: 8.940573930740356\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -1.7209327220916748\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: 10.220508575439453\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -10.761120319366455\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -8.040943145751953\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: 6.741313934326172\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: -12.121529579162598\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: 15.206676721572876\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -0.09583353996276855\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: -6.771910190582275\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: -1.5694737434387207\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 3.876059055328369\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 6.813380718231201\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -14.673125743865967\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -0.4551887512207031\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: 9.114789962768555\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: -0.5899953842163086\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -4.008116722106934\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -1.8229866027832031\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 0.6509017944335938\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 11.387913227081299\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -5.205013751983643\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -11.486995220184326\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: 5.0574469566345215\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 5.34066915512085\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 0.6288957595825195\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -9.98558759689331\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 4.164595603942871\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 1.6845989227294922\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 4.488372802734375\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: -7.74874210357666\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 6.886894702911377\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: -3.1903767585754395\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: 7.425897121429443\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -13.525960445404053\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 14.010355472564697\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: -3.679361343383789\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: -7.215981483459473\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -5.765953063964844\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: 2.95654296875\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 7.205572128295898\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 3.0254602432250977\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: -0.04386425018310547\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: 4.5213282108306885\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: -16.022862195968628\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: 10.275180339813232\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 2.4939751625061035\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -9.67177152633667\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 3.7923765182495117\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 4.5198822021484375\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: 5.8149755001068115\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -2.246450185775757\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: -2.25691556930542\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: -1.429150104522705\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: -4.733061790466309\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: -5.773203372955322\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 12.772235870361328\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: -4.812920093536377\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -0.7018661499023438\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: -1.7570757865905762\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: 5.402679443359375\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -14.202473163604736\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 17.98617124557495\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: -13.74027967453003\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: 10.861093997955322\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: -3.014659881591797\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: 4.437592029571533\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -5.07183313369751\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -3.3478593826293945\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 2.2263240814208984\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 5.595040321350098\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: -1.663510799407959\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: -6.502354145050049\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 3.98040771484375\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -7.945542335510254\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: 15.535882711410522\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -15.956200361251831\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 8.69473934173584\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: 4.91532564163208\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -1.2687468528747559\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: -9.839224815368652\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: 8.837862014770508\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: 1.5169262886047363\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: -1.266622543334961\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: -6.533448696136475\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: 2.293105125427246\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 0.16145944595336914\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: 2.4364876747131348\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -4.8230695724487305\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 7.467968463897705\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: 4.443497657775879\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: -1.4191913604736328\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: -2.47713565826416\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: 3.8885676860809326\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: -13.337894678115845\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: 2.0208239555358887\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 5.4538750648498535\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: -1.8131780624389648\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: -6.17565393447876\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -3.8057422637939453\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 13.648757934570312\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: 2.174621820449829\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: -18.44180703163147\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 9.183857440948486\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -6.19642972946167\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 0.0641942024230957\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 0.888216495513916\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: 9.562859535217285\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -13.399510383605957\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: 8.637533187866211\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 1.2097978591918945\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: -3.183257579803467\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: 5.669524669647217\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: -6.796510219573975\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: 6.422252655029297\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 1.2616801261901855\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: -2.647552490234375\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: 1.1945319175720215\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -0.6084370613098145\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 0.2892589569091797\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: 12.67895221710205\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -10.48245906829834\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: 4.828833341598511\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: -5.97882866859436\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -1.6274213790893555\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 5.943948030471802\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -9.131041765213013\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 12.141743898391724\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -7.035881280899048\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 10.073543787002563\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -17.641223669052124\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 11.106677055358887\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: -4.892833232879639\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: 7.765452861785889\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -10.55272102355957\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 7.245364189147949\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -4.2349982261657715\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -5.35747766494751\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: -3.3519864082336426\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 11.137127876281738\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: -0.8223748207092285\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: -7.746846675872803\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: 1.3857746124267578\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 1.2949299812316895\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: 7.209835052490234\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 6.837372779846191\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: -2.8159987926483154\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -2.7151334285736084\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: -2.090880870819092\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: -0.5983233451843262\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: -4.124951362609863\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: -9.064545631408691\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 13.279871940612793\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: -4.131491184234619\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -1.1994361877441406\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: 1.0335183143615723\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -0.9179782867431641\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: 3.2952880859375\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: -1.071462631225586\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: 2.6401352882385254\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: -2.472684383392334\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -9.37079906463623\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 10.69098949432373\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: 3.0526351928710938\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: -1.7884492874145508\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -8.797228336334229\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: 10.296454429626465\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: -1.8571162223815918\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 6.131377220153809\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -10.248637199401855\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: 6.951591968536377\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: -8.124818801879883\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: 6.162300109863281\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: 2.815737724304199\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: -6.512322425842285\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: -4.980645179748535\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: 2.7705907821655273\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 1.2410354614257812\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 1.83180570602417\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: -8.309769630432129\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 6.833181381225586\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -7.111449241638184\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 10.706424713134766\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: 11.291759014129639\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -18.94233465194702\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: -0.0798797607421875\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 6.289737224578857\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -9.0525484085083\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 9.108216762542725\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: -3.5353970527648926\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -4.616179466247559\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 9.524867534637451\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -9.779503345489502\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 7.019064426422119\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 8.776443004608154\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: -13.130435943603516\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: 9.56208348274231\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -2.0002925395965576\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: 6.680246591567993\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: -15.698937177658081\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: 4.514157772064209\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 3.0383801460266113\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 5.649919509887695\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: -13.827195167541504\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 6.244447231292725\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: 1.9068145751953125\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 1.4200639724731445\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: 4.633505344390869\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: -10.979957580566406\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: 1.4262795448303223\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 3.099689483642578\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: -3.467276096343994\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -6.246669292449951\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: 5.5016398429870605\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: -0.19603729248046875\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: 7.786438465118408\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: 5.8547139167785645\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -18.908982276916504\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 5.74169397354126\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -4.813728332519531\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: 9.444098472595215\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 2.6262760162353516\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: 0.7429409027099609\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: -2.926316261291504\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: 3.7549757957458496\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: -12.03357219696045\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: 2.980785369873047\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: -4.590003490447998\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: 12.646923065185547\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -11.3722562789917\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: 1.604020595550537\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: 3.330831527709961\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -4.636960029602051\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 7.4117207527160645\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: -1.4506077766418457\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: 4.652087688446045\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: -3.591742515563965\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -11.816985607147217\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: 12.155780792236328\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 5.731539726257324\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -0.924447774887085\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: -7.95246958732605\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -13.171243667602539\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: 15.343506336212158\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -10.451998710632324\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: 20.962260961532593\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: -11.037057638168335\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -3.839108943939209\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 1.554262638092041\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 1.2746882438659668\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: 4.904067516326904\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: -10.706994533538818\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: -1.2158751487731934\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 14.269357919692993\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: 0.17860770225524902\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -8.084964752197266\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: -2.0015454292297363\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: 14.211517572402954\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -1.882188320159912\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: -13.061500787734985\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -0.18709659576416016\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: 8.882317543029785\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: -7.5701093673706055\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: 3.549506664276123\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -1.9579124450683594\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: -9.745144844055176\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 10.713651180267334\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 6.973128318786621\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: -9.252145290374756\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: 3.5876107215881348\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 0.8547735214233398\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -1.8673014640808105\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 0.8237528800964355\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: 3.8824820518493652\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: -0.9529304504394531\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -9.296224117279053\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: 8.046116828918457\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 0.9471440315246582\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -15.97712755203247\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: 13.738033771514893\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: 2.180449962615967\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: -6.59712553024292\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: -0.17055988311767578\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: 4.488203525543213\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: 1.2296462059020996\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: -4.80954647064209\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 3.473641872406006\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -6.619839668273926\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: 11.067793369293213\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: -3.949313163757324\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: -1.2306690216064453\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: 2.3908138275146484\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 7.987507581710815\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -14.762741327285767\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -17.45640516281128\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 23.258938789367676\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -3.955378532409668\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -6.818897724151611\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 4.124188423156738\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: 4.12121057510376\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: 1.2668514251708984\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -0.5398654937744141\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: -4.621224403381348\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 4.387717247009277\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: -1.374983787536621\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: 9.645382165908813\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: -7.855616807937622\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: 4.189951419830322\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 5.651276111602783\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -6.185202598571777\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: -1.854104995727539\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: -3.2230353355407715\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: 1.780407428741455\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: 0.9643983840942383\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: -2.881479263305664\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 9.676144123077393\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: -0.3656959533691406\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: -9.379103183746338\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 1.1206436157226562\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 6.113734245300293\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -3.0077600479125977\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: -0.7576274871826172\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 0.13349294662475586\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: -8.877432346343994\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: 3.323383331298828\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: -0.2282571792602539\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: -6.832027435302734\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: 12.664146423339844\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: -1.9818639755249023\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 0.7494759559631348\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 1.8012380599975586\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 1.5356850624084473\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: -10.503888130187988\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: -0.2693963050842285\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 2.841207981109619\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: 6.652634143829346\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: 4.447119235992432\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -7.401838302612305\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -7.3181843757629395\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: 11.762332916259766\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -0.13923883438110352\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 4.2967963218688965\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: -3.7872862815856934\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 3.221386671066284\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -9.693368673324585\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 0.06709575653076172\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -3.721585273742676\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -3.567538261413574\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 5.4300761222839355\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: 5.336198806762695\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -15.417544841766357\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: 22.188433408737183\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -1.584686040878296\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: -6.387581825256348\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: -1.6493797302246094\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -5.188899040222168\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: 8.09149980545044\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 0.10313034057617188\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: 0.5994606018066406\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -4.066791534423828\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -2.9692482948303223\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 9.748969078063965\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -2.640550136566162\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 1.9805526733398438\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: -10.75674295425415\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: 7.7782511711120605\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: -1.4160847663879395\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: 4.901251792907715\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -9.056777954101562\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: -6.417121887207031\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 14.431164264678955\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -15.386316776275635\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: -7.843127250671387\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 25.663487911224365\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: 0.7878398895263672\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: -8.282525539398193\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 0.7905387878417969\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -9.38490629196167\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: 11.393654346466064\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: -0.3094673156738281\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -2.225520610809326\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: -6.537220478057861\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: 8.322954177856445\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 5.87411642074585\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: -9.344754219055176\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -56.87674045562744\n",
      "batch_going: 1\n",
      "change in Valid loss: -46.089539527893066\n",
      "batch_going: 2\n",
      "change in Valid loss: -36.05407238006592\n",
      "batch_going: 3\n",
      "change in Valid loss: -39.18619632720947\n",
      "batch_going: 4\n",
      "change in Valid loss: -60.65324783325195\n",
      "batch_going: 5\n",
      "change in Valid loss: -34.869465827941895\n",
      "batch_going: 6\n",
      "change in Valid loss: -40.69758892059326\n",
      "batch_going: 7\n",
      "change in Valid loss: -45.38540840148926\n",
      "batch_going: 8\n",
      "change in Valid loss: -52.04031944274902\n",
      "batch_going: 9\n",
      "change in Valid loss: -51.373090744018555\n",
      "batch_going: 10\n",
      "change in Valid loss: -33.807406425476074\n",
      "batch_going: 11\n",
      "change in Valid loss: -34.20112609863281\n",
      "batch_going: 12\n",
      "change in Valid loss: -43.88676643371582\n",
      "batch_going: 13\n",
      "change in Valid loss: -48.482666015625\n",
      "batch_going: 14\n",
      "change in Valid loss: -41.2158203125\n",
      "batch_going: 15\n",
      "change in Valid loss: -42.43510723114014\n",
      "batch_going: 16\n",
      "change in Valid loss: -40.05136013031006\n",
      "batch_going: 17\n",
      "change in Valid loss: -44.28006649017334\n",
      "batch_going: 18\n",
      "change in Valid loss: -42.528276443481445\n",
      "batch_going: 19\n",
      "change in Valid loss: -40.52961349487305\n",
      "batch_going: 20\n",
      "change in Valid loss: -35.12019395828247\n",
      "batch_going: 21\n",
      "change in Valid loss: -44.53728675842285\n",
      "batch_going: 22\n",
      "change in Valid loss: -44.88165855407715\n",
      "batch_going: 23\n",
      "change in Valid loss: -36.330084800720215\n",
      "batch_going: 24\n",
      "change in Valid loss: -73.26539516448975\n",
      "batch_going: 25\n",
      "change in Valid loss: -38.814377784729004\n",
      "batch_going: 26\n",
      "change in Valid loss: -48.99806022644043\n",
      "batch_going: 27\n",
      "change in Valid loss: -41.588215827941895\n",
      "batch_going: 28\n",
      "change in Valid loss: -55.43692111968994\n",
      "batch_going: 29\n",
      "change in Valid loss: -44.065752029418945\n",
      "batch_going: 30\n",
      "change in Valid loss: -48.07459354400635\n",
      "batch_going: 31\n",
      "change in Valid loss: -45.43126106262207\n",
      "batch_going: 32\n",
      "change in Valid loss: -37.628350257873535\n",
      "batch_going: 33\n",
      "change in Valid loss: -33.265013694763184\n",
      "batch_going: 34\n",
      "change in Valid loss: -33.637142181396484\n",
      "batch_going: 35\n",
      "change in Valid loss: -60.36789894104004\n",
      "batch_going: 36\n",
      "change in Valid loss: -42.80129909515381\n",
      "batch_going: 37\n",
      "change in Valid loss: -48.978257179260254\n",
      "batch_going: 38\n",
      "change in Valid loss: -40.63295364379883\n",
      "batch_going: 39\n",
      "change in Valid loss: -35.521559715270996\n",
      "batch_going: 40\n",
      "change in Valid loss: -51.86638355255127\n",
      "batch_going: 41\n",
      "change in Valid loss: -53.15521717071533\n",
      "batch_going: 42\n",
      "change in Valid loss: -38.9935827255249\n",
      "batch_going: 43\n",
      "change in Valid loss: -38.32451343536377\n",
      "batch_going: 44\n",
      "change in Valid loss: -38.66046905517578\n",
      "batch_going: 45\n",
      "change in Valid loss: -34.50562238693237\n",
      "batch_going: 46\n",
      "change in Valid loss: -41.42740726470947\n",
      "batch_going: 47\n",
      "change in Valid loss: -45.920610427856445\n",
      "batch_going: 48\n",
      "change in Valid loss: -45.835628509521484\n",
      "batch_going: 49\n",
      "change in Valid loss: -46.434326171875\n",
      "batch_going: 50\n",
      "change in Valid loss: -42.04155921936035\n",
      "batch_going: 51\n",
      "change in Valid loss: -41.40632629394531\n",
      "batch_going: 52\n",
      "change in Valid loss: -46.62125110626221\n",
      "batch_going: 53\n",
      "change in Valid loss: -38.313682079315186\n",
      "batch_going: 54\n",
      "change in Valid loss: -31.74834966659546\n",
      "batch_going: 55\n",
      "change in Valid loss: -45.24852752685547\n",
      "batch_going: 56\n",
      "change in Valid loss: -44.68822956085205\n",
      "batch_going: 57\n",
      "change in Valid loss: -35.434913635253906\n",
      "batch_going: 58\n",
      "change in Valid loss: -41.56674385070801\n",
      "batch_going: 59\n",
      "change in Valid loss: -40.423197746276855\n",
      "batch_going: 60\n",
      "change in Valid loss: -38.97021532058716\n",
      "batch_going: 61\n",
      "change in Valid loss: -44.67550754547119\n",
      "batch_going: 62\n",
      "change in Valid loss: -40.31816005706787\n",
      "batch_going: 63\n",
      "change in Valid loss: -45.01378536224365\n",
      "batch_going: 64\n",
      "change in Valid loss: -43.58922004699707\n",
      "batch_going: 65\n",
      "change in Valid loss: -45.282039642333984\n",
      "batch_going: 66\n",
      "change in Valid loss: -43.088998794555664\n",
      "batch_going: 67\n",
      "change in Valid loss: -36.23676776885986\n",
      "batch_going: 68\n",
      "change in Valid loss: -40.359740257263184\n",
      "batch_going: 69\n",
      "change in Valid loss: -44.39070224761963\n",
      "batch_going: 70\n",
      "change in Valid loss: -38.26925992965698\n",
      "batch_going: 71\n",
      "change in Valid loss: -29.5824933052063\n",
      "batch_going: 72\n",
      "change in Valid loss: -41.200947761535645\n",
      "batch_going: 73\n",
      "change in Valid loss: -35.59506177902222\n",
      "batch_going: 74\n",
      "change in Valid loss: -42.666659355163574\n",
      "batch_going: 75\n",
      "change in Valid loss: -37.25669860839844\n",
      "batch_going: 76\n",
      "change in Valid loss: -46.875410079956055\n",
      "batch_going: 77\n",
      "change in Valid loss: -37.90137052536011\n",
      "batch_going: 78\n",
      "change in Valid loss: -41.931819915771484\n",
      "batch_going: 79\n",
      "change in Valid loss: -50.01281261444092\n",
      "batch_going: 80\n",
      "change in Valid loss: -46.10982418060303\n",
      "batch_going: 81\n",
      "change in Valid loss: -44.44277763366699\n",
      "batch_going: 82\n",
      "change in Valid loss: -44.62837219238281\n",
      "batch_going: 83\n",
      "change in Valid loss: -14.673373699188232\n",
      "Epoch: 5 \tTraining Loss: 24.281058 \tValidation Loss: 42.615580\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -22.67984628677368\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: -8.917362689971924\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 13.648737668991089\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -5.696753263473511\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: 3.432900905609131\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 5.879526138305664\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -5.1375412940979\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -4.715116024017334\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 8.32959532737732\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -1.2339341640472412\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -7.788703441619873\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 5.244174003601074\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 2.2033822536468506\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 1.9895601272583008\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: -4.198623895645142\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -1.8283438682556152\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 5.597094297409058\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: -2.6146316528320312\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: 2.70463228225708\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -6.512681245803833\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 2.8813672065734863\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -2.532806396484375\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 0.15203237533569336\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -1.4158868789672852\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: 14.084099531173706\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: -14.344276189804077\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 4.312541484832764\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 5.515322685241699\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -1.8098104000091553\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: 1.2713778018951416\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: -11.455693244934082\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 6.8903398513793945\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: -2.6614761352539062\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 1.4497184753417969\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -5.093348026275635\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 3.120133876800537\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 3.0081677436828613\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: -0.8328354358673096\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: -1.1859667301177979\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: -2.3571133613586426\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: 4.6708762645721436\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -5.018645524978638\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 9.016623497009277\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -2.819335460662842\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -0.39963603019714355\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -11.137455701828003\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 3.1503772735595703\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 8.521618843078613\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -2.9454708099365234\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -7.873828411102295\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: 6.813023090362549\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 8.752453327178955\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: -15.25766134262085\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -0.36208391189575195\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: 14.821465015411377\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: -10.898408889770508\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: 7.370054721832275\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -2.6251602172851562\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: 1.3360512256622314\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -13.2524573802948\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 12.047260999679565\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -11.045469045639038\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 11.164591312408447\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -2.2054648399353027\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 3.7693607807159424\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: -5.863715410232544\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 1.086127758026123\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -9.78806734085083\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 17.9400372505188\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -5.862774848937988\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 1.6970276832580566\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -3.4499335289001465\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: -7.709963321685791\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 6.533408164978027\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -3.4325504302978516\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: 8.282287120819092\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 5.759223699569702\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -6.104723215103149\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: -6.8480634689331055\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: 8.977833986282349\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: -0.7121562957763672\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: 9.19701337814331\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -11.494777202606201\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -0.31707763671875\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 0.39167046546936035\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: 5.079935789108276\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -7.869075536727905\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: 3.4381890296936035\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: 5.824109315872192\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -7.992202043533325\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 1.3926446437835693\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 4.817848205566406\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -11.995035409927368\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: 4.59460973739624\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 9.361437559127808\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -14.577659368515015\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 6.996066570281982\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: 7.705388069152832\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -3.373059034347534\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: -13.756309747695923\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 7.427113056182861\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: -6.939215660095215\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: 16.868356466293335\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: 0.7482945919036865\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: -10.409464836120605\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -0.32410144805908203\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 2.1332216262817383\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 2.73828387260437\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -0.4554307460784912\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: -0.6726980209350586\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -4.743456840515137\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: 2.8351998329162598\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 2.562819719314575\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: 2.7634799480438232\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: 1.451709270477295\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -5.756006240844727\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 3.975658416748047\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 2.166135311126709\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -2.465212345123291\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -0.7237410545349121\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: -10.638444423675537\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 3.8125252723693848\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 2.8706002235412598\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: 3.4169375896453857\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 7.312794327735901\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -16.471022963523865\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 12.391107082366943\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: -1.7552268505096436\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -0.326310396194458\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -3.1884491443634033\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 3.9578640460968018\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -6.427509784698486\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 8.257124423980713\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -6.841843128204346\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: -0.71685791015625\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: 4.332950115203857\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -0.20554304122924805\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: -15.13599157333374\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 10.952246189117432\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -5.708048343658447\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 4.351892471313477\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 4.720065593719482\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: -8.863763809204102\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 1.6747212409973145\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: 10.456138849258423\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: -16.39116883277893\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: 10.70336103439331\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 1.241607666015625\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: 0.9034204483032227\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: -14.805505275726318\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: 10.068690776824951\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: 0.5498361587524414\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 2.7440178394317627\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -1.3548314571380615\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: -0.971839427947998\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: 0.10471343994140625\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -10.693135261535645\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 17.00666904449463\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 3.086099624633789\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -0.9053802490234375\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: -8.451392650604248\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -12.796716690063477\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: 7.3270440101623535\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 0.19091367721557617\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: 6.567878723144531\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: -17.412874698638916\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 15.319764614105225\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 2.4476945400238037\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -3.7936723232269287\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 5.285627841949463\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -1.8694543838500977\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 4.549320936203003\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -12.748037576675415\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: 4.263412952423096\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: -0.41148900985717773\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 8.70321273803711\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -1.2392628192901611\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 0.6445276737213135\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -2.6370012760162354\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -3.0703938007354736\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 1.7041277885437012\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -5.823550224304199\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 8.396666049957275\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: -9.98133659362793\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 1.1105918884277344\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: -0.49977540969848633\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 15.729267597198486\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -13.657073974609375\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 3.268265724182129\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -0.42960166931152344\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -3.192441463470459\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 4.9047160148620605\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: -9.096755981445312\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 10.757676362991333\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: 4.794789552688599\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: -1.5145659446716309\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -8.990404605865479\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: -6.5363264083862305\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 22.867016792297363\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -15.537950992584229\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: 8.6122465133667\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: -7.871308326721191\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -0.5162215232849121\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: 6.942174434661865\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: -0.7052481174468994\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: 4.984694719314575\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: -6.15963339805603\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -2.2862207889556885\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 7.5220513343811035\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: -14.793553352355957\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 8.441106081008911\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -6.562274694442749\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: 3.9866137504577637\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 5.55951714515686\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -13.044127225875854\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: -1.208813190460205\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 12.094931602478027\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -3.788285255432129\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: 7.633800506591797\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: -8.064641952514648\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: -5.0115180015563965\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: 1.1249709129333496\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: 0.7945775985717773\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 0.880739688873291\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: 0.04796266555786133\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: 3.1655311584472656\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: 0.6676840782165527\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: 4.343234300613403\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -2.198665142059326\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 0.773080587387085\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -4.97347354888916\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: -5.011622905731201\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 8.90538215637207\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -5.72270393371582\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 5.197436809539795\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -3.879220485687256\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: 2.513306140899658\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: 0.3086972236633301\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 7.121946811676025\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -4.600993394851685\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: -0.9574508666992188\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: -8.576279878616333\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: 12.04534649848938\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -1.2244009971618652\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: 2.6054930686950684\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: -7.070842981338501\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 3.2844436168670654\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 0.8439254760742188\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: -10.221120119094849\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: 5.839531421661377\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: 3.567962646484375\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 4.4266510009765625\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -17.13160991668701\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: 8.916263580322266\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: -0.004050731658935547\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: 4.130305051803589\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: -16.89926028251648\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 10.215590000152588\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 2.1182680130004883\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: 1.8127846717834473\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 1.5170300006866455\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -7.37331748008728\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -6.807568073272705\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 14.743293523788452\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: 3.417404890060425\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -0.7199954986572266\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: -7.237236499786377\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 4.421488046646118\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 0.5047321319580078\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: -7.522004842758179\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -8.989040851593018\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 11.943359375\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 6.610515117645264\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -6.810522079467773\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -0.46228647232055664\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 12.018816471099854\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: -9.651491641998291\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 1.5627872943878174\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: 3.113374710083008\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 3.390495777130127\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -14.137388467788696\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 17.959076166152954\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -12.84711241722107\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: 6.174448728561401\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -9.194823503494263\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -4.796202182769775\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: 12.713184356689453\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -5.287032127380371\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: 4.231441020965576\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: -3.64652156829834\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: 7.006473541259766\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -7.385168075561523\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 3.115183115005493\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: -3.7100541591644287\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: -14.911231994628906\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 17.45995044708252\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: 2.5049233436584473\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -3.9060616493225098\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -10.85536003112793\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 8.047447204589844\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: 3.8928961753845215\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: 1.0361623764038086\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: -5.0571513175964355\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 0.7425165176391602\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -0.5511188507080078\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: 7.358849048614502\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -0.2951383590698242\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: -1.0641860961914062\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: -0.0589144229888916\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -2.5393497943878174\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: -1.742262840270996\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: -6.5238142013549805\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 9.694256782531738\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: -1.4864635467529297\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 8.758759498596191\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 0.5114305019378662\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -4.124321937561035\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -8.526467084884644\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: -3.971078395843506\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 3.299732208251953\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 3.8276243209838867\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: 6.176403760910034\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -5.807710886001587\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: -6.242084503173828\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: -1.8032073974609375\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 9.128544330596924\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -6.704668998718262\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 6.615800857543945\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -2.440509796142578\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: -0.20653963088989258\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -0.6602931022644043\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 8.694318532943726\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: -5.636073350906372\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: 4.339579343795776\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -12.37587571144104\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: -1.777491569519043\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 13.767720460891724\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: -1.5215468406677246\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: -8.34189772605896\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: -2.8183603286743164\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: 4.684865474700928\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -4.519002437591553\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 10.346732139587402\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -0.8159410953521729\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: 5.572109222412109\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: -18.096648454666138\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 12.1730375289917\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: 0.25693535804748535\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 1.362384557723999\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -7.237608432769775\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -1.3554024696350098\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: 1.6538619995117188\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 2.758209705352783\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 2.152583599090576\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: 5.267786979675293\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: 4.917502403259277\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: -19.24220323562622\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: 9.697610139846802\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -4.7010886669158936\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: 10.26149034500122\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: -5.063779354095459\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -2.3822832107543945\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -6.674003601074219\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 10.977606773376465\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: -16.43867015838623\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: 13.095855712890625\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: -1.6813278198242188\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: -3.881397247314453\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: -3.5715270042419434\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 10.003347396850586\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -1.2318921089172363\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -12.287070751190186\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 14.70410943031311\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -3.0952489376068115\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: -1.5392208099365234\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: 8.28025221824646\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -4.919694662094116\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 2.1170389652252197\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: -10.675526857376099\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 5.155191421508789\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: 3.9973974227905273\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: -1.7693018913269043\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: 6.485635042190552\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: -5.325727462768555\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -0.6044137477874756\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: -6.15950345993042\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 0.2147364616394043\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -5.461580753326416\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 9.129443168640137\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: -4.231152534484863\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: 10.707218647003174\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -4.166514873504639\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -12.164666652679443\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 9.985473155975342\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: 0.1848292350769043\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -0.27915239334106445\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 3.8173282146453857\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -2.1353113651275635\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: -4.363455772399902\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 7.117968797683716\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -4.126638174057007\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: 9.764262437820435\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: -2.3909497261047363\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -11.294864416122437\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -4.155769348144531\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: 2.3216819763183594\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 11.985279321670532\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -10.235055685043335\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 6.692640781402588\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -0.48996448516845703\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: -14.888837337493896\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: 10.221972465515137\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: -7.33668327331543\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: 12.352755069732666\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: -0.04032254219055176\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: -4.447711706161499\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: 3.560163974761963\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -5.538296699523926\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 5.482454299926758\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -3.393712043762207\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: 9.584794044494629\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: -8.063511848449707\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: -8.479080200195312\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 4.666965007781982\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 13.975028991699219\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -13.360416889190674\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 6.915187835693359\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: 9.613200426101685\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: -11.894837617874146\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: -6.987347602844238\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: 5.112133026123047\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: -4.1297149658203125\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: -5.854451656341553\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: 0.6736063957214355\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: 7.630491256713867\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 0.6546401977539062\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 8.031601905822754\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -3.318459987640381\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: -9.116325378417969\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -0.6325411796569824\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: 1.1496376991271973\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 7.985284328460693\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -7.135748863220215\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: 6.686539649963379\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -7.5092387199401855\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 6.318087577819824\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: -10.247666835784912\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 13.979893922805786\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: 0.22370338439941406\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: 0.0005412101745605469\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: -3.4271395206451416\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 1.8319666385650635\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -6.6644203662872314\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: 1.1438465118408203\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: -3.264472484588623\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: 5.798993110656738\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: -14.190170764923096\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: 14.283311367034912\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: 2.438948154449463\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -3.2201242446899414\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 7.504502534866333\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: -8.147159814834595\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 2.9482626914978027\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 3.0565714836120605\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -5.176174640655518\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: -7.3632025718688965\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: 10.86165189743042\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: 3.738691806793213\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: -9.46465253829956\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: -4.912617206573486\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: 13.443737030029297\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: -23.062596321105957\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 17.29966402053833\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -9.610638618469238\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 9.644198417663574\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -5.716919898986816\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 13.468701839447021\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: -12.06092357635498\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: 6.753662824630737\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -3.4541285037994385\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -6.216721534729004\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: 8.854703903198242\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: -1.7493295669555664\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -11.688880920410156\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 7.622981071472168\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 5.149033069610596\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: -3.183929920196533\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 6.50806188583374\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -4.40476655960083\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 13.70943546295166\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: -13.223462104797363\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 5.05537748336792\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -5.300490856170654\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 1.1635851860046387\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: -2.331118583679199\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: 2.8769946098327637\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: 2.7298474311828613\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: -4.33704137802124\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -0.6264781951904297\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -2.020294666290283\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: 2.0136237144470215\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 6.820536851882935\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -5.634397268295288\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -0.32177209854125977\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: -7.84060001373291\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: 4.574534893035889\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: -0.3661322593688965\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -7.958407402038574\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: 6.756923198699951\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: 2.8170371055603027\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: -7.826430797576904\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: 16.01905345916748\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -4.716041088104248\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: -4.340789318084717\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -3.653125762939453\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: 5.717861652374268\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: -8.313956260681152\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: 12.21011757850647\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: -8.022605180740356\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 2.334623336791992\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -0.5793285369873047\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: 8.946315050125122\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: -1.9939517974853516\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -13.550292253494263\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 11.546947956085205\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -1.4365839958190918\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: -0.8983755111694336\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -2.061927318572998\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: 5.410187244415283\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: -7.688276767730713\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: 4.158847332000732\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: -14.725086688995361\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 15.783843994140625\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: 2.3845553398132324\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 3.12727689743042\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: -16.38310194015503\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 14.380630254745483\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -7.818526029586792\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: 5.234689712524414\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: -1.1499381065368652\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -1.8517351150512695\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: 6.721881628036499\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: -8.850029706954956\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -5.2675676345825195\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: 5.6322455406188965\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: 5.174355506896973\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -6.989450454711914\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: 0.7887840270996094\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: 4.04414176940918\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: -10.360333919525146\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 7.290451526641846\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: -0.44156551361083984\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: 7.432116270065308\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: -5.978001356124878\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: 6.679282188415527\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: -9.634256362915039\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -8.196914196014404\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: 19.69932198524475\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -5.076812505722046\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: -2.2747802734375\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 6.111962795257568\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -4.562942981719971\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: 0.3418111801147461\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -4.142248630523682\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 6.785435676574707\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: -6.945750713348389\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -0.9443330764770508\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: -11.10403060913086\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 17.065353393554688\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 4.543488025665283\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: 1.1170244216918945\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: -4.878281354904175\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: -16.515895128250122\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: 10.74638843536377\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: 3.0593180656433105\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 6.049387454986572\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -9.642953872680664\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -0.09686708450317383\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 2.5907135009765625\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -5.504496097564697\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -7.373454570770264\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 18.24208974838257\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: -12.71697998046875\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: 9.204692840576172\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -0.7506918907165527\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 4.7417426109313965\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: -7.132298946380615\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 5.273270606994629\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: -9.918243885040283\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 1.0780692100524902\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: 8.129119873046875\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: -10.177476406097412\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: 10.517759323120117\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: -8.680202960968018\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: -2.6712536811828613\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: 16.57871723175049\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: -5.134719610214233\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: -16.617108583450317\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 14.888875484466553\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: -2.550816535949707\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 2.874317169189453\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: -5.275583267211914\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 6.51749849319458\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -4.264159202575684\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 2.256805896759033\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 0.1403331756591797\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: -3.742847442626953\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: -1.8587112426757812\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: 4.890470504760742\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: 0.9759426116943359\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -8.267230987548828\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: 7.835865020751953\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: -5.294055938720703\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 0.8074426651000977\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: -2.5476765632629395\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 14.176987409591675\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: -18.036128282546997\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 19.712390899658203\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -6.913909912109375\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -0.9450626373291016\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -14.134523868560791\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: 13.222310543060303\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: 1.6344666481018066\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: 1.2661850452423096\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: -6.57068133354187\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: -6.894650459289551\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 9.3184494972229\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -6.793792247772217\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 12.91304349899292\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: 0.01685500144958496\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -14.512485265731812\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 6.182818412780762\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: 7.812286615371704\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -8.989161252975464\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -4.7039031982421875\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: 15.957351922988892\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: -8.338409662246704\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 3.2610344886779785\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: 0.8633506298065186\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -4.895600080490112\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 9.576492309570312\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -6.7832183837890625\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: 7.80017614364624\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -11.956748962402344\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 3.3808112144470215\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -5.1436543464660645\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 6.157665252685547\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 2.9880213737487793\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -0.5259525775909424\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 3.1472623348236084\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -6.607182025909424\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -1.6067147254943848\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: -1.540060043334961\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: -0.9220266342163086\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -7.284188270568848\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 7.4112701416015625\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 8.75276803970337\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -23.616254329681396\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 8.514037132263184\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 0.010223388671875\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: 12.613894939422607\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -6.167731285095215\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 8.938549757003784\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -6.3107216358184814\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: -3.401646614074707\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: 3.9864516258239746\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 1.807851791381836\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 2.7180063724517822\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -38.14855098724365\n",
      "batch_going: 1\n",
      "change in Valid loss: -54.06672477722168\n",
      "batch_going: 2\n",
      "change in Valid loss: -42.60844707489014\n",
      "batch_going: 3\n",
      "change in Valid loss: -53.376474380493164\n",
      "batch_going: 4\n",
      "change in Valid loss: -53.25039863586426\n",
      "batch_going: 5\n",
      "change in Valid loss: -53.00717353820801\n",
      "batch_going: 6\n",
      "change in Valid loss: -43.180789947509766\n",
      "batch_going: 7\n",
      "change in Valid loss: -41.95188045501709\n",
      "batch_going: 8\n",
      "change in Valid loss: -46.53775215148926\n",
      "batch_going: 9\n",
      "change in Valid loss: -53.67344856262207\n",
      "batch_going: 10\n",
      "change in Valid loss: -58.621177673339844\n",
      "batch_going: 11\n",
      "change in Valid loss: -59.810428619384766\n",
      "batch_going: 12\n",
      "change in Valid loss: -44.27690505981445\n",
      "batch_going: 13\n",
      "change in Valid loss: -36.099960803985596\n",
      "batch_going: 14\n",
      "change in Valid loss: -36.20728015899658\n",
      "batch_going: 15\n",
      "change in Valid loss: -36.62757873535156\n",
      "batch_going: 16\n",
      "change in Valid loss: -45.504422187805176\n",
      "batch_going: 17\n",
      "change in Valid loss: -50.24850368499756\n",
      "batch_going: 18\n",
      "change in Valid loss: -47.24277973175049\n",
      "batch_going: 19\n",
      "change in Valid loss: -38.50525617599487\n",
      "batch_going: 20\n",
      "change in Valid loss: -40.62765121459961\n",
      "batch_going: 21\n",
      "change in Valid loss: -47.35304832458496\n",
      "batch_going: 22\n",
      "change in Valid loss: -40.869526863098145\n",
      "batch_going: 23\n",
      "change in Valid loss: -37.196030616760254\n",
      "batch_going: 24\n",
      "change in Valid loss: -40.27544975280762\n",
      "batch_going: 25\n",
      "change in Valid loss: -54.34384822845459\n",
      "batch_going: 26\n",
      "change in Valid loss: -57.88148880004883\n",
      "batch_going: 27\n",
      "change in Valid loss: -45.30074596405029\n",
      "batch_going: 28\n",
      "change in Valid loss: -40.49293518066406\n",
      "batch_going: 29\n",
      "change in Valid loss: -48.921990394592285\n",
      "batch_going: 30\n",
      "change in Valid loss: -45.53633213043213\n",
      "batch_going: 31\n",
      "change in Valid loss: -59.64437007904053\n",
      "batch_going: 32\n",
      "change in Valid loss: -43.236517906188965\n",
      "batch_going: 33\n",
      "change in Valid loss: -39.721248149871826\n",
      "batch_going: 34\n",
      "change in Valid loss: -36.091392040252686\n",
      "batch_going: 35\n",
      "change in Valid loss: -40.93493461608887\n",
      "batch_going: 36\n",
      "change in Valid loss: -56.329050064086914\n",
      "batch_going: 37\n",
      "change in Valid loss: -43.758482933044434\n",
      "batch_going: 38\n",
      "change in Valid loss: -51.995038986206055\n",
      "batch_going: 39\n",
      "change in Valid loss: -45.42186737060547\n",
      "batch_going: 40\n",
      "change in Valid loss: -34.7753381729126\n",
      "batch_going: 41\n",
      "change in Valid loss: -50.99619388580322\n",
      "batch_going: 42\n",
      "change in Valid loss: -51.820878982543945\n",
      "batch_going: 43\n",
      "change in Valid loss: -38.893234729766846\n",
      "batch_going: 44\n",
      "change in Valid loss: -41.263442039489746\n",
      "batch_going: 45\n",
      "change in Valid loss: -38.12990665435791\n",
      "batch_going: 46\n",
      "change in Valid loss: -58.02321910858154\n",
      "batch_going: 47\n",
      "change in Valid loss: -47.16021537780762\n",
      "batch_going: 48\n",
      "change in Valid loss: -38.181681632995605\n",
      "batch_going: 49\n",
      "change in Valid loss: -58.586273193359375\n",
      "batch_going: 50\n",
      "change in Valid loss: -35.174269676208496\n",
      "batch_going: 51\n",
      "change in Valid loss: -35.78135013580322\n",
      "batch_going: 52\n",
      "change in Valid loss: -50.41583061218262\n",
      "batch_going: 53\n",
      "change in Valid loss: -52.0980167388916\n",
      "batch_going: 54\n",
      "change in Valid loss: -44.4374418258667\n",
      "batch_going: 55\n",
      "change in Valid loss: -48.82954120635986\n",
      "batch_going: 56\n",
      "change in Valid loss: -45.23182392120361\n",
      "batch_going: 57\n",
      "change in Valid loss: -50.547780990600586\n",
      "batch_going: 58\n",
      "change in Valid loss: -45.0006103515625\n",
      "batch_going: 59\n",
      "change in Valid loss: -54.907493591308594\n",
      "batch_going: 60\n",
      "change in Valid loss: -53.644022941589355\n",
      "batch_going: 61\n",
      "change in Valid loss: -41.56161308288574\n",
      "batch_going: 62\n",
      "change in Valid loss: -43.00820350646973\n",
      "batch_going: 63\n",
      "change in Valid loss: -35.60213088989258\n",
      "batch_going: 64\n",
      "change in Valid loss: -38.72439622879028\n",
      "batch_going: 65\n",
      "change in Valid loss: -38.43465805053711\n",
      "batch_going: 66\n",
      "change in Valid loss: -44.360971450805664\n",
      "batch_going: 67\n",
      "change in Valid loss: -36.733460426330566\n",
      "batch_going: 68\n",
      "change in Valid loss: -37.99450635910034\n",
      "batch_going: 69\n",
      "change in Valid loss: -47.40771293640137\n",
      "batch_going: 70\n",
      "change in Valid loss: -46.721601486206055\n",
      "batch_going: 71\n",
      "change in Valid loss: -37.27118730545044\n",
      "batch_going: 72\n",
      "change in Valid loss: -45.82474708557129\n",
      "batch_going: 73\n",
      "change in Valid loss: -39.97721195220947\n",
      "batch_going: 74\n",
      "change in Valid loss: -44.63383674621582\n",
      "batch_going: 75\n",
      "change in Valid loss: -45.12200355529785\n",
      "batch_going: 76\n",
      "change in Valid loss: -53.981361389160156\n",
      "batch_going: 77\n",
      "change in Valid loss: -42.99384593963623\n",
      "batch_going: 78\n",
      "change in Valid loss: -37.35299587249756\n",
      "batch_going: 79\n",
      "change in Valid loss: -54.41932201385498\n",
      "batch_going: 80\n",
      "change in Valid loss: -47.58246898651123\n",
      "batch_going: 81\n",
      "change in Valid loss: -34.2921781539917\n",
      "batch_going: 82\n",
      "change in Valid loss: -49.32509422302246\n",
      "batch_going: 83\n",
      "change in Valid loss: -25.694282054901123\n",
      "Epoch: 6 \tTraining Loss: 22.178565 \tValidation Loss: 45.140431\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -16.806766986846924\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 1.290295124053955\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 5.1390910148620605\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -2.120271921157837\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -9.612623453140259\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 5.351964235305786\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -1.4439046382904053\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -3.3768820762634277\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 3.5858142375946045\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: 6.43021821975708\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -6.162147521972656\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: -11.565343141555786\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 17.10302472114563\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: -5.637413263320923\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 1.5420186519622803\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -0.340656042098999\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 2.131192684173584\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 1.9468343257904053\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -4.6887290477752686\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -7.6079511642456055\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 2.475130558013916\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: 0.9479546546936035\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 12.29898989200592\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -6.036388278007507\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: 6.501027941703796\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: -7.991626858711243\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 1.162198781967163\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 8.45035195350647\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -17.012686729431152\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: 4.384868144989014\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: -5.350949764251709\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 13.880054950714111\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: -2.1468305587768555\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: -4.21499490737915\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -12.443404197692871\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 15.950915813446045\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: -2.463768720626831\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: -5.27182936668396\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 3.308393955230713\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 2.771650552749634\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: 0.955580472946167\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -7.134354114532471\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 8.224464654922485\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -7.476898431777954\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -0.2920103073120117\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: 2.9446566104888916\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: -12.341259717941284\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 7.673614025115967\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: 12.877447605133057\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -2.992919683456421\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -9.655956029891968\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 5.165170431137085\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: -3.3604323863983154\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -0.8235406875610352\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -1.2814760208129883\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 6.1794257164001465\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -0.04637598991394043\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -2.628047466278076\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: 4.220820665359497\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -16.390321254730225\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 20.301610231399536\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -6.4192235469818115\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 2.3612070083618164\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -4.3536341190338135\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 3.929011821746826\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: -1.1756336688995361\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: -2.3421144485473633\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -3.5325002670288086\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 1.2418079376220703\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: 1.2583351135253906\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: -1.1809992790222168\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: 6.364755630493164\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: -4.745497703552246\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 8.3096182346344\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -22.31281876564026\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: 6.394541263580322\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 2.547152042388916\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -1.3398146629333496\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 8.880442380905151\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -10.1290762424469\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 13.483467102050781\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -4.140746593475342\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -1.2352240085601807\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -7.489827871322632\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 14.330573081970215\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -1.4795470237731934\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -7.393841743469238\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: 1.0550379753112793\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -1.3567829132080078\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -1.6607904434204102\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: -4.7449564933776855\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 12.682592868804932\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -4.779050350189209\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -2.932403087615967\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 12.836437225341797\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -5.951560735702515\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 9.61726188659668\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -8.480958938598633\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -4.008662700653076\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: -0.7450520992279053\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 7.368074655532837\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: -5.969281196594238\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -0.8481943607330322\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -9.472343921661377\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 0.6124520301818848\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: 8.90861988067627\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: -2.640697956085205\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 4.0120697021484375\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -17.15480327606201\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 15.174238681793213\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: 4.15067195892334\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -2.3681282997131348\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 5.961759090423584\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -13.043160438537598\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: 2.7048230171203613\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: 11.589763164520264\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: -13.078398704528809\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 7.416987419128418\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: 2.7407264709472656\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -12.040784358978271\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 14.54924464225769\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: -19.727081060409546\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 13.545806407928467\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -5.084364414215088\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 8.672651052474976\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -6.426664590835571\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 2.2086822986602783\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: -2.859262228012085\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: 0.16655206680297852\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -0.7233953475952148\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 6.7298078536987305\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -12.095727920532227\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 13.227391242980957\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -3.8077497482299805\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 8.6007821559906\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -8.512769937515259\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -7.3697710037231445\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 4.193603992462158\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: -7.223026752471924\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: 3.209354877471924\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 4.610183238983154\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 2.3028361797332764\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: -3.3727824687957764\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: -1.4447402954101562\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: 7.129874229431152\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: -8.31578254699707\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: 10.7657790184021\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 3.359628915786743\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -14.45834994316101\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 9.149988889694214\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -12.653239965438843\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: 5.615429878234863\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 8.106098175048828\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -4.5635271072387695\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 1.8037867546081543\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -2.6201093196868896\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -0.681077241897583\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 3.8755714893341064\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: -1.80716872215271\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: 7.008017301559448\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: -13.110429048538208\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: 0.3747701644897461\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: 5.806764364242554\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: -4.1259682178497314\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: 2.3757660388946533\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 1.2389814853668213\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: -15.506763458251953\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 15.904045104980469\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -4.965121746063232\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 0.05780220031738281\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: 6.471997499465942\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: -1.9262468814849854\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -11.214137077331543\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: 16.30753517150879\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: -2.5257861614227295\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 0.7737171649932861\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -8.805198669433594\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 3.706200122833252\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: 5.387974977493286\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -10.714298486709595\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 7.960314750671387\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -7.949845790863037\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: -7.6458048820495605\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 12.162578105926514\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 0.546877384185791\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 7.645939588546753\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: -23.852771520614624\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: 4.883015155792236\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 13.400758504867554\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: 3.8195407390594482\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -14.42296028137207\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 4.42800760269165\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 9.080268144607544\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: -22.390114068984985\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: 21.632976531982422\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 8.802430629730225\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -22.94579267501831\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 6.742672920227051\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 13.96375298500061\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -11.761218309402466\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: 3.8012218475341797\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 1.40921950340271\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -13.882972002029419\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: 10.114531517028809\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 2.934650182723999\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -7.399929761886597\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 14.14982557296753\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -12.12764024734497\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 4.489259719848633\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: -13.298566341400146\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 8.015711307525635\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -1.1997199058532715\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: 6.694278717041016\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: -7.749202251434326\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: 1.9912910461425781\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 8.38791012763977\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 0.8336126804351807\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -12.118778228759766\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: 11.893361806869507\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: -3.21600079536438\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 4.445151090621948\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -10.061763525009155\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: 0.48157691955566406\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 2.3217368125915527\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: 6.6463422775268555\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -1.8374335765838623\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -20.92095971107483\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: 22.916921377182007\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -3.1561648845672607\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: -7.534983158111572\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: 10.71689248085022\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: -17.842272520065308\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 10.81066608428955\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -8.424556255340576\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 14.029178619384766\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -3.1917190551757812\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -3.0944204330444336\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: 14.558565020561218\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: -12.36706793308258\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -0.2562892436981201\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: -9.822511672973633\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 0.3251028060913086\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: 11.889705657958984\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -6.2920331954956055\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: 0.4181790351867676\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 5.54282546043396\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: -3.749138116836548\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 1.792970895767212\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: -1.6760623455047607\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -10.511536598205566\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: 10.19702434539795\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: -2.3050379753112793\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: 10.73918104171753\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -8.262383937835693\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 0.7855319976806641\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -5.768694877624512\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 9.660048484802246\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: -7.805836200714111\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 3.390011787414551\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -7.933297157287598\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: -4.561481475830078\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: 10.323686599731445\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: 11.985640525817871\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 1.8627357482910156\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -11.977627277374268\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -2.919647693634033\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 7.892705202102661\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: -5.68567156791687\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 2.02359676361084\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 1.0796654224395752\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: 2.5404739379882812\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 2.861284017562866\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: -6.119586229324341\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: 5.064812898635864\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -6.878654956817627\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 11.746810674667358\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: -12.326935529708862\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 8.216758966445923\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -9.716733694076538\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 14.390750527381897\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -20.12186110019684\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 0.6950950622558594\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -4.632694721221924\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: 16.150799989700317\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -0.7840561866760254\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: 6.332310438156128\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -3.7994039058685303\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -7.620564699172974\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -0.49806833267211914\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 7.618739604949951\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -24.533021450042725\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: 27.408159971237183\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: -2.7530527114868164\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: -7.180997133255005\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 3.101545572280884\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: -1.0342466831207275\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -16.969022750854492\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: 22.69270420074463\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -6.792354583740234\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 3.0342745780944824\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -0.2292323112487793\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -2.245919704437256\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 0.6604099273681641\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 3.7499797344207764\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -7.700513601303101\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -12.272896766662598\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: 6.152846813201904\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 8.119385242462158\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 11.97007417678833\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -14.13586139678955\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 1.7301511764526367\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 9.518766403198242\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: -9.653840065002441\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: -5.427124500274658\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 5.568673610687256\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 6.849215030670166\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: 3.7009716033935547\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -5.42660117149353\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: -21.440821886062622\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 6.346566677093506\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 15.725932121276855\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -2.616778612136841\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: 5.265794992446899\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: -15.175924301147461\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 5.0867486000061035\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: -5.151622295379639\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -2.855808734893799\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 19.83922839164734\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -11.873413324356079\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 12.978513240814209\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -13.004438877105713\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 10.90947151184082\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 1.9885766506195068\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -9.123085737228394\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -3.4590625762939453\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: 1.1980319023132324\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 3.0754947662353516\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: 4.3889570236206055\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: -3.6807477474212646\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 4.450050592422485\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: -1.4706504344940186\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: 1.8326950073242188\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 0.09858369827270508\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -11.633838415145874\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: 12.899543046951294\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: -7.951334714889526\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 7.500214576721191\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -3.7297701835632324\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: -13.920726776123047\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: 22.078545093536377\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -9.067673683166504\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -6.872060298919678\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 11.345151662826538\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: -12.520359754562378\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: 10.171387195587158\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: -0.0557863712310791\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: -0.7739067077636719\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -7.060104608535767\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: 10.281200408935547\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -8.449115753173828\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 1.7185187339782715\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -0.2893829345703125\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -6.769208908081055\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 6.500053405761719\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: 10.45359492301941\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: -6.994262933731079\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: 4.373639822006226\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 0.3617429733276367\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: -12.39214301109314\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 9.796643257141113\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -13.11190128326416\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: 7.711248397827148\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: -3.267650604248047\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: 6.671404838562012\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: 5.606076717376709\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: -4.836618900299072\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: 4.58708643913269\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: -5.263427495956421\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: 8.977294564247131\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: -8.351868987083435\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: -9.192129373550415\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 12.042293548583984\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -10.983152389526367\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 10.952425003051758\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -2.064164876937866\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: 0.22678017616271973\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 1.6982340812683105\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -18.03293228149414\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 11.34448528289795\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: -9.522876739501953\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: 5.223281383514404\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: 9.413803815841675\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -2.2296011447906494\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 0.2549278736114502\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: -7.173241376876831\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: 13.051062822341919\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: -18.277398347854614\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: 13.374167680740356\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: -6.172875165939331\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 3.0414867401123047\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -1.5927696228027344\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -0.13272523880004883\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: -9.461307525634766\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: 14.718661308288574\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -3.5899734497070312\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -4.143383502960205\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 13.301818370819092\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -5.12739896774292\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: -0.9609735012054443\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -3.9057552814483643\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: -5.614306926727295\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: 6.1589813232421875\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: -3.8167238235473633\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -0.760655403137207\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 14.474122524261475\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: -14.90525484085083\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: 10.437204837799072\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -4.182223081588745\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 6.983044147491455\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -11.017552614212036\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -1.611769199371338\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: -4.56425666809082\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 1.4733600616455078\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 9.569931030273438\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 0.27436375617980957\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -6.610687971115112\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 6.008508205413818\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -0.020966529846191406\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: -10.037729740142822\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: 16.108964681625366\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -11.417964696884155\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: 10.255080461502075\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: -6.36233925819397\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: 1.2961995601654053\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: -8.232136964797974\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 4.440405368804932\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: -7.927699089050293\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: 7.669613361358643\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: -4.531142711639404\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: 5.552818775177002\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -3.0543160438537598\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 3.366379737854004\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -0.30960798263549805\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: 2.7834320068359375\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -6.383569240570068\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: -3.6001086235046387\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: 15.754057168960571\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: -10.568753480911255\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -0.518033504486084\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: -1.7495059967041016\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: -2.723555564880371\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 1.4983320236206055\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: 5.865116119384766\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -2.1949100494384766\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 12.983168363571167\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: -9.687174558639526\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: -2.193570137023926\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: 2.7677440643310547\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: 6.337910890579224\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -11.195870637893677\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 0.21765708923339844\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 4.238542318344116\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 1.4576375484466553\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 0.12442469596862793\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: 2.412973642349243\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 2.334343194961548\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: -11.691471338272095\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: 0.9362459182739258\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 7.090663909912109\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: -1.6874992847442627\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -0.30713319778442383\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 1.7979240417480469\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: -8.674994707107544\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: 7.644721269607544\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: -6.0716283321380615\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -1.4733695983886719\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 5.1384782791137695\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: -1.6964340209960938\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: -1.252884864807129\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: 8.996032476425171\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -7.130402326583862\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -3.733077049255371\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: 6.4615797996521\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -3.977799415588379\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: -1.0628199577331543\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 10.637376308441162\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: -8.861751556396484\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 6.708651781082153\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: 0.622638463973999\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: -4.4170331954956055\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: 6.602195501327515\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 0.812309980392456\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -8.048384189605713\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 2.6722371578216553\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: -7.925518751144409\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: 12.855679988861084\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -25.14411687850952\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 21.973460912704468\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -5.62151312828064\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -5.969939231872559\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: 3.7474918365478516\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: -3.0946993827819824\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: 14.959540367126465\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -12.333309650421143\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 2.8111648559570312\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -1.9434857368469238\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: -3.8802289962768555\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: 1.8398427963256836\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: 2.6047801971435547\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: 5.972425937652588\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: 2.8029000759124756\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: -3.4681451320648193\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -8.849923610687256\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: 10.284210443496704\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -3.6110270023345947\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: 11.48106575012207\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: -10.850601196289062\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: 3.4980833530426025\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: -4.824246168136597\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: -0.8583855628967285\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: 1.1104655265808105\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -7.66305685043335\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 11.05003833770752\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -11.770858764648438\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 12.410675287246704\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: 1.740407943725586\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: -11.375826597213745\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: 1.3121557235717773\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: -1.9739317893981934\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 7.090617418289185\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -1.547774076461792\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: -16.952874660491943\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 16.20199203491211\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: -3.4125351905822754\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 8.961189985275269\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: 2.025657892227173\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: -0.9424352645874023\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -4.615886211395264\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: 4.507453441619873\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: -3.3250999450683594\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -2.3128628730773926\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -13.472979068756104\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 12.629177570343018\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -12.036588191986084\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: 9.025769233703613\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: 4.799289703369141\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -5.74777364730835\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -2.9162192344665527\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: 8.254029750823975\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: -8.52839469909668\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 0.41806936264038086\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: 6.793625354766846\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: 0.76812744140625\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 0.5073785781860352\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -4.189136028289795\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 2.5217032432556152\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -4.2656660079956055\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: -1.3532638549804688\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: 3.3960485458374023\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: 4.358282089233398\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 1.1330103874206543\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -2.444150447845459\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: -8.520123958587646\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: 3.2573318481445312\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 9.863133430480957\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: 5.029609203338623\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -2.854278087615967\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: -14.470932483673096\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: -1.6469955444335938\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 10.847246646881104\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: 1.2770295143127441\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: -8.392770290374756\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 11.444610357284546\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: -3.8623905181884766\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -7.172595262527466\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 2.2342801094055176\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: 9.549312591552734\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -14.714648723602295\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 10.56732177734375\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -14.557991027832031\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: 13.207165002822876\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 2.0938169956207275\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: 2.9698967933654785\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: -10.317068099975586\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: 0.1844191551208496\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: -4.188106060028076\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 5.44003963470459\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: -1.1997604370117188\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: 9.936254024505615\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 2.245393991470337\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: -17.199076414108276\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: -4.660451412200928\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: 5.718820095062256\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 2.128734588623047\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: 4.3377685546875\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: 2.119128704071045\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: -4.122645854949951\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 6.4327287673950195\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 0.554497241973877\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: -8.8039231300354\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 4.1954874992370605\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 1.5922975540161133\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: -8.795745372772217\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -5.363202095031738\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 8.894057273864746\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 7.201803922653198\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 1.13084077835083\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: -3.9239823818206787\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: -4.929611682891846\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: 6.2987494468688965\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -0.7050442695617676\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: 1.868981122970581\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: -10.272272825241089\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 5.086026191711426\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 4.474382400512695\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 1.6251814365386963\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: -15.690151453018188\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 15.779927968978882\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -1.3821947574615479\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -0.4107224941253662\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -2.0410335063934326\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: 5.040183067321777\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -3.5257434844970703\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -5.3033447265625\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 3.9794135093688965\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 6.995792388916016\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: -10.992534160614014\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: 16.68894112110138\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: -15.734465718269348\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: 5.12303352355957\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -6.249279975891113\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 10.945029258728027\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -11.090400218963623\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -6.725051403045654\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: 4.2304229736328125\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: 8.500670194625854\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 2.8236043453216553\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: -8.381011486053467\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: 8.90951156616211\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -7.110855579376221\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 3.918933868408203\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -4.498636722564697\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: 1.235034465789795\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -15.702786445617676\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 20.723854303359985\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -2.5867927074432373\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: -2.434079647064209\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: -3.51609468460083\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -2.7135443687438965\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 9.001593589782715\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -3.617064952850342\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -0.6964683532714844\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 0.10541677474975586\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: -0.9059524536132812\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: 6.609587669372559\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: -12.598021030426025\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 5.967166423797607\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -6.19281530380249\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 7.473773956298828\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 2.2142648696899414\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -3.050847053527832\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: 4.307572841644287\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 10.760492086410522\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -10.895301103591919\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 7.600795030593872\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -10.179105997085571\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: -2.5669288635253906\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 7.184814214706421\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -51.84162616729736\n",
      "batch_going: 1\n",
      "change in Valid loss: -44.88877296447754\n",
      "batch_going: 2\n",
      "change in Valid loss: -42.487478256225586\n",
      "batch_going: 3\n",
      "change in Valid loss: -41.78111553192139\n",
      "batch_going: 4\n",
      "change in Valid loss: -52.04655647277832\n",
      "batch_going: 5\n",
      "change in Valid loss: -40.31966209411621\n",
      "batch_going: 6\n",
      "change in Valid loss: -42.76466369628906\n",
      "batch_going: 7\n",
      "change in Valid loss: -54.25360679626465\n",
      "batch_going: 8\n",
      "change in Valid loss: -57.67848014831543\n",
      "batch_going: 9\n",
      "change in Valid loss: -65.54386138916016\n",
      "batch_going: 10\n",
      "change in Valid loss: -43.898468017578125\n",
      "batch_going: 11\n",
      "change in Valid loss: -48.0100154876709\n",
      "batch_going: 12\n",
      "change in Valid loss: -47.23766326904297\n",
      "batch_going: 13\n",
      "change in Valid loss: -49.034953117370605\n",
      "batch_going: 14\n",
      "change in Valid loss: -45.85829257965088\n",
      "batch_going: 15\n",
      "change in Valid loss: -51.78539276123047\n",
      "batch_going: 16\n",
      "change in Valid loss: -58.69833946228027\n",
      "batch_going: 17\n",
      "change in Valid loss: -32.30363368988037\n",
      "batch_going: 18\n",
      "change in Valid loss: -56.303110122680664\n",
      "batch_going: 19\n",
      "change in Valid loss: -35.41325807571411\n",
      "batch_going: 20\n",
      "change in Valid loss: -42.8501033782959\n",
      "batch_going: 21\n",
      "change in Valid loss: -34.83039379119873\n",
      "batch_going: 22\n",
      "change in Valid loss: -36.02848768234253\n",
      "batch_going: 23\n",
      "change in Valid loss: -43.13443660736084\n",
      "batch_going: 24\n",
      "change in Valid loss: -34.45671796798706\n",
      "batch_going: 25\n",
      "change in Valid loss: -39.2023229598999\n",
      "batch_going: 26\n",
      "change in Valid loss: -55.56159019470215\n",
      "batch_going: 27\n",
      "change in Valid loss: -45.05784511566162\n",
      "batch_going: 28\n",
      "change in Valid loss: -51.41312599182129\n",
      "batch_going: 29\n",
      "change in Valid loss: -48.561201095581055\n",
      "batch_going: 30\n",
      "change in Valid loss: -44.32074546813965\n",
      "batch_going: 31\n",
      "change in Valid loss: -56.297264099121094\n",
      "batch_going: 32\n",
      "change in Valid loss: -50.02213478088379\n",
      "batch_going: 33\n",
      "change in Valid loss: -39.299635887145996\n",
      "batch_going: 34\n",
      "change in Valid loss: -53.74575614929199\n",
      "batch_going: 35\n",
      "change in Valid loss: -39.31849002838135\n",
      "batch_going: 36\n",
      "change in Valid loss: -47.01626777648926\n",
      "batch_going: 37\n",
      "change in Valid loss: -54.00280952453613\n",
      "batch_going: 38\n",
      "change in Valid loss: -56.35131359100342\n",
      "batch_going: 39\n",
      "change in Valid loss: -45.00941753387451\n",
      "batch_going: 40\n",
      "change in Valid loss: -52.139692306518555\n",
      "batch_going: 41\n",
      "change in Valid loss: -41.05369567871094\n",
      "batch_going: 42\n",
      "change in Valid loss: -36.89602613449097\n",
      "batch_going: 43\n",
      "change in Valid loss: -43.28979015350342\n",
      "batch_going: 44\n",
      "change in Valid loss: -51.58708095550537\n",
      "batch_going: 45\n",
      "change in Valid loss: -41.95308208465576\n",
      "batch_going: 46\n",
      "change in Valid loss: -41.42560005187988\n",
      "batch_going: 47\n",
      "change in Valid loss: -42.82439708709717\n",
      "batch_going: 48\n",
      "change in Valid loss: -45.64420223236084\n",
      "batch_going: 49\n",
      "change in Valid loss: -42.452406883239746\n",
      "batch_going: 50\n",
      "change in Valid loss: -48.48651885986328\n",
      "batch_going: 51\n",
      "change in Valid loss: -62.485294342041016\n",
      "batch_going: 52\n",
      "change in Valid loss: -50.22794246673584\n",
      "batch_going: 53\n",
      "change in Valid loss: -43.46549034118652\n",
      "batch_going: 54\n",
      "change in Valid loss: -45.48728942871094\n",
      "batch_going: 55\n",
      "change in Valid loss: -57.19453811645508\n",
      "batch_going: 56\n",
      "change in Valid loss: -47.05822944641113\n",
      "batch_going: 57\n",
      "change in Valid loss: -36.82786464691162\n",
      "batch_going: 58\n",
      "change in Valid loss: -43.09863567352295\n",
      "batch_going: 59\n",
      "change in Valid loss: -42.473745346069336\n",
      "batch_going: 60\n",
      "change in Valid loss: -53.80572319030762\n",
      "batch_going: 61\n",
      "change in Valid loss: -43.980584144592285\n",
      "batch_going: 62\n",
      "change in Valid loss: -57.56430149078369\n",
      "batch_going: 63\n",
      "change in Valid loss: -29.27837371826172\n",
      "batch_going: 64\n",
      "change in Valid loss: -47.404351234436035\n",
      "batch_going: 65\n",
      "change in Valid loss: -51.33242607116699\n",
      "batch_going: 66\n",
      "change in Valid loss: -40.14224052429199\n",
      "batch_going: 67\n",
      "change in Valid loss: -37.881622314453125\n",
      "batch_going: 68\n",
      "change in Valid loss: -52.30813980102539\n",
      "batch_going: 69\n",
      "change in Valid loss: -52.184247970581055\n",
      "batch_going: 70\n",
      "change in Valid loss: -51.67628288269043\n",
      "batch_going: 71\n",
      "change in Valid loss: -34.82720613479614\n",
      "batch_going: 72\n",
      "change in Valid loss: -48.76591682434082\n",
      "batch_going: 73\n",
      "change in Valid loss: -51.44132137298584\n",
      "batch_going: 74\n",
      "change in Valid loss: -44.67007637023926\n",
      "batch_going: 75\n",
      "change in Valid loss: -50.8882999420166\n",
      "batch_going: 76\n",
      "change in Valid loss: -46.82260513305664\n",
      "batch_going: 77\n",
      "change in Valid loss: -44.37155246734619\n",
      "batch_going: 78\n",
      "change in Valid loss: -35.10354280471802\n",
      "batch_going: 79\n",
      "change in Valid loss: -53.914384841918945\n",
      "batch_going: 80\n",
      "change in Valid loss: -45.81564426422119\n",
      "batch_going: 81\n",
      "change in Valid loss: -50.655646324157715\n",
      "batch_going: 82\n",
      "change in Valid loss: -38.953304290771484\n",
      "batch_going: 83\n",
      "change in Valid loss: -30.902576446533203\n",
      "Epoch: 7 \tTraining Loss: 20.661553 \tValidation Loss: 46.302273\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -17.651268243789673\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 3.8067996501922607\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: -14.512331485748291\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: 12.276394367218018\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: 1.8878209590911865\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: -4.62628960609436\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: 4.634294509887695\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -2.738621234893799\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 4.753003120422363\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: 2.5428444147109985\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -5.080541968345642\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: -15.663775205612183\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 22.93167233467102\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: -6.647348403930664\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: -2.3347079753875732\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -0.2868950366973877\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 3.8230955600738525\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: -4.179587364196777\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -1.9539713859558105\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: 7.372461557388306\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 0.12691497802734375\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -5.599180459976196\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: 4.31645393371582\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -4.666515588760376\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -2.9072415828704834\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 8.85399580001831\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 0.31623363494873047\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: -5.150465965270996\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: 0.014352798461914062\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: 4.877346754074097\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: -0.645601749420166\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 2.5916272401809692\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: -0.8669394254684448\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: -11.116023063659668\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: 8.57776403427124\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: -1.8478655815124512\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: -2.192060947418213\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 0.35195469856262207\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: -13.20346474647522\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 2.996795177459717\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: 9.135578870773315\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -7.899717092514038\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 8.492780923843384\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -5.062700510025024\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: 7.5737833976745605\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -2.1640491485595703\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: -4.744436740875244\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 7.556729316711426\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -3.9475226402282715\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -0.3724098205566406\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: 3.8547134399414062\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: -9.468045234680176\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 2.4028491973876953\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: 11.074141263961792\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -11.961532831192017\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 9.724791049957275\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: 3.8959842920303345\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -9.13935124874115\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -0.019451379776000977\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: 4.26181435585022\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: -3.4052562713623047\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: 4.0858423709869385\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 1.0284042358398438\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -4.608213901519775\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 6.7079079151153564\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: -8.291913270950317\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: -7.478232383728027\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: 9.776066541671753\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 1.8297696113586426\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -12.688106298446655\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 9.242193698883057\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: 0.7177305221557617\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 2.8378331661224365\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 0.9117567539215088\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -7.767996788024902\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -0.19820213317871094\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 9.166501760482788\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -5.923502445220947\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: -0.8125817775726318\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -5.995011329650879\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 2.8302454948425293\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: 8.461294174194336\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -13.475840091705322\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: 16.40395164489746\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: -6.47343635559082\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: 1.8627989292144775\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -9.175502061843872\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -0.4710721969604492\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: 5.454193353652954\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -5.980976819992065\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 9.347763061523438\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 4.002180099487305\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -1.1122465133666992\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -1.6916894912719727\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: -4.744390249252319\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: 8.146427869796753\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: -8.026977777481079\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: 5.68587064743042\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -10.323251485824585\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 3.8248038291931152\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: -2.5733542442321777\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 4.795185327529907\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: 0.17105698585510254\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -4.357702732086182\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 4.577153921127319\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: 6.001603603363037\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: -4.402520656585693\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: -1.0060763359069824\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -2.650085687637329\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 6.48787260055542\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -0.46805858612060547\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -3.5579299926757812\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 2.12349534034729\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: 2.5549018383026123\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -3.9430630207061768\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: 7.167196273803711\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: -8.262885808944702\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: -3.1447982788085938\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: 3.2633018493652344\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -5.20829439163208\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 8.063225746154785\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: -4.667503833770752\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 5.213290452957153\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -10.458585023880005\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 13.028625249862671\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -4.7140443325042725\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 4.1110169887542725\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: -12.744220495223999\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: 8.854954242706299\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -1.7820429801940918\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: -1.902635097503662\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -0.8141088485717773\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 7.815147638320923\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -6.721113920211792\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: -3.4247732162475586\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: 14.067239165306091\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -12.913467288017273\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: -2.834799289703369\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 13.518127202987671\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -2.429220676422119\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: -6.012827157974243\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: -9.756946563720703\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 1.062474250793457\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 4.093010425567627\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -5.161418914794922\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 16.661070585250854\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: 2.0377159118652344\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: -6.2301647663116455\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -4.213113784790039\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 4.793353080749512\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -1.123502254486084\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: 4.8256516456604\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: -5.673853158950806\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -3.1191885471343994\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 4.621318578720093\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -0.7698404788970947\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: 3.482480049133301\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: -4.074524641036987\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 8.27402114868164\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -8.028323650360107\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: -10.842145681381226\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: 14.263951778411865\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -8.593432903289795\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 7.810931205749512\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -1.0025262832641602\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: -5.47405481338501\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 8.456614017486572\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 0.1513838768005371\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -3.8534963130950928\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: -6.630574464797974\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: 4.062371253967285\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 2.957746982574463\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -6.309940814971924\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: 3.94095778465271\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: -10.562952756881714\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 12.147399187088013\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -1.011955738067627\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: -2.317405939102173\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: 5.1712024211883545\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -3.89703631401062\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 4.015083312988281\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -8.995602130889893\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 6.846960783004761\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: -9.43343997001648\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 6.428382396697998\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 14.296609163284302\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: -9.421000480651855\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -1.2315666675567627\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 7.581106424331665\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -7.518142461776733\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: 0.8153808116912842\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 2.4566292762756348\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: -1.9587790966033936\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: -6.168761253356934\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -1.5558505058288574\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 8.4662926197052\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -3.9315104484558105\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 9.601181149482727\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: -12.590453028678894\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: 8.909423351287842\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -19.47655439376831\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 7.280282974243164\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: 4.684154987335205\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -6.081728935241699\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 4.460759162902832\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: 6.351696252822876\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: -11.630009412765503\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: 7.0717644691467285\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 3.5158121585845947\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 2.4327802658081055\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 0.17252445220947266\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -1.6952931880950928\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -3.0164217948913574\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: -2.731180191040039\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: 4.958219528198242\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: -1.5394902229309082\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 6.350432634353638\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -12.569137811660767\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: 5.858266353607178\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 2.5794196128845215\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: -16.153523921966553\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: 12.900357246398926\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: 1.1616575717926025\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 3.4278392791748047\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -11.486560106277466\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: 2.1125340461730957\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: 8.139058351516724\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -4.076073169708252\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: 1.951134204864502\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 0.9964847564697266\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -1.9235074520111084\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 4.19979453086853\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 2.6859700679779053\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: 1.1492407321929932\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: -10.59630274772644\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: 6.395769119262695\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -0.4167509078979492\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -6.316878795623779\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 0.4622316360473633\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -3.407433032989502\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 0.9869503974914551\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 9.038112163543701\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -3.0818843841552734\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: 6.621767282485962\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -6.2692296504974365\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 5.343129634857178\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: -9.257383346557617\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: -10.010898113250732\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 14.915293455123901\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: 3.0076098442077637\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -5.253536701202393\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: -3.749290704727173\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: 6.129988431930542\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -2.8858792781829834\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: -8.331506252288818\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: 0.19730806350708008\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 13.943244218826294\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: -5.9382617473602295\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: -7.994012832641602\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: 10.054517984390259\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 4.038506746292114\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -11.864979267120361\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: 0.5213260650634766\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 4.417449235916138\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: 7.770185470581055\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -9.827884435653687\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 4.805173873901367\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: -11.927042007446289\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 7.421360015869141\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 1.9190895557403564\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -4.942530393600464\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 0.026335716247558594\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 13.168880939483643\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -5.201786756515503\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -3.9818227291107178\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: -1.465904712677002\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 3.582184314727783\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: -7.7596211433410645\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: 2.667562961578369\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 13.09399962425232\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -5.378185510635376\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: -16.529414653778076\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: 22.634390592575073\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -9.79063630104065\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: 6.679835319519043\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -15.095188617706299\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: 19.1730535030365\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -9.093292951583862\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -5.213444232940674\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 3.507111072540283\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: 9.965723752975464\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -13.154176473617554\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 12.271002531051636\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: -17.620409727096558\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 16.816587448120117\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: -8.807377815246582\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -5.352215766906738\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: 9.9738609790802\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: 3.989579677581787\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: -7.460833787918091\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: 0.39704084396362305\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: 1.587749719619751\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: -7.34951376914978\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 8.495054244995117\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -3.2028985023498535\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -5.6620192527771\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: 7.0133185386657715\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 0.8294451236724854\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: -10.40340542793274\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -2.0207977294921875\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 3.745722770690918\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 5.215821266174316\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: -7.491941452026367\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 5.532271862030029\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: -10.32170057296753\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 20.407148599624634\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -10.400348901748657\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: 0.6104898452758789\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 6.885634660720825\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 1.7454445362091064\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: -15.257728099822998\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: 12.618815898895264\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: 4.3938493728637695\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: -0.553889274597168\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: -14.71916675567627\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 4.561550617218018\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: 8.647671937942505\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: -8.53991150856018\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -5.957117080688477\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 20.070583820343018\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -14.950077533721924\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 6.452376842498779\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: -5.400664806365967\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -14.966669082641602\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: 22.3819899559021\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: -5.9046196937561035\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 5.838690996170044\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: 6.395685076713562\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: -9.311463236808777\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 0.8532154560089111\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: 0.5130636692047119\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -3.2518553733825684\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 7.9274725914001465\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -12.911118268966675\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: 8.146628141403198\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 0.48831820487976074\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: -5.2652716636657715\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: 7.631475925445557\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: -9.918653964996338\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -7.541389465332031\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: 13.20706844329834\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: 6.658793687820435\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: -3.0453503131866455\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: -2.579529285430908\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: -11.013412475585938\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: 12.862119674682617\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: -2.4841320514678955\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -4.3160927295684814\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -2.7217483520507812\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: 3.712162971496582\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: -8.656132221221924\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: 1.1191487312316895\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -2.57004976272583\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 24.40856397151947\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: -19.843963980674744\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: 13.684356212615967\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: -6.505450010299683\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 1.887063980102539\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: 3.6650240421295166\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 1.5991687774658203\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -9.355475902557373\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: 5.1567161083221436\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 1.542966365814209\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -10.137015581130981\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: 14.039461612701416\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: -7.494549751281738\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -3.7537598609924316\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 6.083172559738159\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: -8.301931619644165\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 9.65267300605774\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: -2.6261794567108154\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: -1.4130806922912598\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: 0.7534050941467285\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 1.1269819736480713\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: 2.786058187484741\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: -5.322694778442383\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: -4.974839687347412\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: 11.290831565856934\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 2.847413420677185\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: -0.7975989580154419\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: -2.5552308559417725\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -1.679832935333252\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -7.067568302154541\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: -4.416921138763428\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: 2.2455477714538574\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -4.842569828033447\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 0.5250287055969238\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: 7.643852233886719\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 2.5562310218811035\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 4.159461259841919\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -7.309683561325073\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -3.472878932952881\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 16.584049463272095\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -3.9747190475463867\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -2.339705228805542\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -8.148362636566162\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: -1.1790919303894043\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: 1.8633151054382324\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 4.890308380126953\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -6.182248592376709\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 10.174190998077393\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -5.271787643432617\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: -2.478349208831787\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -2.0123839378356934\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 2.220170497894287\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: 11.920469999313354\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -5.305936336517334\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -8.614856004714966\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 2.1685123443603516\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: 5.2119433879852295\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -9.80296015739441\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: 8.156946897506714\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: -4.380558729171753\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 4.278603792190552\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 1.8444550037384033\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -6.751546859741211\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 1.9476509094238281\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: 2.8704798221588135\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: -6.008051633834839\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: 2.021300792694092\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: 1.1610841751098633\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: -3.9407873153686523\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: 10.904219150543213\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: -18.749945163726807\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: 16.663469076156616\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 2.0280933380126953\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 1.321636438369751\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -15.979416370391846\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: 4.682269096374512\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: 7.724592685699463\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -11.13426685333252\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 6.630158424377441\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -5.350492000579834\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: -3.2756567001342773\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: 14.749114513397217\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: -15.003728866577148\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: 9.150232076644897\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 6.669220924377441\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -14.317117929458618\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: 6.459901332855225\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 6.213974952697754\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: -5.751402378082275\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: 1.4327216148376465\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -5.428347587585449\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 6.771550178527832\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: -1.26198410987854\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: -6.504315137863159\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: -4.716293811798096\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: -2.1544361114501953\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: 15.273047685623169\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: -2.2832143306732178\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 3.413255214691162\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 0.17819762229919434\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: -4.310036897659302\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: 3.9253687858581543\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: -8.13387155532837\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: 5.273571014404297\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -1.327815055847168\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 7.047742605209351\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: -5.54668664932251\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -4.4367969036102295\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 6.472846269607544\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 2.486910820007324\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -7.1270835399627686\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 7.160582542419434\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -11.183483600616455\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 1.6437983512878418\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 4.439510107040405\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: 8.248111009597778\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -15.113935470581055\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: 2.569711208343506\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: 1.7480254173278809\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: -3.8599395751953125\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: 10.749430656433105\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: -9.846546649932861\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 0.6894779205322266\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: 6.658885478973389\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: -4.610309600830078\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: 5.1756203174591064\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: -1.2532806396484375\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: -0.842059850692749\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 3.786904811859131\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: 1.8947577476501465\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: -11.952211856842041\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: 13.386731147766113\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -6.4687347412109375\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -2.179253101348877\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 5.609939098358154\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: 5.306825041770935\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -5.843407511711121\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -1.5154063701629639\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 1.7760848999023438\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -4.008352756500244\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -8.309003114700317\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 9.538089036941528\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -1.1809253692626953\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: 7.364401817321777\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -10.270837545394897\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: -2.7788138389587402\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: 11.0992431640625\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: -4.633059501647949\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: 2.3190438747406006\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: 2.367016077041626\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: -6.467647552490234\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -3.0565857887268066\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -0.6222820281982422\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: -0.8202290534973145\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: -1.2234091758728027\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: 4.683842658996582\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 2.473956346511841\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -3.165956735610962\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: 3.072817325592041\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 6.37709379196167\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -9.666621685028076\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: -0.9450721740722656\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -2.821803092956543\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: -1.3624024391174316\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: 9.849482774734497\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: -4.467343091964722\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 1.903930902481079\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -18.398431539535522\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 22.567883729934692\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 3.535773754119873\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: -7.463947534561157\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: -2.539689540863037\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: -3.611769676208496\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 7.501084804534912\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -6.5206193923950195\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: 7.1029698848724365\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: 3.463228940963745\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -6.56996488571167\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -14.24614667892456\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: -4.185690879821777\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: 3.435492515563965\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: 17.837040424346924\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: -2.5451207160949707\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -6.015274524688721\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -1.2642240524291992\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: 6.341152191162109\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 2.927011251449585\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 1.9515717029571533\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: -3.4039878845214844\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: 5.277684926986694\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: -2.2724485397338867\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -9.193154573440552\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 3.7124228477478027\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: 3.5051488876342773\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: 2.97121524810791\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -6.622025966644287\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: 4.73379373550415\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 0.96382737159729\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -21.981981992721558\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: 6.394705772399902\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: 11.272754669189453\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 5.893347263336182\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: -1.784830093383789\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -8.650264739990234\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: 2.866792678833008\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 4.730937480926514\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 0.10885000228881836\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -5.237021446228027\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: 10.97638726234436\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: -5.78105092048645\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: 3.8857996463775635\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -2.5322437286376953\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: -3.204871416091919\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -2.630167007446289\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -11.435000896453857\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 14.670342206954956\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -7.61043906211853\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: 5.296058654785156\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: -7.063331604003906\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: 10.769840478897095\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: -3.420463800430298\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -0.5854010581970215\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 8.671042919158936\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: -25.039288997650146\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 16.479945182800293\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: 5.822798013687134\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: -7.8890931606292725\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: 10.921353101730347\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: -6.9988977909088135\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -5.88259220123291\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 2.2004008293151855\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: 8.750625848770142\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -9.614001512527466\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: 2.55324125289917\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: -4.958465099334717\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: -0.9753108024597168\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: 9.012374877929688\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: -3.325622081756592\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 3.1123709678649902\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: -0.10887384414672852\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -12.705321311950684\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 15.606299638748169\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: 4.216221570968628\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: -5.48216700553894\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: -10.581375360488892\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: 12.79354214668274\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: 0.7912313938140869\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: 0.2820861339569092\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: -1.3228797912597656\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 1.2646400928497314\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: -13.04807186126709\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 12.461599111557007\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: -12.63292908668518\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 4.085655212402344\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: -5.645260810852051\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: 12.920033931732178\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -8.317258358001709\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: 5.776021480560303\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -2.586946487426758\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -4.969627857208252\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -7.86144495010376\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 9.091963768005371\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 19.488543272018433\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: -15.253063440322876\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -5.108919143676758\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 4.245672225952148\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: 4.240587949752808\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: 2.1878039836883545\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: -11.624250411987305\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -4.233353137969971\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: 3.7796783447265625\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -0.8402514457702637\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -3.61161470413208\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 1.8942880630493164\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 8.297364711761475\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: 4.002282619476318\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -6.660122871398926\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: -4.45364236831665\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: 11.323198080062866\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: 3.7002575397491455\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -3.19632887840271\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: -5.242940187454224\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: 0.8261942863464355\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: -0.8673954010009766\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 1.9055986404418945\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -10.625085830688477\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 15.727965831756592\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -4.502825736999512\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -7.5859808921813965\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: -1.9550251960754395\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 0.14857053756713867\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: 2.9879403114318848\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 1.048579216003418\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 20.129787027835846\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -10.560441315174103\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: -1.7809593677520752\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: -5.761253833770752\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: 7.937890291213989\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -9.679757356643677\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: -6.374673843383789\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: 0.770263671875\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 19.077508449554443\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -3.8868772983551025\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: -15.904396772384644\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 4.187436103820801\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -43.898353576660156\n",
      "batch_going: 1\n",
      "change in Valid loss: -54.51244354248047\n",
      "batch_going: 2\n",
      "change in Valid loss: -42.15973377227783\n",
      "batch_going: 3\n",
      "change in Valid loss: -55.47905445098877\n",
      "batch_going: 4\n",
      "change in Valid loss: -30.123589038848877\n",
      "batch_going: 5\n",
      "change in Valid loss: -40.153207778930664\n",
      "batch_going: 6\n",
      "change in Valid loss: -44.597182273864746\n",
      "batch_going: 7\n",
      "change in Valid loss: -47.307119369506836\n",
      "batch_going: 8\n",
      "change in Valid loss: -48.20624828338623\n",
      "batch_going: 9\n",
      "change in Valid loss: -38.72610569000244\n",
      "batch_going: 10\n",
      "change in Valid loss: -51.58989429473877\n",
      "batch_going: 11\n",
      "change in Valid loss: -36.73561096191406\n",
      "batch_going: 12\n",
      "change in Valid loss: -45.37224292755127\n",
      "batch_going: 13\n",
      "change in Valid loss: -40.03519535064697\n",
      "batch_going: 14\n",
      "change in Valid loss: -51.988463401794434\n",
      "batch_going: 15\n",
      "change in Valid loss: -47.66932010650635\n",
      "batch_going: 16\n",
      "change in Valid loss: -50.23585796356201\n",
      "batch_going: 17\n",
      "change in Valid loss: -47.33992099761963\n",
      "batch_going: 18\n",
      "change in Valid loss: -33.774986267089844\n",
      "batch_going: 19\n",
      "change in Valid loss: -58.5629940032959\n",
      "batch_going: 20\n",
      "change in Valid loss: -42.78709411621094\n",
      "batch_going: 21\n",
      "change in Valid loss: -55.0771427154541\n",
      "batch_going: 22\n",
      "change in Valid loss: -32.487030029296875\n",
      "batch_going: 23\n",
      "change in Valid loss: -43.0018949508667\n",
      "batch_going: 24\n",
      "change in Valid loss: -40.35698890686035\n",
      "batch_going: 25\n",
      "change in Valid loss: -46.468610763549805\n",
      "batch_going: 26\n",
      "change in Valid loss: -61.027588844299316\n",
      "batch_going: 27\n",
      "change in Valid loss: -41.970319747924805\n",
      "batch_going: 28\n",
      "change in Valid loss: -26.181559562683105\n",
      "batch_going: 29\n",
      "change in Valid loss: -41.47212505340576\n",
      "batch_going: 30\n",
      "change in Valid loss: -44.058990478515625\n",
      "batch_going: 31\n",
      "change in Valid loss: -50.91169357299805\n",
      "batch_going: 32\n",
      "change in Valid loss: -50.816802978515625\n",
      "batch_going: 33\n",
      "change in Valid loss: -39.66240406036377\n",
      "batch_going: 34\n",
      "change in Valid loss: -52.99607753753662\n",
      "batch_going: 35\n",
      "change in Valid loss: -41.09182834625244\n",
      "batch_going: 36\n",
      "change in Valid loss: -50.07453441619873\n",
      "batch_going: 37\n",
      "change in Valid loss: -40.49377918243408\n",
      "batch_going: 38\n",
      "change in Valid loss: -49.81836795806885\n",
      "batch_going: 39\n",
      "change in Valid loss: -59.97845649719238\n",
      "batch_going: 40\n",
      "change in Valid loss: -51.622843742370605\n",
      "batch_going: 41\n",
      "change in Valid loss: -47.68548011779785\n",
      "batch_going: 42\n",
      "change in Valid loss: -47.955613136291504\n",
      "batch_going: 43\n",
      "change in Valid loss: -44.24818992614746\n",
      "batch_going: 44\n",
      "change in Valid loss: -63.361639976501465\n",
      "batch_going: 45\n",
      "change in Valid loss: -48.99923801422119\n",
      "batch_going: 46\n",
      "change in Valid loss: -52.13836193084717\n",
      "batch_going: 47\n",
      "change in Valid loss: -51.38630390167236\n",
      "batch_going: 48\n",
      "change in Valid loss: -42.78220176696777\n",
      "batch_going: 49\n",
      "change in Valid loss: -41.926069259643555\n",
      "batch_going: 50\n",
      "change in Valid loss: -52.78118133544922\n",
      "batch_going: 51\n",
      "change in Valid loss: -42.27957725524902\n",
      "batch_going: 52\n",
      "change in Valid loss: -47.124266624450684\n",
      "batch_going: 53\n",
      "change in Valid loss: -45.60915946960449\n",
      "batch_going: 54\n",
      "change in Valid loss: -41.50815963745117\n",
      "batch_going: 55\n",
      "change in Valid loss: -42.863197326660156\n",
      "batch_going: 56\n",
      "change in Valid loss: -43.82978439331055\n",
      "batch_going: 57\n",
      "change in Valid loss: -47.81190872192383\n",
      "batch_going: 58\n",
      "change in Valid loss: -54.59150791168213\n",
      "batch_going: 59\n",
      "change in Valid loss: -51.04569435119629\n",
      "batch_going: 60\n",
      "change in Valid loss: -48.95453453063965\n",
      "batch_going: 61\n",
      "change in Valid loss: -39.73763942718506\n",
      "batch_going: 62\n",
      "change in Valid loss: -49.11435604095459\n",
      "batch_going: 63\n",
      "change in Valid loss: -40.9921932220459\n",
      "batch_going: 64\n",
      "change in Valid loss: -44.853458404541016\n",
      "batch_going: 65\n",
      "change in Valid loss: -48.28326225280762\n",
      "batch_going: 66\n",
      "change in Valid loss: -45.63708305358887\n",
      "batch_going: 67\n",
      "change in Valid loss: -45.97090721130371\n",
      "batch_going: 68\n",
      "change in Valid loss: -47.69750118255615\n",
      "batch_going: 69\n",
      "change in Valid loss: -50.38522243499756\n",
      "batch_going: 70\n",
      "change in Valid loss: -41.55754089355469\n",
      "batch_going: 71\n",
      "change in Valid loss: -45.03775119781494\n",
      "batch_going: 72\n",
      "change in Valid loss: -60.15869617462158\n",
      "batch_going: 73\n",
      "change in Valid loss: -46.8598747253418\n",
      "batch_going: 74\n",
      "change in Valid loss: -45.82886219024658\n",
      "batch_going: 75\n",
      "change in Valid loss: -47.80771732330322\n",
      "batch_going: 76\n",
      "change in Valid loss: -52.98962593078613\n",
      "batch_going: 77\n",
      "change in Valid loss: -45.63298225402832\n",
      "batch_going: 78\n",
      "change in Valid loss: -46.31566047668457\n",
      "batch_going: 79\n",
      "change in Valid loss: -40.039687156677246\n",
      "batch_going: 80\n",
      "change in Valid loss: -37.499470710754395\n",
      "batch_going: 81\n",
      "change in Valid loss: -63.82753372192383\n",
      "batch_going: 82\n",
      "change in Valid loss: -65.34464836120605\n",
      "batch_going: 83\n",
      "change in Valid loss: -32.12118148803711\n",
      "Epoch: 8 \tTraining Loss: 19.082781 \tValidation Loss: 46.588078\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -11.135900020599365\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: -5.6516289710998535\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 9.744996428489685\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -3.8144999742507935\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: 0.25338292121887207\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: -5.08486270904541\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -9.52336311340332\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: 7.787400484085083\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: -1.9300782680511475\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: 3.4134113788604736\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -2.841264009475708\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 1.2880682945251465\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 8.271493315696716\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: -6.8888479471206665\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: -5.050450563430786\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: 11.789433360099792\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: -9.230733513832092\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 4.973541498184204\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -2.990347146987915\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: 6.131279468536377\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 1.9774794578552246\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -4.342819452285767\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: -9.215865135192871\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: 5.955641269683838\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: 2.7634477615356445\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: -0.9211146831512451\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 4.455299377441406\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 0.33832550048828125\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -3.5696887969970703\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -3.687490224838257\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 4.896385669708252\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: -4.78458046913147\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 1.5081608295440674\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 5.7011836767196655\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -14.070705771446228\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: -1.8415451049804688\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: 7.884020805358887\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 1.9759666919708252\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 1.6987955570220947\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 7.098678350448608\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -3.466113805770874\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: 3.3638113737106323\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: -4.745845198631287\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -5.141628980636597\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: 1.6278493404388428\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: 2.9584968090057373\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 4.060140252113342\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: -1.4027100801467896\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -5.875294208526611\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -0.3804302215576172\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -2.445864677429199\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 0.017538070678710938\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: -13.97720456123352\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: 16.49113655090332\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: 9.290640354156494\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: -13.433065414428711\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: 8.519558906555176\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: -3.492138385772705\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: 4.009120464324951\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -12.459447383880615\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 16.963969469070435\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -24.293562173843384\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 18.044222593307495\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -12.197040319442749\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 8.975406885147095\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 7.492663860321045\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: -12.978485822677612\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: 5.065343379974365\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 6.028461456298828\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -5.406594276428223\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: -4.806461334228516\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: 1.3671541213989258\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 1.016312837600708\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 1.953948736190796\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: 3.250105381011963\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -0.051767826080322266\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: -7.326493263244629\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: 4.321101903915405\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 3.075019121170044\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -0.9366774559020996\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: -2.904336452484131\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -1.4782285690307617\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: 4.5049965381622314\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: -12.542191743850708\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 16.159991025924683\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -8.48659873008728\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -2.822253704071045\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: 4.879963397979736\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -0.3549814224243164\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: 6.698232293128967\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: -5.732077956199646\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: -11.606813669204712\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: 13.040075302124023\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -0.7395458221435547\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 1.1254918575286865\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: 3.8279080390930176\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: -3.279242515563965\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -1.2499141693115234\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -8.687390089035034\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 1.798841953277588\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: -1.287827491760254\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 10.109332799911499\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: 3.738570213317871\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: -14.699293375015259\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 10.891435146331787\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: 5.1625072956085205\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: -18.410815000534058\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 19.59097981452942\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -8.467563390731812\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 1.852867603302002\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: 2.7985262870788574\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -7.6557886600494385\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 2.405291795730591\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -0.1468515396118164\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -0.17432808876037598\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: 8.679405450820923\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: -11.318269968032837\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 4.484920501708984\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -6.282378435134888\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: 1.979234218597412\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: -4.516239166259766\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 10.282771587371826\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 0.11464238166809082\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -1.814131736755371\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 1.4545118808746338\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: 1.4936327934265137\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 2.3993510007858276\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: -4.022310376167297\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -15.671395063400269\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: 10.60520052909851\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 4.653338193893433\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -1.0149669647216797\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 4.345223903656006\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -3.3354926109313965\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: -0.7587480545043945\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: 4.9713146686553955\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -11.006702184677124\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 8.329249620437622\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: -12.751823663711548\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -1.4834046363830566\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 3.31373929977417\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 8.410966396331787\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 0.4501771926879883\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: -8.631782531738281\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: 4.405512809753418\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 9.442256689071655\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -21.13204836845398\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 19.8486989736557\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -4.1475313901901245\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: -3.5231852531433105\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: 2.191261053085327\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -2.5268054008483887\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 2.3624086380004883\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: 2.319042682647705\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 1.760627031326294\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -8.919169902801514\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -1.6305327415466309\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 12.5703626871109\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: -16.352160573005676\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: 1.2514591217041016\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 2.730424404144287\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -2.7073073387145996\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: 10.821945667266846\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 0.2582979202270508\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -6.929457187652588\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 9.681018590927124\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: -8.71790885925293\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: -5.888172388076782\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: 11.822800636291504\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: -0.8798325061798096\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -2.1921133995056152\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: -3.3924448490142822\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -1.2486815452575684\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: 6.354691982269287\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: -5.68690299987793\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 9.136829376220703\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: 1.0801947116851807\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: -2.100057601928711\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -14.212111234664917\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -1.5952777862548828\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 15.253503322601318\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: 6.889829635620117\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: -9.549294710159302\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: -0.12632131576538086\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 6.892423033714294\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: -7.822625041007996\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 3.016083240509033\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: 4.884442687034607\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: -14.951174855232239\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: 6.9167399406433105\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -8.047740459442139\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 7.875018119812012\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: -7.594504356384277\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 0.10355949401855469\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: 8.158135414123535\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: -2.1333539485931396\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -3.37260365486145\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 5.459822416305542\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 3.1275033950805664\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: 2.4571800231933594\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -2.6501941680908203\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: -2.7968037128448486\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -4.371893405914307\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -8.18324327468872\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 25.321288108825684\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -7.53351092338562\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: -10.350576639175415\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: 10.416703224182129\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: -6.212896108627319\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 0.08285880088806152\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: -2.7616918087005615\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: 4.412018060684204\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -6.154985427856445\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 4.374593496322632\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: 0.22902727127075195\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: -0.15839815139770508\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: -6.3726794719696045\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: 1.0765790939331055\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -3.275275230407715\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 11.4882493019104\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: -5.293666124343872\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -5.419849157333374\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: 3.107924461364746\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 12.77402639389038\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -9.390995502471924\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -7.149467468261719\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: 14.544129371643066\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -10.147526264190674\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: 3.1148290634155273\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 1.1734890937805176\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -2.3879265785217285\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 12.045820355415344\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: -11.182268261909485\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: 7.053227424621582\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: -14.213781356811523\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: 10.959309339523315\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -3.073432445526123\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -2.527261972427368\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 2.7629947662353516\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: 3.6712241172790527\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: -1.9272112846374512\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: -5.688934326171875\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: 1.8981516361236572\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -2.3553478717803955\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: 11.290535926818848\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: -11.273138523101807\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 9.041910171508789\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: -7.739105224609375\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: -0.9404659271240234\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: 9.029693603515625\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -12.481470108032227\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: -9.541933536529541\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: 21.451557874679565\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -3.2842540740966797\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 6.214298605918884\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -4.247291684150696\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 2.6519083976745605\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 1.6180980205535889\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: -8.895063400268555\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -8.154743909835815\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 8.925304412841797\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -1.549072265625\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -5.011131763458252\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 1.8526291847229004\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: 7.677211761474609\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -5.923943519592285\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 4.81258749961853\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 2.2493839263916016\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: -2.261190414428711\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 5.9517598152160645\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -7.953091859817505\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 2.969229221343994\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: -0.7675361633300781\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: 2.8759407997131348\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -2.4800825119018555\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: -1.928025484085083\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 0.5176007747650146\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 0.9430849552154541\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -3.599294424057007\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 10.575233101844788\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -5.414251685142517\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: -6.569193601608276\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: 8.404209613800049\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -5.589971542358398\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: 1.8784236907958984\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: 3.149232864379883\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -1.2162590026855469\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: 0.8302402496337891\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -11.787667274475098\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 8.616759777069092\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -3.6361026763916016\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: 1.1066210269927979\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 1.5815067291259766\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: -5.950382947921753\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 3.8645827770233154\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 5.010278224945068\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -4.050651788711548\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: 3.651801347732544\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: 6.329739689826965\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: -11.563732028007507\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -0.38307666778564453\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: 9.220446348190308\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: -3.167390823364258\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: 4.305211305618286\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -5.169491767883301\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: 9.74729299545288\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -15.6868314743042\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 1.024937629699707\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 9.541956186294556\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -10.125092267990112\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: -4.602909088134766\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 6.3324058055877686\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: -2.178248167037964\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 5.0739967823028564\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: -8.31295132637024\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 8.995389938354492\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: 3.5378575325012207\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: 1.0292446613311768\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: -1.276261806488037\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: -18.075257539749146\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 17.478644847869873\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -15.634310245513916\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: 13.347433805465698\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: -1.50002121925354\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: -4.965882301330566\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 1.3671445846557617\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: 8.106634616851807\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 2.5926411151885986\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -6.300088167190552\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 3.610893487930298\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -4.525692462921143\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 2.87434458732605\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: -8.522300720214844\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: 12.617621421813965\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -5.162848234176636\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: -15.532463788986206\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 16.891319751739502\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: -3.677554130554199\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: 2.0143485069274902\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 0.9077179431915283\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: 5.173998475074768\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -8.217366337776184\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 3.029935359954834\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -10.269609689712524\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -3.9106202125549316\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 7.234101295471191\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 3.287076950073242\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -4.130253791809082\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 1.6281533241271973\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: 6.52483344078064\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -0.15478968620300293\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: -3.683058023452759\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 0.8419263362884521\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 2.3693811893463135\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: -1.4787936210632324\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: -8.036586046218872\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 12.230119705200195\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -8.322241306304932\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: 7.648439407348633\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -1.9691932201385498\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: -4.467954635620117\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: 2.3856663703918457\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -7.8770911693573\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 2.9681038856506348\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: 5.377095937728882\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: -3.9951932430267334\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: -0.3406858444213867\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 11.967650651931763\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: -0.9457838535308838\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: -3.919738531112671\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -1.2403488159179688\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -12.29061245918274\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 20.154056549072266\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -6.065026521682739\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: -7.591723203659058\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: 5.6104958057403564\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -10.629006624221802\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 0.13254165649414062\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: 3.358621597290039\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 5.5950117111206055\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: 0.18835067749023438\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 4.505900144577026\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -3.8855481147766113\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 8.017528057098389\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -6.806536912918091\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: -7.507569789886475\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 5.409090518951416\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -5.432024002075195\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: -2.181429862976074\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 10.252699851989746\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: 5.656088590621948\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -3.968074321746826\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: 0.608903169631958\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 0.9962606430053711\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: -7.664710283279419\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: 4.165080785751343\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 3.066239356994629\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: 1.337255835533142\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: -12.557174563407898\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 1.0667920112609863\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: 7.076654434204102\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: 0.1846146583557129\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 2.6538443565368652\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -5.18524169921875\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -8.004508018493652\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -3.0695009231567383\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 18.659833669662476\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -13.46676230430603\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 6.088434457778931\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -0.2817690372467041\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 5.341097116470337\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -4.558769464492798\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 1.3721656799316406\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -14.685556888580322\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 17.31288194656372\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: -0.7365655899047852\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -3.888695240020752\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -2.515547275543213\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: -2.5456857681274414\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: 0.31768083572387695\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -5.484619140625\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: 9.718960523605347\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: -2.509164810180664\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: -2.0378577709198\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 4.607746601104736\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: -5.718908309936523\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 12.648687362670898\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -16.938400268554688\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 5.6395697593688965\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: 6.299779415130615\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -5.836825370788574\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: -0.2381443977355957\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: 4.0153419971466064\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: -13.222960233688354\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: 13.241324424743652\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 1.6956961154937744\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: -8.831228017807007\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: 7.656235694885254\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: 5.926042795181274\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -18.10536503791809\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: 7.310428619384766\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 7.0990073680877686\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -4.918782711029053\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: -4.54724907875061\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: 9.633650779724121\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 0.528876781463623\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: -19.55404043197632\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 15.79441785812378\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -5.313739776611328\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: 0.6286263465881348\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 7.608299255371094\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 2.9698240756988525\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -9.60445523262024\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: 5.8255839347839355\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: -15.605967044830322\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: 16.56087636947632\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: 0.5197429656982422\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: 2.692502737045288\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: -8.016077280044556\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -0.4030919075012207\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: -6.05771541595459\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 1.3454246520996094\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 11.942605972290039\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: -2.9022645950317383\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -5.101935863494873\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 8.3561372756958\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: -3.378676176071167\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -9.790087938308716\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 5.292222499847412\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 7.549527883529663\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -9.27700400352478\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 11.116656064987183\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: -3.531852960586548\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -5.6269824504852295\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 5.112674236297607\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: 1.0517966747283936\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: -1.1795520782470703\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: -11.783854961395264\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: 7.294396162033081\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -2.9961049556732178\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: 0.45339107513427734\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -1.0889482498168945\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: 0.8770275115966797\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: 5.065860748291016\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 1.513509750366211\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: -5.748045444488525\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: 4.472982883453369\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 1.5783417224884033\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -5.137990713119507\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 6.230535507202148\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: 1.2606430053710938\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: -1.2581586837768555\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -7.044553756713867\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 10.308597087860107\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: -9.101928472518921\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: 3.132392168045044\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -11.541574001312256\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 19.606882333755493\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -4.723851680755615\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -10.49467921257019\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: 8.817371129989624\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: -0.5009245872497559\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -4.068260192871094\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -7.364145517349243\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 17.55963444709778\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -14.919229745864868\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: 15.482260584831238\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -13.548535704612732\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: 5.5733442306518555\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: -4.844925403594971\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: 6.89365029335022\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: -11.711550951004028\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: 8.508579730987549\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: 1.5128552913665771\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -1.4094066619873047\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: 1.5575993061065674\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 5.775972604751587\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: -11.946321725845337\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: 3.4522557258605957\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: -6.343624591827393\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: 16.633616089820862\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -8.980904221534729\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 5.7067060470581055\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -15.971064567565918\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 17.548937797546387\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -6.645996570587158\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: -4.145035743713379\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: 3.0297017097473145\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: 1.252056360244751\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 0.30059218406677246\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -14.748024940490723\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 2.4247026443481445\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 6.037344932556152\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: 4.303145408630371\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 3.394671678543091\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: -3.807234764099121\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 3.2648885250091553\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -4.295945167541504\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: 1.2869596481323242\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: 2.7396953105926514\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -6.3920676708221436\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: 1.6570568084716797\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 3.1571757793426514\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: 4.539909362792969\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: -1.3906967639923096\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: -8.123738765716553\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -0.28711795806884766\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -4.740707874298096\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: 2.9515981674194336\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 10.068583488464355\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 1.6987788677215576\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: 1.206282377243042\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: -3.434321880340576\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: -0.9936690330505371\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -11.70236587524414\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 13.720029592514038\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -7.136050462722778\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: 15.996023416519165\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -10.836647748947144\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: 9.306968450546265\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: -14.12946105003357\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: 6.132127046585083\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: -2.5344526767730713\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -6.937081813812256\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: -12.1189546585083\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: 12.930123805999756\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: 5.577597618103027\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: 7.2126054763793945\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 1.5375292301177979\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: -5.519727468490601\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -8.42247724533081\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: 8.322858810424805\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 3.8550376892089844\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: 1.34147047996521\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -14.417766332626343\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 9.756226539611816\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -18.61182928085327\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: 18.903969526290894\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: -2.165728807449341\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: 0.7654762268066406\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -2.49478816986084\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: -2.6847243309020996\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: 2.6849365234375\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: -7.853546142578125\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: 10.50402045249939\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: -0.5587923526763916\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: -13.77403974533081\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 10.068156719207764\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: -10.79357385635376\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 15.622758865356445\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: -4.07498836517334\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: -2.4322080612182617\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -1.6206741333007812\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 7.04845666885376\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: -1.347665786743164\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -5.8821940422058105\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: 7.536265850067139\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 1.7161405086517334\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: -14.39226746559143\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: 10.693981647491455\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 0.2881968021392822\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: -7.522686719894409\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 12.609870433807373\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -3.1510889530181885\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: -0.30503273010253906\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: -6.144062280654907\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 3.8643765449523926\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: 0.2033400535583496\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: 4.745466709136963\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: -10.607597827911377\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -1.388230323791504\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: 4.676485061645508\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: -4.548676013946533\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 0.6438469886779785\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 0.7412004470825195\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 7.0878636837005615\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: -5.081275701522827\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 5.063934326171875\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -1.0808491706848145\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: 7.568930983543396\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -10.763508677482605\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: 5.314916372299194\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -9.864195585250854\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: 0.2813100814819336\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 1.684417724609375\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 8.614047765731812\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: -2.852567434310913\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -2.85367488861084\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 6.5339648723602295\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -9.77556586265564\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: 3.4255504608154297\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 7.159435749053955\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: 0.12608766555786133\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: 0.7191359996795654\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -5.984560251235962\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -7.717127799987793\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 10.855486392974854\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 2.919790744781494\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -2.071336507797241\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -6.080484390258789\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: -6.474560499191284\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: 9.548827409744263\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -9.37256932258606\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: 9.575095176696777\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 6.749288439750671\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -13.881413340568542\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 16.302074193954468\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: -16.61650061607361\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: 7.9059672355651855\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 0.6785106658935547\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -1.944035291671753\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -0.665283203125\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: -1.364450454711914\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 4.6256303787231445\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -17.109006643295288\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 13.126002550125122\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 3.2521820068359375\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: 5.29423713684082\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: -2.814035415649414\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: -8.033775091171265\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -4.354102611541748\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -10.052423477172852\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 20.993170738220215\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -2.433624267578125\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: -5.216467380523682\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -5.977365970611572\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: -0.5230331420898438\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 9.214756488800049\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -44.78264808654785\n",
      "batch_going: 1\n",
      "change in Valid loss: -49.13729667663574\n",
      "batch_going: 2\n",
      "change in Valid loss: -45.68432807922363\n",
      "batch_going: 3\n",
      "change in Valid loss: -45.11246204376221\n",
      "batch_going: 4\n",
      "change in Valid loss: -41.56285762786865\n",
      "batch_going: 5\n",
      "change in Valid loss: -51.269474029541016\n",
      "batch_going: 6\n",
      "change in Valid loss: -51.327714920043945\n",
      "batch_going: 7\n",
      "change in Valid loss: -38.06124925613403\n",
      "batch_going: 8\n",
      "change in Valid loss: -57.92809009552002\n",
      "batch_going: 9\n",
      "change in Valid loss: -38.0357551574707\n",
      "batch_going: 10\n",
      "change in Valid loss: -54.63090419769287\n",
      "batch_going: 11\n",
      "change in Valid loss: -45.831265449523926\n",
      "batch_going: 12\n",
      "change in Valid loss: -49.89396095275879\n",
      "batch_going: 13\n",
      "change in Valid loss: -46.724419593811035\n",
      "batch_going: 14\n",
      "change in Valid loss: -38.47412586212158\n",
      "batch_going: 15\n",
      "change in Valid loss: -47.79227256774902\n",
      "batch_going: 16\n",
      "change in Valid loss: -50.17812252044678\n",
      "batch_going: 17\n",
      "change in Valid loss: -37.39025592803955\n",
      "batch_going: 18\n",
      "change in Valid loss: -43.63407611846924\n",
      "batch_going: 19\n",
      "change in Valid loss: -34.14822816848755\n",
      "batch_going: 20\n",
      "change in Valid loss: -37.387263774871826\n",
      "batch_going: 21\n",
      "change in Valid loss: -69.00203704833984\n",
      "batch_going: 22\n",
      "change in Valid loss: -51.40852451324463\n",
      "batch_going: 23\n",
      "change in Valid loss: -44.8551607131958\n",
      "batch_going: 24\n",
      "change in Valid loss: -43.7591552734375\n",
      "batch_going: 25\n",
      "change in Valid loss: -48.75729560852051\n",
      "batch_going: 26\n",
      "change in Valid loss: -52.12955951690674\n",
      "batch_going: 27\n",
      "change in Valid loss: -39.42355394363403\n",
      "batch_going: 28\n",
      "change in Valid loss: -36.566548347473145\n",
      "batch_going: 29\n",
      "change in Valid loss: -47.37804412841797\n",
      "batch_going: 30\n",
      "change in Valid loss: -50.27475833892822\n",
      "batch_going: 31\n",
      "change in Valid loss: -50.238142013549805\n",
      "batch_going: 32\n",
      "change in Valid loss: -45.08902549743652\n",
      "batch_going: 33\n",
      "change in Valid loss: -46.466007232666016\n",
      "batch_going: 34\n",
      "change in Valid loss: -40.666704177856445\n",
      "batch_going: 35\n",
      "change in Valid loss: -45.152411460876465\n",
      "batch_going: 36\n",
      "change in Valid loss: -70.39364814758301\n",
      "batch_going: 37\n",
      "change in Valid loss: -41.986098289489746\n",
      "batch_going: 38\n",
      "change in Valid loss: -43.29329490661621\n",
      "batch_going: 39\n",
      "change in Valid loss: -57.80540943145752\n",
      "batch_going: 40\n",
      "change in Valid loss: -53.80793571472168\n",
      "batch_going: 41\n",
      "change in Valid loss: -52.31644630432129\n",
      "batch_going: 42\n",
      "change in Valid loss: -42.48876094818115\n",
      "batch_going: 43\n",
      "change in Valid loss: -53.58639717102051\n",
      "batch_going: 44\n",
      "change in Valid loss: -66.31108283996582\n",
      "batch_going: 45\n",
      "change in Valid loss: -42.26809024810791\n",
      "batch_going: 46\n",
      "change in Valid loss: -60.515875816345215\n",
      "batch_going: 47\n",
      "change in Valid loss: -56.23093605041504\n",
      "batch_going: 48\n",
      "change in Valid loss: -70.08764743804932\n",
      "batch_going: 49\n",
      "change in Valid loss: -46.7900276184082\n",
      "batch_going: 50\n",
      "change in Valid loss: -60.24559020996094\n",
      "batch_going: 51\n",
      "change in Valid loss: -40.558366775512695\n",
      "batch_going: 52\n",
      "change in Valid loss: -50.48684120178223\n",
      "batch_going: 53\n",
      "change in Valid loss: -54.52946662902832\n",
      "batch_going: 54\n",
      "change in Valid loss: -40.99173545837402\n",
      "batch_going: 55\n",
      "change in Valid loss: -52.130231857299805\n",
      "batch_going: 56\n",
      "change in Valid loss: -47.079782485961914\n",
      "batch_going: 57\n",
      "change in Valid loss: -49.45408821105957\n",
      "batch_going: 58\n",
      "change in Valid loss: -35.058369636535645\n",
      "batch_going: 59\n",
      "change in Valid loss: -29.53192949295044\n",
      "batch_going: 60\n",
      "change in Valid loss: -55.07471561431885\n",
      "batch_going: 61\n",
      "change in Valid loss: -42.874956130981445\n",
      "batch_going: 62\n",
      "change in Valid loss: -58.432602882385254\n",
      "batch_going: 63\n",
      "change in Valid loss: -47.60570526123047\n",
      "batch_going: 64\n",
      "change in Valid loss: -47.69950866699219\n",
      "batch_going: 65\n",
      "change in Valid loss: -44.68162536621094\n",
      "batch_going: 66\n",
      "change in Valid loss: -50.64133644104004\n",
      "batch_going: 67\n",
      "change in Valid loss: -39.53736066818237\n",
      "batch_going: 68\n",
      "change in Valid loss: -51.71265125274658\n",
      "batch_going: 69\n",
      "change in Valid loss: -44.21799659729004\n",
      "batch_going: 70\n",
      "change in Valid loss: -53.10699462890625\n",
      "batch_going: 71\n",
      "change in Valid loss: -44.05538082122803\n",
      "batch_going: 72\n",
      "change in Valid loss: -45.24428367614746\n",
      "batch_going: 73\n",
      "change in Valid loss: -41.05380058288574\n",
      "batch_going: 74\n",
      "change in Valid loss: -51.238412857055664\n",
      "batch_going: 75\n",
      "change in Valid loss: -46.88433647155762\n",
      "batch_going: 76\n",
      "change in Valid loss: -56.54648780822754\n",
      "batch_going: 77\n",
      "change in Valid loss: -48.76689910888672\n",
      "batch_going: 78\n",
      "change in Valid loss: -32.24609851837158\n",
      "batch_going: 79\n",
      "change in Valid loss: -30.821866989135742\n",
      "batch_going: 80\n",
      "change in Valid loss: -46.966590881347656\n",
      "batch_going: 81\n",
      "change in Valid loss: -42.58990287780762\n",
      "batch_going: 82\n",
      "change in Valid loss: -43.41376304626465\n",
      "batch_going: 83\n",
      "change in Valid loss: -19.315239191055298\n",
      "Epoch: 9 \tTraining Loss: 17.379726 \tValidation Loss: 47.176551\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -14.877674579620361\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 1.5761315822601318\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: -5.6340861320495605\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: 5.974467992782593\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -5.6899237632751465\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 13.275941610336304\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -1.3998627662658691\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -14.618953466415405\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 4.4927215576171875\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -5.909788608551025\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: 15.018573999404907\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: -5.90593695640564\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: 1.4210212230682373\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: -8.953920602798462\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 6.74511194229126\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: 1.8969392776489258\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 2.288910150527954\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: -5.3704142570495605\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: 7.969641089439392\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -1.0933643579483032\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: -0.27153611183166504\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: 1.9039452075958252\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: -6.20364785194397\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -0.6170225143432617\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -4.634114503860474\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 12.176393270492554\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: -8.320482969284058\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 0.06150007247924805\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: 1.681680679321289\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -3.8352620601654053\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: -11.147750616073608\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 9.39873218536377\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 2.0502209663391113\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 1.1416411399841309\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: 7.8210508823394775\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: -10.104978084564209\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: -8.452435731887817\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 12.850806713104248\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 4.864882230758667\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: -0.1661372184753418\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -6.144853830337524\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -8.561720848083496\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 9.05409574508667\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: 8.697428107261658\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -10.88638961315155\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: 2.910299301147461\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 1.9513356685638428\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: -1.2978100776672363\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: 1.3493835926055908\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: 4.617951512336731\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -10.200442671775818\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 4.230989217758179\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: -0.18452167510986328\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -6.787910461425781\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: 11.976377964019775\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 3.0179643630981445\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -8.688619136810303\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: 0.8380162715911865\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -1.7216908931732178\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -14.964873790740967\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 13.70684027671814\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -8.86975884437561\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 15.974071025848389\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -1.3052845001220703\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: -4.515345096588135\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 8.647415041923523\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 0.4718083143234253\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -8.739588260650635\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: -9.21681523323059\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: 12.79086947441101\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 5.774741470813751\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -11.684363186359406\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 6.162962913513184\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: -2.673022747039795\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: 1.241391897201538\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -4.786381721496582\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 1.802361011505127\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: 6.777783632278442\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: -3.3257174491882324\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -4.2192792892456055\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 6.933549642562866\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -6.5659308433532715\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: 3.1621289253234863\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: 6.687108874320984\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: -7.32627809047699\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -8.715417385101318\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: 0.4084205627441406\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: 8.579288721084595\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -3.2258689403533936\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -0.058002471923828125\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 6.170133948326111\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 0.3072035312652588\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: 1.8189388513565063\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -4.4197046756744385\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: -1.8584692478179932\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -6.678849458694458\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 12.130012512207031\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -1.5842926502227783\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -9.666181802749634\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 9.773587584495544\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 2.354363799095154\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: -6.818535327911377\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -1.4775538444519043\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: 5.770473480224609\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: -3.7278735637664795\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -3.9927518367767334\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: -1.1710166931152344\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 2.610269784927368\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: 6.605600118637085\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 0.6335854530334473\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -8.749693632125854\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -2.069697380065918\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 11.339307427406311\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -5.220410227775574\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: 1.5366625785827637\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -0.31786084175109863\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: -12.409536838531494\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 14.565887451171875\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -7.88725733757019\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: 3.405231237411499\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 9.99435842037201\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: -7.218591570854187\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: -1.4655578136444092\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -3.564002513885498\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 8.51072371006012\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -12.857455611228943\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 5.164356231689453\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 6.930013298988342\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -8.770089745521545\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: 1.5519487857818604\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 11.254159808158875\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -4.322931170463562\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: -4.870959520339966\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -2.951449155807495\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 10.51259160041809\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -5.3038811683654785\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -3.8583552837371826\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 9.365425109863281\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: -0.37056565284729004\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -15.842838287353516\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 13.533068895339966\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: -6.439087390899658\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: -4.31592583656311\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 9.345906972885132\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -5.995044708251953\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 2.011997699737549\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -10.879303216934204\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 16.442039608955383\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -7.354328036308289\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 9.728479385375977\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -11.919454336166382\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -2.3839712142944336\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 11.356196999549866\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -6.231761574745178\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 4.244554042816162\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -4.698621034622192\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: 5.8235132694244385\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: -10.763623714447021\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 7.303075790405273\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -0.7251405715942383\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 4.8972392082214355\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -7.401907444000244\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -1.5518152713775635\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 6.934554576873779\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -1.1532890796661377\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 1.4783918857574463\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 1.5297883749008179\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 0.8038139343261719\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -8.553041815757751\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 8.516731262207031\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -7.646690607070923\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: -2.463548183441162\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: 3.081737756729126\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -1.0607719421386719\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 5.003387928009033\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: -1.9950461387634277\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -9.74915623664856\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 11.834361553192139\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: 2.523949146270752\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -10.346822738647461\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 2.037290334701538\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: 0.4753243923187256\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 0.17724990844726562\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 5.114055871963501\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: -6.58063530921936\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 7.053771018981934\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: -9.27560806274414\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: 4.354805946350098\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 8.243353366851807\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -17.632062435150146\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: 6.257106065750122\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 6.088125705718994\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: -8.781810998916626\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: 3.3378052711486816\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -3.9321517944335938\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 4.188636541366577\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -3.364626169204712\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 7.136931419372559\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 4.418365955352783\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -1.3380956649780273\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -11.509158611297607\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 10.135432481765747\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -4.0039753913879395\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -3.414105176925659\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 16.09806537628174\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -15.30673623085022\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 5.960153341293335\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -6.2483811378479\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 8.486883640289307\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: -7.156566381454468\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 7.197932004928589\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -0.06147146224975586\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -1.1261248588562012\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: -4.558688402175903\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -0.6057131290435791\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 2.2583889961242676\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: -0.44678330421447754\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -8.70167851448059\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: 10.161974430084229\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 8.182834386825562\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: -4.811139106750488\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -3.1194841861724854\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -3.089134693145752\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 8.564777970314026\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -2.04764187335968\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -5.366001129150391\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -11.114740371704102\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: 13.444406986236572\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: 4.573865532875061\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: -5.50123393535614\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -0.10734796524047852\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 2.5311267375946045\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 7.71366685628891\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: -8.318431079387665\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: -10.03512978553772\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: 3.297450542449951\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: 4.259934425354004\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: -8.386766910552979\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: -2.982943058013916\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: 7.501940727233887\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 6.747149229049683\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: -2.9967105388641357\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: 7.944389581680298\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -3.48818302154541\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -4.179435968399048\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: -0.3977787494659424\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: -0.8401429653167725\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 2.169063091278076\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 2.7925562858581543\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -9.13550853729248\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: 3.5264742374420166\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 6.027120351791382\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -8.011322021484375\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -0.01179814338684082\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 3.308265209197998\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -2.6033568382263184\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: 7.9834675788879395\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 2.141066789627075\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: -12.068638801574707\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: 4.812281131744385\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 4.534786939620972\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -4.5708167552948\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -12.59953498840332\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 18.311684131622314\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: 5.540311932563782\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -9.71020758152008\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: -0.691826343536377\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 10.063902735710144\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: -9.40747320652008\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: -1.6965091228485107\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -1.5208816528320312\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 9.026746153831482\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: -14.477352499961853\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: 4.074039459228516\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -6.1733174324035645\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 4.164755344390869\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: -9.854931831359863\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 16.43480658531189\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -13.443256616592407\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 8.27161431312561\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: 1.4249324798583984\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 9.296939373016357\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -10.099903345108032\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: 3.9984023571014404\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -12.303322553634644\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: 9.176082611083984\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -7.411918640136719\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: 16.047552824020386\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: 2.6679664850234985\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: -8.091859221458435\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -3.4754323959350586\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -1.9423127174377441\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: 6.7547667026519775\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 3.1339025497436523\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: -3.995453119277954\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 0.19361019134521484\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: 4.2623138427734375\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -5.523816347122192\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -0.4300975799560547\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: -1.1187589168548584\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: 7.074968218803406\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -4.752568602561951\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: -1.4990901947021484\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: -1.2677884101867676\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: 5.1655519008636475\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -0.9728920459747314\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -12.29886770248413\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 15.337908267974854\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: -6.940698623657227\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: 2.600064277648926\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 0.9285569190979004\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 0.9084296226501465\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: -11.544630527496338\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 5.894730091094971\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 4.196357727050781\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 3.0614233016967773\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -5.165262222290039\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -4.852509498596191\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 7.422029972076416\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 0.9756946563720703\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: -7.067669630050659\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: 11.975488066673279\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -11.652877926826477\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 5.8068883419036865\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 2.6590609550476074\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: -0.45498013496398926\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -4.09611701965332\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: -2.554776668548584\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -5.68709135055542\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 1.2795257568359375\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: 6.7851972579956055\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: -4.6074628829956055\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 13.157938122749329\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -15.593515038490295\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -0.582427978515625\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: 9.836146831512451\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: -8.10765027999878\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: -2.4953222274780273\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: 3.4270095825195312\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: -0.8757376670837402\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: 9.315171241760254\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: 1.3670885562896729\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: 0.18202662467956543\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -6.815176010131836\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -4.868879318237305\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 1.8178987503051758\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 10.661011338233948\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -5.078039765357971\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 1.658935546875\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -1.1386775970458984\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -15.092260837554932\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: 14.352375268936157\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: -2.3066794872283936\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 1.9231367111206055\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: 3.7324070930480957\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: 1.0936510562896729\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 4.139242768287659\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -1.683964729309082\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -9.334314465522766\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: -0.1172637939453125\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 6.845117807388306\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -8.895094394683838\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: 7.615623474121094\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: -0.7932782173156738\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: -11.288690567016602\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: 15.569705963134766\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: -6.688950061798096\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: 0.7684969902038574\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: -5.2243077754974365\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: 3.032575845718384\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: -7.046563625335693\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: 0.8447837829589844\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 2.2527027130126953\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: 5.102156400680542\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: 7.5368732213974\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: -6.208551526069641\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -5.114578008651733\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: -0.39496660232543945\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: 7.288188934326172\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: 2.4389898777008057\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: -4.865487813949585\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 3.706362247467041\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -6.474901437759399\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: -7.412173748016357\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: 11.084328889846802\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: 0.49685239791870117\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: -4.443162679672241\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: 5.913330316543579\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: -10.287994146347046\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 9.023772478103638\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: -9.186323881149292\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: 17.168749570846558\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -5.762580633163452\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: -13.272199630737305\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: 16.26331627368927\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -8.056455254554749\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 7.467683553695679\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -17.23514676094055\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 9.23492431640625\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: -2.888786792755127\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: 9.103138446807861\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -5.918147563934326\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: -3.762035369873047\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: 5.840102434158325\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: 6.268117427825928\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: -5.953381061553955\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: -4.669266939163208\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -5.763955116271973\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: 5.941277742385864\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -2.099970579147339\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 10.254714488983154\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -7.497437000274658\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 2.0264899730682373\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -8.409236669540405\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 6.011950969696045\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: 8.401164412498474\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -1.6862696409225464\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -5.24526834487915\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: 11.652621626853943\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -6.175920367240906\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -3.309842348098755\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: -2.6555514335632324\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 4.496784210205078\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 5.21750807762146\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: -20.691704750061035\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: 16.514557600021362\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: -3.282252550125122\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -4.702163934707642\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 6.201335191726685\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: 5.798462629318237\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -16.827129125595093\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: 5.330671072006226\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: 1.676473617553711\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: 5.951550006866455\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: 8.498975038528442\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: -17.203526496887207\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 10.99523663520813\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -7.968956232070923\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: 0.3200685977935791\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -0.2573049068450928\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -2.7166366577148438\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 3.6114120483398438\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: 5.814633369445801\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: -4.386916160583496\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -3.9437055587768555\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 6.835527420043945\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: -2.3199617862701416\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: -2.5643229484558105\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: 4.979778528213501\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: -5.218801498413086\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: -1.1363375186920166\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: 12.264795303344727\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: -4.1066741943359375\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -5.800596475601196\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: -1.1159086227416992\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: 4.302077293395996\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: 4.225250482559204\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: -8.908320665359497\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: 6.689215898513794\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -6.8212127685546875\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: -1.5720856189727783\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: -3.650951385498047\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 5.66581130027771\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 1.0149669647216797\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -1.2279927730560303\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 10.032929182052612\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: 0.3382730484008789\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: -19.84944462776184\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 12.03589677810669\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 2.8943169116973877\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -9.744514226913452\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 2.696274518966675\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 2.449343204498291\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -2.4099385738372803\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 6.099860668182373\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: -1.8915677070617676\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: -5.036873817443848\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 4.1678619384765625\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: 1.8973243236541748\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -0.59043288230896\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: -0.37366509437561035\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -1.2252509593963623\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: -0.5036437511444092\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -1.2445461750030518\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 2.995699644088745\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: -2.7770400047302246\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: -2.7658164501190186\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: -2.3079991340637207\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: 4.665321111679077\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: -9.603110551834106\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: 5.692706108093262\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 11.670550107955933\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -6.807640790939331\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 5.354104042053223\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: 0.5324816703796387\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -11.563448905944824\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: 3.4628641605377197\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 7.219685316085815\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -10.774636268615723\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: 6.880743503570557\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -2.7615487575531006\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: -4.069653749465942\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -1.7719125747680664\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: 9.980809688568115\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: -0.7524895668029785\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -3.074371814727783\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: 2.739403247833252\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -2.213160991668701\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: -4.8340654373168945\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: 14.039536714553833\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: -2.591249942779541\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: -2.4970316886901855\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -2.0683181285858154\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: -2.652636766433716\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: 1.6100847721099854\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -8.125290870666504\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 4.361152648925781\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: 3.4287238121032715\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: -0.0710451602935791\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 5.946823358535767\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -11.244227886199951\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: 12.54423439502716\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 0.4239463806152344\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -6.753166317939758\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: -3.984687328338623\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: 8.157581090927124\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: -13.957263231277466\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: 19.216997623443604\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: -18.54992151260376\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 1.382601261138916\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: 7.772423028945923\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 7.163505554199219\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: -14.077516794204712\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: 6.231255531311035\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: -10.384516716003418\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: 13.822493553161621\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 0.2631378173828125\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -6.837973594665527\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -2.7793145179748535\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: 1.6749978065490723\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: 7.023677825927734\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -12.311832904815674\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 14.894171953201294\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -1.6121649742126465\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: 0.791100263595581\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: -12.430417537689209\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: 15.824138522148132\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -1.973136067390442\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: -17.134469747543335\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 4.611616134643555\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 9.053562879562378\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: -2.9723644256591797\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: 0.12279510498046875\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: -5.363703966140747\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: 7.396780252456665\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: -4.386618137359619\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: 13.73510479927063\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: -11.777373552322388\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: 1.392446756362915\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: 2.4868202209472656\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 4.94242787361145\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -6.368265151977539\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: -1.343902349472046\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -5.734810829162598\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 5.585566759109497\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: -2.9960215091705322\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -4.908556938171387\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: 9.299407005310059\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: -8.455524444580078\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: 12.978346347808838\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: -1.732630729675293\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: -9.15323257446289\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 6.7429280281066895\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: -2.2752416133880615\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: 9.588326811790466\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: -6.6320401430130005\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -9.830889701843262\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: 8.500645160675049\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: -5.655643939971924\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -2.761569023132324\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: 13.448121547698975\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: -11.034538745880127\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: 7.676471471786499\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: -27.90773034095764\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: 26.911184787750244\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: -2.4737441539764404\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 1.1395454406738281\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: -7.6472437381744385\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: 0.2630782127380371\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: -0.029578208923339844\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: -0.34874439239501953\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 14.99827265739441\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: -11.25411868095398\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: -4.896881580352783\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: 7.0798444747924805\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -0.16954541206359863\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: 1.1233997344970703\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 2.245098352432251\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 0.056557655334472656\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: 1.191622018814087\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 0.6276834011077881\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 2.731938362121582\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: -10.74038028717041\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -2.7317309379577637\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 9.828484058380127\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: -9.976375102996826\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 2.646207809448242\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: 9.646921157836914\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: -5.232275724411011\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: -0.7773613929748535\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -8.533092737197876\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: 14.53646183013916\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: -4.326003789901733\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: -4.130654335021973\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: -10.934838056564331\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 9.748859405517578\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 1.9099020957946777\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 1.0626709461212158\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -0.9303915500640869\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: 2.612447738647461\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: 0.8128213882446289\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -8.898322582244873\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: 8.673529624938965\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -0.9997749328613281\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: -9.137587547302246\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 11.37826681137085\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 5.4860663414001465\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -9.404640197753906\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 3.7860453128814697\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -7.0992958545684814\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: 0.37319421768188477\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 5.074772834777832\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: 1.5214157104492188\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -13.447942733764648\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: 11.307786703109741\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: 1.9718945026397705\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: -7.010002136230469\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 6.386328935623169\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -0.49669384956359863\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: -0.059990882873535156\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: -8.37834119796753\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: 15.745924711227417\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -3.3591806888580322\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: 2.8023725748062134\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: -13.97931158542633\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: 16.702505350112915\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: -12.073084115982056\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 6.90386176109314\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: 0.6968510150909424\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 2.5381410121917725\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -10.524381399154663\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -5.072076320648193\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 4.647109508514404\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 6.132467985153198\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -0.07459163665771484\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: -8.484963178634644\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 0.8491730690002441\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -7.201180458068848\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 7.567794322967529\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 5.8316779136657715\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -2.1163558959960938\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -3.3837175369262695\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 12.33535647392273\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -2.0797371864318848\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 2.1159428358078003\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -19.273274540901184\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 4.393143653869629\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: -6.621506214141846\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -57.50450611114502\n",
      "batch_going: 1\n",
      "change in Valid loss: -55.571255683898926\n",
      "batch_going: 2\n",
      "change in Valid loss: -51.67879104614258\n",
      "batch_going: 3\n",
      "change in Valid loss: -58.24363708496094\n",
      "batch_going: 4\n",
      "change in Valid loss: -83.91100883483887\n",
      "batch_going: 5\n",
      "change in Valid loss: -51.75454139709473\n",
      "batch_going: 6\n",
      "change in Valid loss: -43.84884834289551\n",
      "batch_going: 7\n",
      "change in Valid loss: -43.360843658447266\n",
      "batch_going: 8\n",
      "change in Valid loss: -26.855061054229736\n",
      "batch_going: 9\n",
      "change in Valid loss: -42.22247123718262\n",
      "batch_going: 10\n",
      "change in Valid loss: -36.21675968170166\n",
      "batch_going: 11\n",
      "change in Valid loss: -59.78806495666504\n",
      "batch_going: 12\n",
      "change in Valid loss: -42.53443241119385\n",
      "batch_going: 13\n",
      "change in Valid loss: -59.1747522354126\n",
      "batch_going: 14\n",
      "change in Valid loss: -45.14986515045166\n",
      "batch_going: 15\n",
      "change in Valid loss: -48.19298267364502\n",
      "batch_going: 16\n",
      "change in Valid loss: -56.97484016418457\n",
      "batch_going: 17\n",
      "change in Valid loss: -52.883338928222656\n",
      "batch_going: 18\n",
      "change in Valid loss: -73.71828556060791\n",
      "batch_going: 19\n",
      "change in Valid loss: -41.02142810821533\n",
      "batch_going: 20\n",
      "change in Valid loss: -53.683462142944336\n",
      "batch_going: 21\n",
      "change in Valid loss: -53.8065767288208\n",
      "batch_going: 22\n",
      "change in Valid loss: -57.83766269683838\n",
      "batch_going: 23\n",
      "change in Valid loss: -38.302483558654785\n",
      "batch_going: 24\n",
      "change in Valid loss: -49.86358642578125\n",
      "batch_going: 25\n",
      "change in Valid loss: -49.65327739715576\n",
      "batch_going: 26\n",
      "change in Valid loss: -52.800869941711426\n",
      "batch_going: 27\n",
      "change in Valid loss: -54.94351863861084\n",
      "batch_going: 28\n",
      "change in Valid loss: -51.94998741149902\n",
      "batch_going: 29\n",
      "change in Valid loss: -43.529672622680664\n",
      "batch_going: 30\n",
      "change in Valid loss: -46.25774383544922\n",
      "batch_going: 31\n",
      "change in Valid loss: -47.04501152038574\n",
      "batch_going: 32\n",
      "change in Valid loss: -45.99213123321533\n",
      "batch_going: 33\n",
      "change in Valid loss: -58.50734233856201\n",
      "batch_going: 34\n",
      "change in Valid loss: -41.23316287994385\n",
      "batch_going: 35\n",
      "change in Valid loss: -41.610426902770996\n",
      "batch_going: 36\n",
      "change in Valid loss: -48.36514472961426\n",
      "batch_going: 37\n",
      "change in Valid loss: -50.663604736328125\n",
      "batch_going: 38\n",
      "change in Valid loss: -52.71496772766113\n",
      "batch_going: 39\n",
      "change in Valid loss: -58.733224868774414\n",
      "batch_going: 40\n",
      "change in Valid loss: -47.710914611816406\n",
      "batch_going: 41\n",
      "change in Valid loss: -50.86629390716553\n",
      "batch_going: 42\n",
      "change in Valid loss: -58.84805202484131\n",
      "batch_going: 43\n",
      "change in Valid loss: -46.76806449890137\n",
      "batch_going: 44\n",
      "change in Valid loss: -37.23053455352783\n",
      "batch_going: 45\n",
      "change in Valid loss: -33.938705921173096\n",
      "batch_going: 46\n",
      "change in Valid loss: -49.31826114654541\n",
      "batch_going: 47\n",
      "change in Valid loss: -65.06654262542725\n",
      "batch_going: 48\n",
      "change in Valid loss: -33.07018280029297\n",
      "batch_going: 49\n",
      "change in Valid loss: -37.00265169143677\n",
      "batch_going: 50\n",
      "change in Valid loss: -55.74549674987793\n",
      "batch_going: 51\n",
      "change in Valid loss: -42.166171073913574\n",
      "batch_going: 52\n",
      "change in Valid loss: -42.682437896728516\n",
      "batch_going: 53\n",
      "change in Valid loss: -59.91156578063965\n",
      "batch_going: 54\n",
      "change in Valid loss: -47.37625598907471\n",
      "batch_going: 55\n",
      "change in Valid loss: -53.669843673706055\n",
      "batch_going: 56\n",
      "change in Valid loss: -31.5910005569458\n",
      "batch_going: 57\n",
      "change in Valid loss: -52.55026817321777\n",
      "batch_going: 58\n",
      "change in Valid loss: -50.53277015686035\n",
      "batch_going: 59\n",
      "change in Valid loss: -39.32882308959961\n",
      "batch_going: 60\n",
      "change in Valid loss: -40.15080451965332\n",
      "batch_going: 61\n",
      "change in Valid loss: -68.97778511047363\n",
      "batch_going: 62\n",
      "change in Valid loss: -43.5530948638916\n",
      "batch_going: 63\n",
      "change in Valid loss: -64.16234016418457\n",
      "batch_going: 64\n",
      "change in Valid loss: -37.66277313232422\n",
      "batch_going: 65\n",
      "change in Valid loss: -56.41838073730469\n",
      "batch_going: 66\n",
      "change in Valid loss: -42.88163185119629\n",
      "batch_going: 67\n",
      "change in Valid loss: -72.01685905456543\n",
      "batch_going: 68\n",
      "change in Valid loss: -43.16448211669922\n",
      "batch_going: 69\n",
      "change in Valid loss: -33.15244197845459\n",
      "batch_going: 70\n",
      "change in Valid loss: -41.37593746185303\n",
      "batch_going: 71\n",
      "change in Valid loss: -57.05411911010742\n",
      "batch_going: 72\n",
      "change in Valid loss: -43.44198226928711\n",
      "batch_going: 73\n",
      "change in Valid loss: -38.4098744392395\n",
      "batch_going: 74\n",
      "change in Valid loss: -44.0583610534668\n",
      "batch_going: 75\n",
      "change in Valid loss: -41.04692459106445\n",
      "batch_going: 76\n",
      "change in Valid loss: -52.49575138092041\n",
      "batch_going: 77\n",
      "change in Valid loss: -54.720234870910645\n",
      "batch_going: 78\n",
      "change in Valid loss: -61.66842460632324\n",
      "batch_going: 79\n",
      "change in Valid loss: -59.9576473236084\n",
      "batch_going: 80\n",
      "change in Valid loss: -44.73586082458496\n",
      "batch_going: 81\n",
      "change in Valid loss: -63.966965675354004\n",
      "batch_going: 82\n",
      "change in Valid loss: -48.067007064819336\n",
      "batch_going: 83\n",
      "change in Valid loss: -29.37220573425293\n",
      "Epoch: 10 \tTraining Loss: 15.758073 \tValidation Loss: 49.356980\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -18.677908182144165\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 9.156293869018555\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 0.8857488632202148\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -4.128305912017822\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: 2.518324851989746\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: -3.153480291366577\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: 5.681228041648865\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -4.110153317451477\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: -0.27784228324890137\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: -0.8331692218780518\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: 0.13483881950378418\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 3.551734685897827\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: -0.6301051378250122\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: -1.821642518043518\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 6.700332164764404\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -16.961734294891357\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 8.938239812850952\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 3.6589837074279785\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: 1.5967941284179688\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -5.077863931655884\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 1.7733573913574219\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -0.26401281356811523\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: -1.2984085083007812\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: 3.7274056673049927\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -2.851833701133728\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: -8.266736268997192\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: -4.946544170379639\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 20.255043506622314\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: -5.03010630607605\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -5.552853345870972\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 8.690770268440247\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 0.8829289674758911\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: -9.113878011703491\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 7.145628333091736\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -1.765543818473816\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 7.227971106767654\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: -6.318622380495071\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: -5.784019231796265\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: -0.7447719573974609\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: -0.5389440059661865\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: 2.2989988327026367\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -7.414120435714722\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 10.17573356628418\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: 1.113656759262085\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -6.8498194217681885\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: 0.6467103958129883\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 8.366692066192627\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: -0.0806272029876709\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -4.19791579246521\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -0.7746601104736328\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: 0.5739009380340576\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: -9.422980546951294\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 12.631982564926147\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -3.62174391746521\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -9.058423042297363\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 3.5118460655212402\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: 1.6812396049499512\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: 3.820139169692993\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -2.4856650829315186\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: 11.134393215179443\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: -4.90764319896698\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: -12.971745133399963\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: 8.581291437149048\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -1.0318410396575928\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: -2.2711217403411865\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 4.03748631477356\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 2.20159113407135\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: 6.391114592552185\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: -5.810003876686096\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -3.369387984275818\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 6.374457478523254\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -6.932246088981628\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 2.564268112182617\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 2.417088747024536\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -5.164697170257568\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: 7.92103111743927\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: -8.326559662818909\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: 1.6020452976226807\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 2.0828092098236084\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: 0.2179276943206787\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 3.2393479347229004\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: -1.3038456439971924\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -0.4749929904937744\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: 0.28808414936065674\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: -4.758687615394592\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -0.9500265121459961\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: 6.593043804168701\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -8.819763660430908\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: 9.247465133666992\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: -6.1035895347595215\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 3.290061354637146\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: 0.5524259805679321\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: 0.8515387773513794\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -1.0217320919036865\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: -2.95246422290802\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -2.2544920444488525\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 7.4421751499176025\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -0.5423617362976074\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -10.827779769897461\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 0.14085650444030762\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 0.8708775043487549\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 10.256770849227905\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -11.425251960754395\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: 12.359864115715027\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: -6.951591372489929\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -0.2862071990966797\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 1.6014456748962402\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 1.75490140914917\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -13.848973512649536\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: 8.081827163696289\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: -5.853433609008789\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: 12.201535105705261\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: -0.768246054649353\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -3.0745530128479004\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: 2.8144800662994385\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: -6.672698259353638\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 10.857113599777222\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: -7.357660531997681\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -6.36782169342041\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: 6.49968147277832\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 7.163679599761963\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: -12.297115325927734\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 15.867888331413269\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -7.744058966636658\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 1.6400504112243652\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: 1.037924885749817\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 0.4310351610183716\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 0.9193295240402222\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -10.679091811180115\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -6.2684547901153564\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 3.85500431060791\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: 9.519554376602173\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: 4.297149181365967\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -13.760303258895874\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 1.4957618713378906\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: 6.450238227844238\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -5.425777435302734\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 8.820302486419678\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: -7.150689363479614\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: 7.175821661949158\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: -12.313516736030579\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 6.867166757583618\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 2.6549124717712402\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 2.52979576587677\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -9.027231335639954\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 7.739356160163879\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -16.102184653282166\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 17.187432050704956\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -6.330926418304443\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 8.94956111907959\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: -0.11173129081726074\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -2.1649587154388428\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 1.8089359998703003\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -5.575537085533142\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: 1.4011609554290771\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: 6.004398763179779\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -3.7553271651268005\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 2.4190926551818848\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: -17.996132373809814\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: 17.273162603378296\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: -16.076749563217163\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: 8.967432975769043\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: 0.3146803379058838\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 9.333356618881226\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -6.261698007583618\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: -9.884055852890015\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: 2.576310634613037\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: -3.05483341217041\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: 15.575002431869507\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: -5.456918478012085\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -5.275951623916626\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: -5.22217869758606\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: 2.4886155128479004\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -1.7605853080749512\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 7.146601676940918\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 5.549720525741577\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: 1.0770750045776367\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 0.1826953887939453\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -11.964454650878906\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: 11.334368586540222\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: -13.894506096839905\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -0.4410362243652344\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: -3.323698043823242\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 18.508607149124146\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: -8.289182186126709\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: -0.7602667808532715\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: 6.922598481178284\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -6.54863178730011\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 2.004631757736206\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -5.6558215618133545\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -2.4539268016815186\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 9.103481769561768\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 3.46125066280365\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: -2.5119954347610474\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -6.57960057258606\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: 9.247549772262573\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -0.6119608879089355\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 4.651001691818237\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: -5.5091482400894165\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: -5.086836218833923\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -0.0419926643371582\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: 10.358054041862488\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -4.401388764381409\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -2.5438284873962402\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: -2.937943935394287\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -8.299354314804077\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 7.344321012496948\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -4.162890911102295\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 10.723296403884888\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 1.6115891933441162\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: -10.99372148513794\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: 1.811981201171875\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: 6.344786882400513\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 0.6899648904800415\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -0.2549201250076294\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: -4.491438865661621\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 8.539763689041138\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -1.2057149410247803\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -4.5285868644714355\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: -10.738377571105957\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 7.842750549316406\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: 1.7244958877563477\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -15.18751859664917\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 12.128963470458984\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: 0.29418110847473145\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: 2.343968152999878\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -2.383432388305664\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: 6.218777298927307\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -5.529041886329651\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 3.5934972763061523\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -12.029953002929688\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: 7.606351375579834\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: 0.3581070899963379\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: 0.5706250667572021\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 6.8078696727752686\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -7.244024276733398\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -12.928802967071533\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: 7.781424522399902\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: 16.77227407693863\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: -16.44727736711502\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 7.0612633228302\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: -7.72996187210083\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: 12.436424493789673\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -4.485139846801758\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -14.303170442581177\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 8.62173080444336\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 8.619197010993958\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: -7.537446618080139\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 8.200174570083618\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -6.840951442718506\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -0.7391548156738281\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: -2.602217197418213\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: 4.591729640960693\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -11.645056009292603\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 13.612207174301147\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -1.8397259712219238\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: -9.143747091293335\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 4.21018123626709\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 8.150144815444946\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -8.846920728683472\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 11.625168919563293\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: 2.1562230587005615\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -2.418079376220703\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: -13.931769728660583\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: 1.3054871559143066\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -3.3635735511779785\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 13.105919361114502\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: -7.8094565868377686\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: 6.967340707778931\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 3.6900436878204346\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: 2.6030993461608887\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: -4.772891998291016\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: -7.863179445266724\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: 6.165323257446289\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -5.797008275985718\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 8.399156332015991\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 1.602441668510437\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: -1.6572719812393188\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -5.8565568923950195\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: 6.826612949371338\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -5.897163152694702\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: -0.4183495044708252\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: -6.994608640670776\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: 3.5432028770446777\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: 3.4805679321289062\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -9.303786754608154\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: 8.854824304580688\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -1.0587728023529053\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: 1.0115671157836914\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 3.9142704010009766\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -5.0230443477630615\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: 6.799211502075195\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: -6.276639699935913\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 7.0916712284088135\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: -1.9143998622894287\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: -3.586432933807373\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -11.364364624023438\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: 15.379713773727417\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -2.4574005603790283\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 2.6488077640533447\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: 2.542816400527954\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -10.478142499923706\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 1.7040646076202393\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: -1.2313568592071533\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: -5.346003770828247\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: 11.257951259613037\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -7.5082457065582275\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: 1.2468910217285156\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 5.759484767913818\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: 5.490632057189941\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: -11.34144902229309\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 5.805951356887817\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 3.5956186056137085\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: -3.2094866037368774\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 2.903847098350525\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 1.2173283100128174\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -5.692492127418518\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: 7.089537978172302\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: -5.5541616678237915\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: -3.597273826599121\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 11.49994432926178\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -0.023867487907409668\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: -0.4174193739891052\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: -9.317566454410553\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: -5.1551103591918945\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 9.641914963722229\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: 2.468082308769226\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: -8.02437424659729\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -1.6425681114196777\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 6.113767623901367\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: 0.8692562580108643\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 0.4020059108734131\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: -5.056867599487305\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 9.466501474380493\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: -7.442255020141602\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: -1.950899362564087\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: 7.109934091567993\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: 1.8388676643371582\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -13.677101135253906\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: 18.55518877506256\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: -13.635422587394714\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: 1.9276106357574463\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 4.801318645477295\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 2.8189539909362793\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -9.080302715301514\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 3.4850072860717773\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: 0.8561134338378906\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -8.140144348144531\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 15.764223337173462\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -6.060274839401245\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: 1.6608428955078125\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -7.205559015274048\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -4.186993837356567\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 4.117692708969116\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 3.628944158554077\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -0.5231642723083496\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: 1.1403250694274902\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: -2.875993251800537\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -1.7302751541137695\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -4.449310302734375\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: 0.8787035942077637\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 6.432051658630371\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: 1.5320658683776855\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: -15.072040557861328\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 19.08755898475647\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -1.344316005706787\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: -2.589792013168335\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: 5.4006427526474\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: -5.970446467399597\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: -1.76255464553833\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: 5.954304933547974\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -7.169632911682129\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 4.959925413131714\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: -4.913303852081299\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -0.319446325302124\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 3.1510603427886963\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: -3.694511651992798\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: 1.2924611568450928\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -2.194654941558838\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 3.6129379272460938\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: 4.654144048690796\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: -8.626567125320435\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -0.6875014305114746\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: -4.303557872772217\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 4.014835357666016\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -51.95664405822754\n",
      "batch_going: 1\n",
      "change in Valid loss: -47.240586280822754\n",
      "batch_going: 2\n",
      "change in Valid loss: -52.3287296295166\n",
      "batch_going: 3\n",
      "change in Valid loss: -63.61119270324707\n",
      "batch_going: 4\n",
      "change in Valid loss: -42.10438251495361\n",
      "batch_going: 5\n",
      "change in Valid loss: -40.42478084564209\n",
      "batch_going: 6\n",
      "change in Valid loss: -63.820013999938965\n",
      "batch_going: 7\n",
      "change in Valid loss: -40.36471366882324\n",
      "batch_going: 8\n",
      "change in Valid loss: -44.21316623687744\n",
      "batch_going: 9\n",
      "change in Valid loss: -56.6795539855957\n",
      "batch_going: 10\n",
      "change in Valid loss: -63.13326835632324\n",
      "batch_going: 11\n",
      "change in Valid loss: -35.710930824279785\n",
      "batch_going: 12\n",
      "change in Valid loss: -62.41865634918213\n",
      "batch_going: 13\n",
      "change in Valid loss: -62.371015548706055\n",
      "batch_going: 14\n",
      "change in Valid loss: -39.890685081481934\n",
      "batch_going: 15\n",
      "change in Valid loss: -52.371511459350586\n",
      "batch_going: 16\n",
      "change in Valid loss: -69.17929649353027\n",
      "batch_going: 17\n",
      "change in Valid loss: -40.71667194366455\n",
      "batch_going: 18\n",
      "change in Valid loss: -51.681365966796875\n",
      "batch_going: 19\n",
      "change in Valid loss: -62.89060115814209\n",
      "batch_going: 20\n",
      "change in Valid loss: -36.83741807937622\n",
      "batch_going: 21\n",
      "change in Valid loss: -47.01565742492676\n",
      "batch_going: 22\n",
      "change in Valid loss: -40.85162162780762\n",
      "batch_going: 23\n",
      "change in Valid loss: -42.10787773132324\n",
      "batch_going: 24\n",
      "change in Valid loss: -40.856361389160156\n",
      "batch_going: 25\n",
      "change in Valid loss: -43.720030784606934\n",
      "batch_going: 26\n",
      "change in Valid loss: -53.01799297332764\n",
      "batch_going: 27\n",
      "change in Valid loss: -60.934014320373535\n",
      "batch_going: 28\n",
      "change in Valid loss: -39.91528272628784\n",
      "batch_going: 29\n",
      "change in Valid loss: -39.662697315216064\n",
      "batch_going: 30\n",
      "change in Valid loss: -30.156922340393066\n",
      "batch_going: 31\n",
      "change in Valid loss: -46.33737564086914\n",
      "batch_going: 32\n",
      "change in Valid loss: -61.30841255187988\n",
      "batch_going: 33\n",
      "change in Valid loss: -67.17791080474854\n",
      "batch_going: 34\n",
      "change in Valid loss: -40.81068992614746\n",
      "batch_going: 35\n",
      "change in Valid loss: -50.66826820373535\n",
      "batch_going: 36\n",
      "change in Valid loss: -53.865675926208496\n",
      "batch_going: 37\n",
      "change in Valid loss: -61.24141216278076\n",
      "batch_going: 38\n",
      "change in Valid loss: -43.51710319519043\n",
      "batch_going: 39\n",
      "change in Valid loss: -47.0073938369751\n",
      "batch_going: 40\n",
      "change in Valid loss: -31.651794910430908\n",
      "batch_going: 41\n",
      "change in Valid loss: -42.8313684463501\n",
      "batch_going: 42\n",
      "change in Valid loss: -40.085625648498535\n",
      "batch_going: 43\n",
      "change in Valid loss: -61.78756237030029\n",
      "batch_going: 44\n",
      "change in Valid loss: -49.144577980041504\n",
      "batch_going: 45\n",
      "change in Valid loss: -42.699527740478516\n",
      "batch_going: 46\n",
      "change in Valid loss: -49.508299827575684\n",
      "batch_going: 47\n",
      "change in Valid loss: -40.47055244445801\n",
      "batch_going: 48\n",
      "change in Valid loss: -68.84886264801025\n",
      "batch_going: 49\n",
      "change in Valid loss: -52.69702911376953\n",
      "batch_going: 50\n",
      "change in Valid loss: -48.27622890472412\n",
      "batch_going: 51\n",
      "change in Valid loss: -51.135149002075195\n",
      "batch_going: 52\n",
      "change in Valid loss: -66.00710868835449\n",
      "batch_going: 53\n",
      "change in Valid loss: -45.50349235534668\n",
      "batch_going: 54\n",
      "change in Valid loss: -73.09910774230957\n",
      "batch_going: 55\n",
      "change in Valid loss: -56.395206451416016\n",
      "batch_going: 56\n",
      "change in Valid loss: -49.57524299621582\n",
      "batch_going: 57\n",
      "change in Valid loss: -56.410675048828125\n",
      "batch_going: 58\n",
      "change in Valid loss: -49.599595069885254\n",
      "batch_going: 59\n",
      "change in Valid loss: -43.98871421813965\n",
      "batch_going: 60\n",
      "change in Valid loss: -52.06296443939209\n",
      "batch_going: 61\n",
      "change in Valid loss: -65.33318996429443\n",
      "batch_going: 62\n",
      "change in Valid loss: -54.66815948486328\n",
      "batch_going: 63\n",
      "change in Valid loss: -54.04952526092529\n",
      "batch_going: 64\n",
      "change in Valid loss: -38.29305648803711\n",
      "batch_going: 65\n",
      "change in Valid loss: -35.65365552902222\n",
      "batch_going: 66\n",
      "change in Valid loss: -52.77534484863281\n",
      "batch_going: 67\n",
      "change in Valid loss: -46.50729179382324\n",
      "batch_going: 68\n",
      "change in Valid loss: -63.94550323486328\n",
      "batch_going: 69\n",
      "change in Valid loss: -45.57019233703613\n",
      "batch_going: 70\n",
      "change in Valid loss: -68.6850118637085\n",
      "batch_going: 71\n",
      "change in Valid loss: -36.913790702819824\n",
      "batch_going: 72\n",
      "change in Valid loss: -38.100666999816895\n",
      "batch_going: 73\n",
      "change in Valid loss: -59.70418930053711\n",
      "batch_going: 74\n",
      "change in Valid loss: -45.97482681274414\n",
      "batch_going: 75\n",
      "change in Valid loss: -60.728583335876465\n",
      "batch_going: 76\n",
      "change in Valid loss: -58.94078731536865\n",
      "batch_going: 77\n",
      "change in Valid loss: -37.0063853263855\n",
      "batch_going: 78\n",
      "change in Valid loss: -57.98684120178223\n",
      "batch_going: 79\n",
      "change in Valid loss: -39.1456937789917\n",
      "batch_going: 80\n",
      "change in Valid loss: -57.710089683532715\n",
      "batch_going: 81\n",
      "change in Valid loss: -41.71903133392334\n",
      "batch_going: 82\n",
      "change in Valid loss: -51.45325183868408\n",
      "batch_going: 83\n",
      "change in Valid loss: -30.720295906066895\n",
      "Epoch: 11 \tTraining Loss: 14.645258 \tValidation Loss: 50.041452\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -17.964465618133545\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: 2.9942774772644043\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 2.942243814468384\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: 0.038138628005981445\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -9.169771671295166\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: 10.714099407196045\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: -2.3637187480926514\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: 1.098036766052246\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: -5.443388223648071\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: 10.101905465126038\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -8.61909806728363\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: 9.218650460243225\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: -15.511662364006042\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 8.727792501449585\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: 6.675209999084473\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: -3.8158786296844482\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: 7.5382304191589355\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: -1.9707956910133362\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -2.3802265524864197\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: -4.382944107055664\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 3.141162395477295\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -5.709042549133301\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: -0.07694602012634277\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: -1.8090152740478516\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: 3.21449875831604\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: 3.6061489582061768\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: -4.42202091217041\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 4.22247052192688\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: 2.3222434520721436\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: 0.6225699186325073\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: -12.965167164802551\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: 11.187008619308472\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 1.8404626846313477\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: -5.22060751914978\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: 1.9432425498962402\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 4.902811050415039\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: -13.503657579421997\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 10.782751441001892\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 0.25828540325164795\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: -0.5626523494720459\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -3.0594348907470703\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: -7.3567187786102295\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 11.205471754074097\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -3.4641671180725098\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: 6.322957277297974\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -11.478558778762817\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 3.3674561977386475\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: 7.127781510353088\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: -0.8768606185913086\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -1.327788233757019\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -5.078290700912476\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 8.119385242462158\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 1.9193807244300842\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -4.3431356549263\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -8.371859788894653\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 8.748179078102112\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -12.5170236825943\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: 6.836674213409424\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: 7.212449908256531\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: -13.835157752037048\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: 3.970811367034912\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: 8.368849754333496\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: -6.355717182159424\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: 1.2833881378173828\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 2.618470788002014\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 0.41601359844207764\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 5.7004135847091675\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -7.756417393684387\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: 5.726763904094696\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -2.9588904976844788\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: -5.94901978969574\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -0.3500485420227051\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: 8.685517311096191\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: -3.8794541358947754\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: 6.4044299721717834\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -15.382726490497589\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 4.266694784164429\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -0.9940028190612793\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 0.3621208667755127\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -11.478163003921509\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: 9.91941213607788\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: 6.225650310516357\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -1.9646143913269043\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: 0.7858633995056152\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: 2.6782357692718506\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -3.5590970516204834\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: -2.9864442348480225\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: -0.6095564365386963\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -12.157902717590332\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: 13.242483139038086\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 8.480085134506226\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: -4.054566025733948\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: -6.737199425697327\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: 3.057835102081299\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 5.206000208854675\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: 2.341218590736389\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: -2.8504425287246704\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -4.263905882835388\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: -2.6107442378997803\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: -9.000357389450073\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 16.95065438747406\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: 2.6892369985580444\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: -7.148237228393555\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: 4.202750325202942\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 0.8704942464828491\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -10.240790843963623\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 2.6284539699554443\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: 2.0366525650024414\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: -2.412395477294922\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: -0.42317628860473633\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: 2.5079798698425293\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -7.684881687164307\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 14.148610830307007\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -7.809785604476929\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: -3.170454502105713\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: 11.273602843284607\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: 0.010070204734802246\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: -1.7521393299102783\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -8.447799682617188\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -0.37760019302368164\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: 3.3513236045837402\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 3.7389928102493286\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: -5.221888422966003\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: 8.142427206039429\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: -11.067031621932983\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: 9.06028926372528\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: -16.667264103889465\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 14.704123735427856\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -5.580211877822876\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: 6.337853670120239\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: 4.039763808250427\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: -5.210264325141907\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: -0.7077121734619141\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: 0.16929268836975098\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: -2.4513161182403564\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -2.638239860534668\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: -0.35237789154052734\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: 6.063966751098633\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 2.309807538986206\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: -0.7191300392150879\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: 0.35520315170288086\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 0.1300358772277832\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: -12.165392637252808\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: 5.715278387069702\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: 4.4668614864349365\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: -8.68821382522583\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: 6.3288116455078125\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: -4.26404595375061\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: -2.2196578979492188\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: 10.465505719184875\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: 1.4393675327301025\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -2.928929924964905\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: 2.759069800376892\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: -2.874259352684021\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: -9.635732173919678\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: 10.777042508125305\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: -1.9904130697250366\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: 6.240376830101013\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: -2.252568006515503\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -0.8641111850738525\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 4.020790457725525\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -10.092277526855469\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: 10.738796591758728\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: -7.115129828453064\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -3.137497901916504\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 8.418639898300171\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: -3.818535804748535\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: -6.552176475524902\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: -4.227813482284546\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: 6.802346706390381\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -6.3501715660095215\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 14.052096009254456\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -8.615995049476624\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -4.642957448959351\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 6.090492010116577\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: 1.808030605316162\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: 3.4637516736984253\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: -4.565581679344177\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: 6.800239682197571\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -12.42737591266632\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 4.045383930206299\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: -2.7243053913116455\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: 1.7562663555145264\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: -1.5711009502410889\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: 1.6486132144927979\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: -1.0155236721038818\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: -0.11587977409362793\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -1.3345050811767578\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 8.170780539512634\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -0.6309211254119873\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: -9.715617299079895\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 15.077715516090393\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 1.9845318794250488\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: -8.585166335105896\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: 0.47332167625427246\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: -3.2590389251708984\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -2.962193489074707\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 6.452444791793823\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: -10.401731729507446\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: 15.57413637638092\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: -0.5438441038131714\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: -3.8367795944213867\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: -1.1844611167907715\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: 4.358623027801514\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: -14.446004629135132\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: 8.388352394104004\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 0.553973913192749\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -4.5449793338775635\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: 1.7182505130767822\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 5.09981632232666\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: 2.7596592903137207\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -6.095317602157593\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: -3.6512362957000732\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: -2.2707557678222656\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: -1.4304578304290771\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: 8.028228282928467\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: 0.6967759132385254\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: -11.478254795074463\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: 8.021111488342285\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 2.771449089050293\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 0.998297929763794\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -2.1742045879364014\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: -4.865226745605469\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: 13.36917757987976\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: -8.065896034240723\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: 7.243962287902832\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: -13.757681846618652\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: 15.977686047554016\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: -14.106727242469788\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: -3.55754017829895\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: 12.164117097854614\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: -6.10482931137085\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: -1.6723215579986572\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: 6.630069017410278\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: 0.78357994556427\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: -2.1284860372543335\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -7.829558849334717\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: 5.832850933074951\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: -1.4632236957550049\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: 2.3643040657043457\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: -3.290534019470215\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 6.8629056215286255\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -2.7952557802200317\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: -0.9993374347686768\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: -1.1133050918579102\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: 2.4073708057403564\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: -11.449483633041382\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: 11.27840280532837\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 3.0121368169784546\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -0.8974933624267578\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: -8.519695401191711\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 4.638335704803467\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: 2.949131727218628\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -6.136424541473389\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 11.855376660823822\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -4.2758747935295105\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: -12.533704042434692\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 11.083632707595825\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 4.67378556728363\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -8.495457768440247\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: 6.044922471046448\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: -3.662460446357727\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: -2.9615938663482666\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 6.520361304283142\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -12.476149201393127\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: 9.867856502532959\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: -1.7370986938476562\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 3.0400103330612183\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: -6.587195992469788\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 1.5183043479919434\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -3.5421884059906006\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 0.886085033416748\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 14.145683348178864\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -4.495337903499603\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: -22.174530625343323\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: 13.061245679855347\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 1.6862499713897705\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: -5.874497890472412\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: 7.541134357452393\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: -0.2278280258178711\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: -1.2038087844848633\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: 0.7255196571350098\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: 9.1020667552948\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -8.28187346458435\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -0.5814778804779053\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: 10.387687385082245\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -1.6500946879386902\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: -17.146233320236206\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: 12.362284660339355\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: -4.097089767456055\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -5.756981372833252\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: 13.640393018722534\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: -11.151916980743408\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 7.381088733673096\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: -0.8152496814727783\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: -6.104211807250977\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: 1.4678847789764404\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: -6.405564546585083\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: 14.675194025039673\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: -4.662028551101685\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -4.877946376800537\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: 9.00012493133545\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: -5.585819482803345\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: -12.952123880386353\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: 9.923828840255737\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -4.068812131881714\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: 9.05897855758667\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: -4.166169166564941\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 3.082735538482666\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -2.2008919715881348\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: 5.56607186794281\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: -8.669571280479431\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 13.246072232723236\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: -12.576669156551361\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: 11.479871273040771\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: -9.994184970855713\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: 6.407550573348999\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -22.57576584815979\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 14.038313627243042\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 3.7291061878204346\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: 2.481687068939209\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: -9.239234924316406\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: 6.371419429779053\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: 1.254279613494873\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: 1.6497349739074707\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: -8.379924297332764\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: 6.381182670593262\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 8.380699753761292\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: -7.148929238319397\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: 1.2867462635040283\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: -6.1317455768585205\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 3.2829928398132324\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: 4.55366313457489\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -2.0527929067611694\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: -8.347229957580566\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: 1.8381690979003906\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 2.2196662425994873\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: 5.154486894607544\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: 1.203019618988037\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: 2.7891379594802856\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: -3.6728960275650024\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: -6.4123475551605225\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: -4.853407144546509\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -2.234680652618408\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: -6.046848297119141\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: 10.067740678787231\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 4.219337701797485\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -4.696762561798096\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 13.740941286087036\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: -6.844418048858643\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -5.667287111282349\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: 12.052149176597595\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: -27.919766306877136\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: 12.941064834594727\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: 11.942508220672607\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: 4.852160215377808\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: -13.614048957824707\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: 6.381202936172485\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: -6.92625880241394\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: 9.04753565788269\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: 9.51007030904293\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: -11.093865856528282\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: 4.156264066696167\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 0.3765571117401123\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: -2.8351378440856934\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: -5.553779602050781\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: 10.155157446861267\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: -2.9321086406707764\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: -2.151198983192444\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: -8.655102252960205\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: 6.294882297515869\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -0.5412840843200684\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 8.97986888885498\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -9.018126726150513\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: -5.758043527603149\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: 8.963894844055176\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -7.2611236572265625\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 11.260874271392822\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: -13.04552674293518\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: -8.447867631912231\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: 12.070462703704834\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: 2.936532497406006\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -5.168759822845459\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 9.848482012748718\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -0.4382133483886719\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: -10.611490607261658\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 7.740874290466309\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: 1.0182428359985352\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: -4.727610349655151\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 6.971621513366699\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: 3.3598846197128296\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: -2.441641688346863\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -0.6903374195098877\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 1.3570153713226318\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: -5.754117965698242\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -5.720968246459961\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 11.239904761314392\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -4.162116646766663\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 5.766855478286743\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: -6.552773714065552\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: -0.6547880172729492\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: -1.8474674224853516\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 2.4501609802246094\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -9.083831310272217\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: -1.684114933013916\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: 1.507887840270996\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: 12.20460295677185\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: -3.8397014141082764\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: -0.336153507232666\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: -14.796605110168457\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: 11.111376285552979\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: -2.670339345932007\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: 3.0034732818603516\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: -1.0491657257080078\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 4.684504270553589\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: 6.276534795761108\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -8.37478518486023\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: 9.495171904563904\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: -12.593876719474792\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: -0.10938405990600586\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -2.074763774871826\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: 0.6715536117553711\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 3.941032886505127\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: 3.644498586654663\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 0.36383509635925293\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: 0.14499306678771973\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 5.770213603973389\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -10.22326111793518\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 6.508805751800537\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: -0.7359862327575684\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -8.344566822052002\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: 5.681359767913818\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: -6.814718246459961\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: 0.9037041664123535\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: -4.893636703491211\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: 12.971699237823486\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: -4.634215831756592\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: -0.5862975120544434\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: 3.86094331741333\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -0.11972188949584961\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -7.5286030769348145\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 1.1339318752288818\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: -2.2787463665008545\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: 4.012465476989746\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -0.6179714202880859\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: 2.548644542694092\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: 1.5764415264129639\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 5.610010027885437\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -8.786044716835022\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: 2.7350568771362305\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 4.8103296756744385\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: -16.612354516983032\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: 18.8202166557312\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -10.648369789123535\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 3.354339599609375\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: -3.6669564247131348\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: 11.002870798110962\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: -10.309549570083618\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: 1.890273094177246\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: -0.21645188331604004\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: 2.0449328422546387\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: -1.491481065750122\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: -4.532679319381714\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 11.26177430152893\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: 0.022633075714111328\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: -1.1769282817840576\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: -7.664213180541992\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: 6.08545184135437\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: 3.3869969844818115\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: -16.727536916732788\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: 13.73486876487732\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 1.773974895477295\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 1.0112053155899048\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -9.280661940574646\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 2.8197169303894043\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: 2.458089590072632\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: 3.7395167350769043\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 1.225728988647461\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: -4.452892541885376\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -6.580088138580322\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: 8.067854046821594\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -0.32269179821014404\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: -0.32042860984802246\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: -1.2279081344604492\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: -11.285426616668701\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: 0.1242685317993164\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: 5.76835036277771\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 3.9101052284240723\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -3.879925012588501\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 5.310337543487549\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: 0.7173788547515869\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: -6.98131799697876\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: -3.37255597114563\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: 3.577059507369995\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: 5.142307281494141\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -0.8491325378417969\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: -4.142799377441406\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: -2.9510486125946045\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -0.6458687782287598\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: -0.9865164756774902\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: 9.93759036064148\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 2.6369011402130127\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -7.181394100189209\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: -4.747400283813477\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 12.435290813446045\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -9.898724555969238\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: 4.392528533935547\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: 4.1429829597473145\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: -8.340669870376587\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: -0.9858226776123047\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: 10.219793915748596\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: -2.0124465227127075\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -0.7720780372619629\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: -0.6894028186798096\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: -2.1985244750976562\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: -1.72410249710083\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: 10.329079031944275\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: -16.73949658870697\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: 7.650018930435181\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: 8.532460927963257\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: -9.476184844970703\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -0.7801544666290283\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: -2.6023828983306885\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -7.998969554901123\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 21.031936407089233\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: 0.01130521297454834\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: 2.4495452642440796\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -5.833425521850586\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: -1.366649866104126\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 0.619429349899292\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -9.117238521575928\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 15.077006816864014\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: -5.152466297149658\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: -12.435705661773682\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 10.41393756866455\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: 0.7375693321228027\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: 6.678346693515778\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -11.131412088871002\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -0.720822811126709\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: -6.770005226135254\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: 13.1857168674469\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -5.762896537780762\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: -2.1781373023986816\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -2.817162275314331\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: -0.6259799003601074\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: 14.01311993598938\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: -9.744369983673096\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -0.6128942966461182\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: -1.6069531440734863\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: -12.29970932006836\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 15.490492582321167\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: -3.2040560245513916\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: 0.4728662967681885\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 5.4228127002716064\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: 1.724715232849121\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: -0.6018149852752686\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -6.232248544692993\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: 5.406885147094727\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -2.578110694885254\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: -0.015367269515991211\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 3.5205817222595215\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: 2.9467129707336426\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: -2.2666680812835693\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -2.478686571121216\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 2.364856004714966\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: -0.7868599891662598\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -1.9605910778045654\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: -7.163635492324829\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: 12.093337774276733\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: -9.874793291091919\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: 11.409221887588501\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: -3.7045228481292725\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 1.6754722595214844\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: 1.7956197261810303\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -12.812052965164185\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 10.833346843719482\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -5.96867561340332\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: -1.1117351055145264\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: 10.455588102340698\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -3.692789077758789\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: -7.241960763931274\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 8.275086283683777\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: -2.31406033039093\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: -8.852472305297852\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -0.4495120048522949\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: 5.284454822540283\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 2.238590717315674\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 3.8937366008758545\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: -14.699212312698364\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 14.385415315628052\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: 2.5211262702941895\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: -5.180884599685669\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: 3.388383388519287\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: -3.0033230781555176\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: -1.860424280166626\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -0.46563029289245605\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: 4.223462343215942\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 2.208588719367981\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: -14.62042510509491\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: 7.9930174350738525\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 5.796629786491394\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: -24.51184570789337\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: 19.353885650634766\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -11.741633415222168\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 9.711012840270996\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: -6.087887287139893\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 1.0060691833496094\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: 1.2684416770935059\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: 5.027437210083008\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: 4.397037029266357\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: 3.879903554916382\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: -6.806323528289795\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 8.088445663452148\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: -11.374560594558716\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: 3.674776554107666\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 4.636720418930054\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: -8.847748041152954\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: 8.271715641021729\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: 0.4680746793746948\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -12.636544108390808\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: 9.932020902633667\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: -2.9673290252685547\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -4.704614877700806\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: 10.895265340805054\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: -5.47237753868103\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: -1.019594669342041\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: -4.270650148391724\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: 4.114822149276733\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: 5.444144010543823\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: -11.615363359451294\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: 12.89940059185028\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: -4.474723935127258\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: -8.85553240776062\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: 14.130650758743286\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: -9.722857475280762\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -1.886885166168213\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 7.664384841918945\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: 7.895086109638214\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: -24.659246504306793\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: 12.156882286071777\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 10.519241094589233\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -3.6751842498779297\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: -1.643584966659546\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -10.217092037200928\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 3.6605286598205566\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: 4.212472438812256\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: -1.7229664325714111\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 4.78462815284729\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: 1.4748173952102661\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: -10.617886185646057\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: 6.058768033981323\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: 0.14792084693908691\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 6.057812571525574\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: -5.133456587791443\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: -0.1473832130432129\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: -2.5710535049438477\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: 5.820985436439514\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: -10.90016782283783\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 11.234133839607239\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: 0.07769107818603516\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -0.16060709953308105\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: -11.41217052936554\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 7.287287712097168\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -5.254154205322266\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 9.186216592788696\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: 0.5061250925064087\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 2.0688408613204956\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: -3.963114023208618\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -59.115424156188965\n",
      "batch_going: 1\n",
      "change in Valid loss: -57.24062442779541\n",
      "batch_going: 2\n",
      "change in Valid loss: -60.75575828552246\n",
      "batch_going: 3\n",
      "change in Valid loss: -46.956787109375\n",
      "batch_going: 4\n",
      "change in Valid loss: -59.71961975097656\n",
      "batch_going: 5\n",
      "change in Valid loss: -68.85213375091553\n",
      "batch_going: 6\n",
      "change in Valid loss: -26.25837802886963\n",
      "batch_going: 7\n",
      "change in Valid loss: -45.76601505279541\n",
      "batch_going: 8\n",
      "change in Valid loss: -50.15337944030762\n",
      "batch_going: 9\n",
      "change in Valid loss: -79.85947608947754\n",
      "batch_going: 10\n",
      "change in Valid loss: -62.00089931488037\n",
      "batch_going: 11\n",
      "change in Valid loss: -45.83857536315918\n",
      "batch_going: 12\n",
      "change in Valid loss: -36.064743995666504\n",
      "batch_going: 13\n",
      "change in Valid loss: -58.12628746032715\n",
      "batch_going: 14\n",
      "change in Valid loss: -44.16172504425049\n",
      "batch_going: 15\n",
      "change in Valid loss: -42.87127494812012\n",
      "batch_going: 16\n",
      "change in Valid loss: -41.00790023803711\n",
      "batch_going: 17\n",
      "change in Valid loss: -61.15377426147461\n",
      "batch_going: 18\n",
      "change in Valid loss: -75.27958869934082\n",
      "batch_going: 19\n",
      "change in Valid loss: -70.94249725341797\n",
      "batch_going: 20\n",
      "change in Valid loss: -28.997275829315186\n",
      "batch_going: 21\n",
      "change in Valid loss: -46.64348602294922\n",
      "batch_going: 22\n",
      "change in Valid loss: -56.904592514038086\n",
      "batch_going: 23\n",
      "change in Valid loss: -50.14939308166504\n",
      "batch_going: 24\n",
      "change in Valid loss: -35.209782123565674\n",
      "batch_going: 25\n",
      "change in Valid loss: -66.04516506195068\n",
      "batch_going: 26\n",
      "change in Valid loss: -55.09246826171875\n",
      "batch_going: 27\n",
      "change in Valid loss: -61.43836975097656\n",
      "batch_going: 28\n",
      "change in Valid loss: -71.62185668945312\n",
      "batch_going: 29\n",
      "change in Valid loss: -58.45489978790283\n",
      "batch_going: 30\n",
      "change in Valid loss: -58.42317581176758\n",
      "batch_going: 31\n",
      "change in Valid loss: -47.26572036743164\n",
      "batch_going: 32\n",
      "change in Valid loss: -47.1115779876709\n",
      "batch_going: 33\n",
      "change in Valid loss: -70.92246055603027\n",
      "batch_going: 34\n",
      "change in Valid loss: -47.87369728088379\n",
      "batch_going: 35\n",
      "change in Valid loss: -62.29723930358887\n",
      "batch_going: 36\n",
      "change in Valid loss: -30.17941951751709\n",
      "batch_going: 37\n",
      "change in Valid loss: -51.43390655517578\n",
      "batch_going: 38\n",
      "change in Valid loss: -61.13734722137451\n",
      "batch_going: 39\n",
      "change in Valid loss: -55.972042083740234\n",
      "batch_going: 40\n",
      "change in Valid loss: -51.70592784881592\n",
      "batch_going: 41\n",
      "change in Valid loss: -50.08443832397461\n",
      "batch_going: 42\n",
      "change in Valid loss: -48.39852333068848\n",
      "batch_going: 43\n",
      "change in Valid loss: -32.81836748123169\n",
      "batch_going: 44\n",
      "change in Valid loss: -47.24982738494873\n",
      "batch_going: 45\n",
      "change in Valid loss: -54.65281009674072\n",
      "batch_going: 46\n",
      "change in Valid loss: -54.17252540588379\n",
      "batch_going: 47\n",
      "change in Valid loss: -55.34738540649414\n",
      "batch_going: 48\n",
      "change in Valid loss: -43.272223472595215\n",
      "batch_going: 49\n",
      "change in Valid loss: -47.09193229675293\n",
      "batch_going: 50\n",
      "change in Valid loss: -50.55877685546875\n",
      "batch_going: 51\n",
      "change in Valid loss: -71.69838905334473\n",
      "batch_going: 52\n",
      "change in Valid loss: -49.60677146911621\n",
      "batch_going: 53\n",
      "change in Valid loss: -49.573469161987305\n",
      "batch_going: 54\n",
      "change in Valid loss: -57.096800804138184\n",
      "batch_going: 55\n",
      "change in Valid loss: -71.46261692047119\n",
      "batch_going: 56\n",
      "change in Valid loss: -62.152414321899414\n",
      "batch_going: 57\n",
      "change in Valid loss: -75.51333427429199\n",
      "batch_going: 58\n",
      "change in Valid loss: -47.34659194946289\n",
      "batch_going: 59\n",
      "change in Valid loss: -49.43202018737793\n",
      "batch_going: 60\n",
      "change in Valid loss: -70.5808162689209\n",
      "batch_going: 61\n",
      "change in Valid loss: -48.08785438537598\n",
      "batch_going: 62\n",
      "change in Valid loss: -90.79148292541504\n",
      "batch_going: 63\n",
      "change in Valid loss: -62.79909610748291\n",
      "batch_going: 64\n",
      "change in Valid loss: -51.081247329711914\n",
      "batch_going: 65\n",
      "change in Valid loss: -75.23765563964844\n",
      "batch_going: 66\n",
      "change in Valid loss: -61.29608154296875\n",
      "batch_going: 67\n",
      "change in Valid loss: -68.72367858886719\n",
      "batch_going: 68\n",
      "change in Valid loss: -86.54742240905762\n",
      "batch_going: 69\n",
      "change in Valid loss: -50.79826354980469\n",
      "batch_going: 70\n",
      "change in Valid loss: -48.244452476501465\n",
      "batch_going: 71\n",
      "change in Valid loss: -57.797746658325195\n",
      "batch_going: 72\n",
      "change in Valid loss: -46.768126487731934\n",
      "batch_going: 73\n",
      "change in Valid loss: -70.79652309417725\n",
      "batch_going: 74\n",
      "change in Valid loss: -46.790900230407715\n",
      "batch_going: 75\n",
      "change in Valid loss: -50.06588935852051\n",
      "batch_going: 76\n",
      "change in Valid loss: -55.84885597229004\n",
      "batch_going: 77\n",
      "change in Valid loss: -38.16298246383667\n",
      "batch_going: 78\n",
      "change in Valid loss: -44.60251808166504\n",
      "batch_going: 79\n",
      "change in Valid loss: -52.96041965484619\n",
      "batch_going: 80\n",
      "change in Valid loss: -66.71035766601562\n",
      "batch_going: 81\n",
      "change in Valid loss: -48.06130409240723\n",
      "batch_going: 82\n",
      "change in Valid loss: -36.499266624450684\n",
      "batch_going: 83\n",
      "change in Valid loss: -24.301514625549316\n",
      "Epoch: 12 \tTraining Loss: 13.399251 \tValidation Loss: 54.501052\n",
      "668\n",
      "Batch_idx 0\n",
      "batch_going: 0\n",
      "Change in Train_loss: -5.843995213508606\n",
      "Batch_idx 1\n",
      "batch_going: 1\n",
      "Change in Train_loss: -1.5255844593048096\n",
      "Batch_idx 2\n",
      "batch_going: 2\n",
      "Change in Train_loss: 2.9856589436531067\n",
      "Batch_idx 3\n",
      "batch_going: 3\n",
      "Change in Train_loss: -0.9082147479057312\n",
      "Batch_idx 4\n",
      "batch_going: 4\n",
      "Change in Train_loss: -0.7675588130950928\n",
      "Batch_idx 5\n",
      "batch_going: 5\n",
      "Change in Train_loss: -3.622102737426758\n",
      "Batch_idx 6\n",
      "batch_going: 6\n",
      "Change in Train_loss: 2.350865602493286\n",
      "Batch_idx 7\n",
      "batch_going: 7\n",
      "Change in Train_loss: -7.527890205383301\n",
      "Batch_idx 8\n",
      "batch_going: 8\n",
      "Change in Train_loss: 8.965904712677002\n",
      "Batch_idx 9\n",
      "batch_going: 9\n",
      "Change in Train_loss: 3.351885974407196\n",
      "Batch_idx 10\n",
      "batch_going: 10\n",
      "Change in Train_loss: -2.2171053290367126\n",
      "Batch_idx 11\n",
      "batch_going: 11\n",
      "Change in Train_loss: -5.2041614055633545\n",
      "Batch_idx 12\n",
      "batch_going: 12\n",
      "Change in Train_loss: -5.196468830108643\n",
      "Batch_idx 13\n",
      "batch_going: 13\n",
      "Change in Train_loss: 10.649947822093964\n",
      "Batch_idx 14\n",
      "batch_going: 14\n",
      "Change in Train_loss: -15.282571017742157\n",
      "Batch_idx 15\n",
      "batch_going: 15\n",
      "Change in Train_loss: 11.625677347183228\n",
      "Batch_idx 16\n",
      "batch_going: 16\n",
      "Change in Train_loss: -7.364338636398315\n",
      "Batch_idx 17\n",
      "batch_going: 17\n",
      "Change in Train_loss: 5.78157901763916\n",
      "Batch_idx 18\n",
      "batch_going: 18\n",
      "Change in Train_loss: -2.3999059200286865\n",
      "Batch_idx 19\n",
      "batch_going: 19\n",
      "Change in Train_loss: 1.735759973526001\n",
      "Batch_idx 20\n",
      "batch_going: 20\n",
      "Change in Train_loss: 7.5792258977890015\n",
      "Batch_idx 21\n",
      "batch_going: 21\n",
      "Change in Train_loss: -6.262781023979187\n",
      "Batch_idx 22\n",
      "batch_going: 22\n",
      "Change in Train_loss: -1.0855662822723389\n",
      "Batch_idx 23\n",
      "batch_going: 23\n",
      "Change in Train_loss: 6.95928156375885\n",
      "Batch_idx 24\n",
      "batch_going: 24\n",
      "Change in Train_loss: -10.584182143211365\n",
      "Batch_idx 25\n",
      "batch_going: 25\n",
      "Change in Train_loss: -2.6448118686676025\n",
      "Batch_idx 26\n",
      "batch_going: 26\n",
      "Change in Train_loss: 5.165585279464722\n",
      "Batch_idx 27\n",
      "batch_going: 27\n",
      "Change in Train_loss: 0.5335700511932373\n",
      "Batch_idx 28\n",
      "batch_going: 28\n",
      "Change in Train_loss: 5.07428765296936\n",
      "Batch_idx 29\n",
      "batch_going: 29\n",
      "Change in Train_loss: -13.355098962783813\n",
      "Batch_idx 30\n",
      "batch_going: 30\n",
      "Change in Train_loss: 1.4246714115142822\n",
      "Batch_idx 31\n",
      "batch_going: 31\n",
      "Change in Train_loss: -3.378244638442993\n",
      "Batch_idx 32\n",
      "batch_going: 32\n",
      "Change in Train_loss: 10.81493616104126\n",
      "Batch_idx 33\n",
      "batch_going: 33\n",
      "Change in Train_loss: 5.737211108207703\n",
      "Batch_idx 34\n",
      "batch_going: 34\n",
      "Change in Train_loss: -18.57001006603241\n",
      "Batch_idx 35\n",
      "batch_going: 35\n",
      "Change in Train_loss: 16.130062341690063\n",
      "Batch_idx 36\n",
      "batch_going: 36\n",
      "Change in Train_loss: -7.859889268875122\n",
      "Batch_idx 37\n",
      "batch_going: 37\n",
      "Change in Train_loss: 2.0959043502807617\n",
      "Batch_idx 38\n",
      "batch_going: 38\n",
      "Change in Train_loss: 2.8622061014175415\n",
      "Batch_idx 39\n",
      "batch_going: 39\n",
      "Change in Train_loss: 0.6391352415084839\n",
      "Batch_idx 40\n",
      "batch_going: 40\n",
      "Change in Train_loss: -18.76084327697754\n",
      "Batch_idx 41\n",
      "batch_going: 41\n",
      "Change in Train_loss: 21.75450325012207\n",
      "Batch_idx 42\n",
      "batch_going: 42\n",
      "Change in Train_loss: 0.1268225908279419\n",
      "Batch_idx 43\n",
      "batch_going: 43\n",
      "Change in Train_loss: -5.413816571235657\n",
      "Batch_idx 44\n",
      "batch_going: 44\n",
      "Change in Train_loss: -7.1454644203186035\n",
      "Batch_idx 45\n",
      "batch_going: 45\n",
      "Change in Train_loss: -1.0009312629699707\n",
      "Batch_idx 46\n",
      "batch_going: 46\n",
      "Change in Train_loss: 6.853357553482056\n",
      "Batch_idx 47\n",
      "batch_going: 47\n",
      "Change in Train_loss: -8.333224058151245\n",
      "Batch_idx 48\n",
      "batch_going: 48\n",
      "Change in Train_loss: 14.224902391433716\n",
      "Batch_idx 49\n",
      "batch_going: 49\n",
      "Change in Train_loss: -2.3893284797668457\n",
      "Batch_idx 50\n",
      "batch_going: 50\n",
      "Change in Train_loss: -9.440912008285522\n",
      "Batch_idx 51\n",
      "batch_going: 51\n",
      "Change in Train_loss: 5.995426177978516\n",
      "Batch_idx 52\n",
      "batch_going: 52\n",
      "Change in Train_loss: 10.908484011888504\n",
      "Batch_idx 53\n",
      "batch_going: 53\n",
      "Change in Train_loss: -4.43533256649971\n",
      "Batch_idx 54\n",
      "batch_going: 54\n",
      "Change in Train_loss: -13.484344482421875\n",
      "Batch_idx 55\n",
      "batch_going: 55\n",
      "Change in Train_loss: 7.735928297042847\n",
      "Batch_idx 56\n",
      "batch_going: 56\n",
      "Change in Train_loss: -1.7187201976776123\n",
      "Batch_idx 57\n",
      "batch_going: 57\n",
      "Change in Train_loss: 3.260226249694824\n",
      "Batch_idx 58\n",
      "batch_going: 58\n",
      "Change in Train_loss: -7.2544050216674805\n",
      "Batch_idx 59\n",
      "batch_going: 59\n",
      "Change in Train_loss: 7.894033789634705\n",
      "Batch_idx 60\n",
      "batch_going: 60\n",
      "Change in Train_loss: -6.662706732749939\n",
      "Batch_idx 61\n",
      "batch_going: 61\n",
      "Change in Train_loss: 10.667915344238281\n",
      "Batch_idx 62\n",
      "batch_going: 62\n",
      "Change in Train_loss: -5.24029016494751\n",
      "Batch_idx 63\n",
      "batch_going: 63\n",
      "Change in Train_loss: -8.940110206604004\n",
      "Batch_idx 64\n",
      "batch_going: 64\n",
      "Change in Train_loss: 4.797393083572388\n",
      "Batch_idx 65\n",
      "batch_going: 65\n",
      "Change in Train_loss: 7.742234468460083\n",
      "Batch_idx 66\n",
      "batch_going: 66\n",
      "Change in Train_loss: 0.9441065788269043\n",
      "Batch_idx 67\n",
      "batch_going: 67\n",
      "Change in Train_loss: -3.7115979194641113\n",
      "Batch_idx 68\n",
      "batch_going: 68\n",
      "Change in Train_loss: -7.641572952270508\n",
      "Batch_idx 69\n",
      "batch_going: 69\n",
      "Change in Train_loss: -1.4628541469573975\n",
      "Batch_idx 70\n",
      "batch_going: 70\n",
      "Change in Train_loss: 7.813612222671509\n",
      "Batch_idx 71\n",
      "batch_going: 71\n",
      "Change in Train_loss: -2.5954341888427734\n",
      "Batch_idx 72\n",
      "batch_going: 72\n",
      "Change in Train_loss: -3.41660737991333\n",
      "Batch_idx 73\n",
      "batch_going: 73\n",
      "Change in Train_loss: 9.973648190498352\n",
      "Batch_idx 74\n",
      "batch_going: 74\n",
      "Change in Train_loss: -2.731083035469055\n",
      "Batch_idx 75\n",
      "batch_going: 75\n",
      "Change in Train_loss: -1.0516643524169922\n",
      "Batch_idx 76\n",
      "batch_going: 76\n",
      "Change in Train_loss: 5.857614874839783\n",
      "Batch_idx 77\n",
      "batch_going: 77\n",
      "Change in Train_loss: -1.4607489109039307\n",
      "Batch_idx 78\n",
      "batch_going: 78\n",
      "Change in Train_loss: 0.039966702461242676\n",
      "Batch_idx 79\n",
      "batch_going: 79\n",
      "Change in Train_loss: -3.169844150543213\n",
      "Batch_idx 80\n",
      "batch_going: 80\n",
      "Change in Train_loss: -4.5343077182769775\n",
      "Batch_idx 81\n",
      "batch_going: 81\n",
      "Change in Train_loss: 10.567612946033478\n",
      "Batch_idx 82\n",
      "batch_going: 82\n",
      "Change in Train_loss: -16.965064108371735\n",
      "Batch_idx 83\n",
      "batch_going: 83\n",
      "Change in Train_loss: 13.40541958808899\n",
      "Batch_idx 84\n",
      "batch_going: 84\n",
      "Change in Train_loss: -2.330472469329834\n",
      "Batch_idx 85\n",
      "batch_going: 85\n",
      "Change in Train_loss: -7.039926052093506\n",
      "Batch_idx 86\n",
      "batch_going: 86\n",
      "Change in Train_loss: 2.6459920406341553\n",
      "Batch_idx 87\n",
      "batch_going: 87\n",
      "Change in Train_loss: 7.991777658462524\n",
      "Batch_idx 88\n",
      "batch_going: 88\n",
      "Change in Train_loss: -12.373740673065186\n",
      "Batch_idx 89\n",
      "batch_going: 89\n",
      "Change in Train_loss: 6.388723850250244\n",
      "Batch_idx 90\n",
      "batch_going: 90\n",
      "Change in Train_loss: 2.2142302989959717\n",
      "Batch_idx 91\n",
      "batch_going: 91\n",
      "Change in Train_loss: -2.8469645977020264\n",
      "Batch_idx 92\n",
      "batch_going: 92\n",
      "Change in Train_loss: 6.461284160614014\n",
      "Batch_idx 93\n",
      "batch_going: 93\n",
      "Change in Train_loss: -7.875379323959351\n",
      "Batch_idx 94\n",
      "batch_going: 94\n",
      "Change in Train_loss: 3.7750327587127686\n",
      "Batch_idx 95\n",
      "batch_going: 95\n",
      "Change in Train_loss: -4.475216865539551\n",
      "Batch_idx 96\n",
      "batch_going: 96\n",
      "Change in Train_loss: 5.377267599105835\n",
      "Batch_idx 97\n",
      "batch_going: 97\n",
      "Change in Train_loss: -9.11247968673706\n",
      "Batch_idx 98\n",
      "batch_going: 98\n",
      "Change in Train_loss: 0.5022597312927246\n",
      "Batch_idx 99\n",
      "batch_going: 99\n",
      "Change in Train_loss: 4.4701313972473145\n",
      "Batch_idx 100\n",
      "batch_going: 100\n",
      "Change in Train_loss: 5.361319184303284\n",
      "Batch_idx 101\n",
      "batch_going: 101\n",
      "Change in Train_loss: -18.06803047657013\n",
      "Batch_idx 102\n",
      "batch_going: 102\n",
      "Change in Train_loss: 12.314677238464355\n",
      "Batch_idx 103\n",
      "batch_going: 103\n",
      "Change in Train_loss: 7.354990839958191\n",
      "Batch_idx 104\n",
      "batch_going: 104\n",
      "Change in Train_loss: 1.4453524351119995\n",
      "Batch_idx 105\n",
      "batch_going: 105\n",
      "Change in Train_loss: -11.000739336013794\n",
      "Batch_idx 106\n",
      "batch_going: 106\n",
      "Change in Train_loss: 9.437240958213806\n",
      "Batch_idx 107\n",
      "batch_going: 107\n",
      "Change in Train_loss: -7.422793507575989\n",
      "Batch_idx 108\n",
      "batch_going: 108\n",
      "Change in Train_loss: 7.442230582237244\n",
      "Batch_idx 109\n",
      "batch_going: 109\n",
      "Change in Train_loss: -4.081682562828064\n",
      "Batch_idx 110\n",
      "batch_going: 110\n",
      "Change in Train_loss: 5.693410634994507\n",
      "Batch_idx 111\n",
      "batch_going: 111\n",
      "Change in Train_loss: -10.46313762664795\n",
      "Batch_idx 112\n",
      "batch_going: 112\n",
      "Change in Train_loss: 5.111621618270874\n",
      "Batch_idx 113\n",
      "batch_going: 113\n",
      "Change in Train_loss: -6.169397830963135\n",
      "Batch_idx 114\n",
      "batch_going: 114\n",
      "Change in Train_loss: 4.533563852310181\n",
      "Batch_idx 115\n",
      "batch_going: 115\n",
      "Change in Train_loss: 4.954706430435181\n",
      "Batch_idx 116\n",
      "batch_going: 116\n",
      "Change in Train_loss: -4.297260046005249\n",
      "Batch_idx 117\n",
      "batch_going: 117\n",
      "Change in Train_loss: 2.92913019657135\n",
      "Batch_idx 118\n",
      "batch_going: 118\n",
      "Change in Train_loss: -1.715736985206604\n",
      "Batch_idx 119\n",
      "batch_going: 119\n",
      "Change in Train_loss: -2.3681282997131348\n",
      "Batch_idx 120\n",
      "batch_going: 120\n",
      "Change in Train_loss: -9.502115249633789\n",
      "Batch_idx 121\n",
      "batch_going: 121\n",
      "Change in Train_loss: 8.39066743850708\n",
      "Batch_idx 122\n",
      "batch_going: 122\n",
      "Change in Train_loss: 5.55665910243988\n",
      "Batch_idx 123\n",
      "batch_going: 123\n",
      "Change in Train_loss: -5.367352366447449\n",
      "Batch_idx 124\n",
      "batch_going: 124\n",
      "Change in Train_loss: 2.474195957183838\n",
      "Batch_idx 125\n",
      "batch_going: 125\n",
      "Change in Train_loss: -1.0405218601226807\n",
      "Batch_idx 126\n",
      "batch_going: 126\n",
      "Change in Train_loss: 0.8389222621917725\n",
      "Batch_idx 127\n",
      "batch_going: 127\n",
      "Change in Train_loss: 6.751174032688141\n",
      "Batch_idx 128\n",
      "batch_going: 128\n",
      "Change in Train_loss: -1.6034874320030212\n",
      "Batch_idx 129\n",
      "batch_going: 129\n",
      "Change in Train_loss: -1.8716037273406982\n",
      "Batch_idx 130\n",
      "batch_going: 130\n",
      "Change in Train_loss: -4.984520077705383\n",
      "Batch_idx 131\n",
      "batch_going: 131\n",
      "Change in Train_loss: 4.074927568435669\n",
      "Batch_idx 132\n",
      "batch_going: 132\n",
      "Change in Train_loss: -3.2439029216766357\n",
      "Batch_idx 133\n",
      "batch_going: 133\n",
      "Change in Train_loss: -2.589477300643921\n",
      "Batch_idx 134\n",
      "batch_going: 134\n",
      "Change in Train_loss: 0.03468036651611328\n",
      "Batch_idx 135\n",
      "batch_going: 135\n",
      "Change in Train_loss: -3.3377599716186523\n",
      "Batch_idx 136\n",
      "batch_going: 136\n",
      "Change in Train_loss: 10.331481099128723\n",
      "Batch_idx 137\n",
      "batch_going: 137\n",
      "Change in Train_loss: -10.980198979377747\n",
      "Batch_idx 138\n",
      "batch_going: 138\n",
      "Change in Train_loss: 9.692825078964233\n",
      "Batch_idx 139\n",
      "batch_going: 139\n",
      "Change in Train_loss: 0.7033699750900269\n",
      "Batch_idx 140\n",
      "batch_going: 140\n",
      "Change in Train_loss: -10.353288054466248\n",
      "Batch_idx 141\n",
      "batch_going: 141\n",
      "Change in Train_loss: 8.88185739517212\n",
      "Batch_idx 142\n",
      "batch_going: 142\n",
      "Change in Train_loss: 7.297870516777039\n",
      "Batch_idx 143\n",
      "batch_going: 143\n",
      "Change in Train_loss: -3.0188918113708496\n",
      "Batch_idx 144\n",
      "batch_going: 144\n",
      "Change in Train_loss: -0.3837621212005615\n",
      "Batch_idx 145\n",
      "batch_going: 145\n",
      "Change in Train_loss: 3.9120914041996\n",
      "Batch_idx 146\n",
      "batch_going: 146\n",
      "Change in Train_loss: -12.765640765428543\n",
      "Batch_idx 147\n",
      "batch_going: 147\n",
      "Change in Train_loss: 4.911274313926697\n",
      "Batch_idx 148\n",
      "batch_going: 148\n",
      "Change in Train_loss: 1.657668948173523\n",
      "Batch_idx 149\n",
      "batch_going: 149\n",
      "Change in Train_loss: -8.206254243850708\n",
      "Batch_idx 150\n",
      "batch_going: 150\n",
      "Change in Train_loss: 6.2213134765625\n",
      "Batch_idx 151\n",
      "batch_going: 151\n",
      "Change in Train_loss: -1.2187957763671875\n",
      "Batch_idx 152\n",
      "batch_going: 152\n",
      "Change in Train_loss: -5.803177356719971\n",
      "Batch_idx 153\n",
      "batch_going: 153\n",
      "Change in Train_loss: 10.057038068771362\n",
      "Batch_idx 154\n",
      "batch_going: 154\n",
      "Change in Train_loss: -4.719310998916626\n",
      "Batch_idx 155\n",
      "batch_going: 155\n",
      "Change in Train_loss: -4.723614454269409\n",
      "Batch_idx 156\n",
      "batch_going: 156\n",
      "Change in Train_loss: 11.045191884040833\n",
      "Batch_idx 157\n",
      "batch_going: 157\n",
      "Change in Train_loss: -10.734322667121887\n",
      "Batch_idx 158\n",
      "batch_going: 158\n",
      "Change in Train_loss: 5.585606098175049\n",
      "Batch_idx 159\n",
      "batch_going: 159\n",
      "Change in Train_loss: -1.4542138576507568\n",
      "Batch_idx 160\n",
      "batch_going: 160\n",
      "Change in Train_loss: 8.861000537872314\n",
      "Batch_idx 161\n",
      "batch_going: 161\n",
      "Change in Train_loss: -1.6355830430984497\n",
      "Batch_idx 162\n",
      "batch_going: 162\n",
      "Change in Train_loss: -13.437616229057312\n",
      "Batch_idx 163\n",
      "batch_going: 163\n",
      "Change in Train_loss: 10.170605778694153\n",
      "Batch_idx 164\n",
      "batch_going: 164\n",
      "Change in Train_loss: -7.005249857902527\n",
      "Batch_idx 165\n",
      "batch_going: 165\n",
      "Change in Train_loss: 2.687619924545288\n",
      "Batch_idx 166\n",
      "batch_going: 166\n",
      "Change in Train_loss: -0.3038763999938965\n",
      "Batch_idx 167\n",
      "batch_going: 167\n",
      "Change in Train_loss: 1.7539501190185547\n",
      "Batch_idx 168\n",
      "batch_going: 168\n",
      "Change in Train_loss: 0.5186855792999268\n",
      "Batch_idx 169\n",
      "batch_going: 169\n",
      "Change in Train_loss: -3.1348586082458496\n",
      "Batch_idx 170\n",
      "batch_going: 170\n",
      "Change in Train_loss: -2.677774429321289\n",
      "Batch_idx 171\n",
      "batch_going: 171\n",
      "Change in Train_loss: 12.10143119096756\n",
      "Batch_idx 172\n",
      "batch_going: 172\n",
      "Change in Train_loss: -0.11089414358139038\n",
      "Batch_idx 173\n",
      "batch_going: 173\n",
      "Change in Train_loss: -0.4299202561378479\n",
      "Batch_idx 174\n",
      "batch_going: 174\n",
      "Change in Train_loss: 1.6809147596359253\n",
      "Batch_idx 175\n",
      "batch_going: 175\n",
      "Change in Train_loss: -4.542111456394196\n",
      "Batch_idx 176\n",
      "batch_going: 176\n",
      "Change in Train_loss: -8.052135109901428\n",
      "Batch_idx 177\n",
      "batch_going: 177\n",
      "Change in Train_loss: 3.4126949310302734\n",
      "Batch_idx 178\n",
      "batch_going: 178\n",
      "Change in Train_loss: -2.52264142036438\n",
      "Batch_idx 179\n",
      "batch_going: 179\n",
      "Change in Train_loss: -1.9962942600250244\n",
      "Batch_idx 180\n",
      "batch_going: 180\n",
      "Change in Train_loss: 0.5979037284851074\n",
      "Batch_idx 181\n",
      "batch_going: 181\n",
      "Change in Train_loss: 6.96086049079895\n",
      "Batch_idx 182\n",
      "batch_going: 182\n",
      "Change in Train_loss: -2.146538496017456\n",
      "Batch_idx 183\n",
      "batch_going: 183\n",
      "Change in Train_loss: 4.311851859092712\n",
      "Batch_idx 184\n",
      "batch_going: 184\n",
      "Change in Train_loss: -10.537894368171692\n",
      "Batch_idx 185\n",
      "batch_going: 185\n",
      "Change in Train_loss: 10.31592309474945\n",
      "Batch_idx 186\n",
      "batch_going: 186\n",
      "Change in Train_loss: -3.5603874921798706\n",
      "Batch_idx 187\n",
      "batch_going: 187\n",
      "Change in Train_loss: -1.0226714611053467\n",
      "Batch_idx 188\n",
      "batch_going: 188\n",
      "Change in Train_loss: 4.501047134399414\n",
      "Batch_idx 189\n",
      "batch_going: 189\n",
      "Change in Train_loss: -4.690870046615601\n",
      "Batch_idx 190\n",
      "batch_going: 190\n",
      "Change in Train_loss: 2.0317935943603516\n",
      "Batch_idx 191\n",
      "batch_going: 191\n",
      "Change in Train_loss: 1.0875755548477173\n",
      "Batch_idx 192\n",
      "batch_going: 192\n",
      "Change in Train_loss: 0.19973456859588623\n",
      "Batch_idx 193\n",
      "batch_going: 193\n",
      "Change in Train_loss: -0.15256106853485107\n",
      "Batch_idx 194\n",
      "batch_going: 194\n",
      "Change in Train_loss: -0.21979928016662598\n",
      "Batch_idx 195\n",
      "batch_going: 195\n",
      "Change in Train_loss: -2.9929107427597046\n",
      "Batch_idx 196\n",
      "batch_going: 196\n",
      "Change in Train_loss: -8.137350082397461\n",
      "Batch_idx 197\n",
      "batch_going: 197\n",
      "Change in Train_loss: 1.562635898590088\n",
      "Batch_idx 198\n",
      "batch_going: 198\n",
      "Change in Train_loss: 4.4171142578125\n",
      "Batch_idx 199\n",
      "batch_going: 199\n",
      "Change in Train_loss: 3.276219367980957\n",
      "Batch_idx 200\n",
      "batch_going: 200\n",
      "Change in Train_loss: 5.6834352016448975\n",
      "Batch_idx 201\n",
      "batch_going: 201\n",
      "Change in Train_loss: -3.96712064743042\n",
      "Batch_idx 202\n",
      "batch_going: 202\n",
      "Change in Train_loss: 2.3073136806488037\n",
      "Batch_idx 203\n",
      "batch_going: 203\n",
      "Change in Train_loss: -9.19589877128601\n",
      "Batch_idx 204\n",
      "batch_going: 204\n",
      "Change in Train_loss: 7.106214165687561\n",
      "Batch_idx 205\n",
      "batch_going: 205\n",
      "Change in Train_loss: -3.7709659337997437\n",
      "Batch_idx 206\n",
      "batch_going: 206\n",
      "Change in Train_loss: 6.272014379501343\n",
      "Batch_idx 207\n",
      "batch_going: 207\n",
      "Change in Train_loss: -3.0492258071899414\n",
      "Batch_idx 208\n",
      "batch_going: 208\n",
      "Change in Train_loss: -5.035845041275024\n",
      "Batch_idx 209\n",
      "batch_going: 209\n",
      "Change in Train_loss: 4.148502349853516\n",
      "Batch_idx 210\n",
      "batch_going: 210\n",
      "Change in Train_loss: -0.49712538719177246\n",
      "Batch_idx 211\n",
      "batch_going: 211\n",
      "Change in Train_loss: -3.312610387802124\n",
      "Batch_idx 212\n",
      "batch_going: 212\n",
      "Change in Train_loss: 1.439129114151001\n",
      "Batch_idx 213\n",
      "batch_going: 213\n",
      "Change in Train_loss: 3.52863609790802\n",
      "Batch_idx 214\n",
      "batch_going: 214\n",
      "Change in Train_loss: 3.828616142272949\n",
      "Batch_idx 215\n",
      "batch_going: 215\n",
      "Change in Train_loss: -9.273999333381653\n",
      "Batch_idx 216\n",
      "batch_going: 216\n",
      "Change in Train_loss: -2.418428659439087\n",
      "Batch_idx 217\n",
      "batch_going: 217\n",
      "Change in Train_loss: 4.288070201873779\n",
      "Batch_idx 218\n",
      "batch_going: 218\n",
      "Change in Train_loss: -0.8018887042999268\n",
      "Batch_idx 219\n",
      "batch_going: 219\n",
      "Change in Train_loss: 0.3801274299621582\n",
      "Batch_idx 220\n",
      "batch_going: 220\n",
      "Change in Train_loss: 2.20622181892395\n",
      "Batch_idx 221\n",
      "batch_going: 221\n",
      "Change in Train_loss: -7.873907089233398\n",
      "Batch_idx 222\n",
      "batch_going: 222\n",
      "Change in Train_loss: 10.11890172958374\n",
      "Batch_idx 223\n",
      "batch_going: 223\n",
      "Change in Train_loss: -12.015607357025146\n",
      "Batch_idx 224\n",
      "batch_going: 224\n",
      "Change in Train_loss: 18.96040767431259\n",
      "Batch_idx 225\n",
      "batch_going: 225\n",
      "Change in Train_loss: -20.171376168727875\n",
      "Batch_idx 226\n",
      "batch_going: 226\n",
      "Change in Train_loss: 16.68880522251129\n",
      "Batch_idx 227\n",
      "batch_going: 227\n",
      "Change in Train_loss: -6.1082834005355835\n",
      "Batch_idx 228\n",
      "batch_going: 228\n",
      "Change in Train_loss: 4.430986642837524\n",
      "Batch_idx 229\n",
      "batch_going: 229\n",
      "Change in Train_loss: 3.7743163108825684\n",
      "Batch_idx 230\n",
      "batch_going: 230\n",
      "Change in Train_loss: -2.064284086227417\n",
      "Batch_idx 231\n",
      "batch_going: 231\n",
      "Change in Train_loss: -3.2363158464431763\n",
      "Batch_idx 232\n",
      "batch_going: 232\n",
      "Change in Train_loss: -1.8684357404708862\n",
      "Batch_idx 233\n",
      "batch_going: 233\n",
      "Change in Train_loss: 5.544900894165039\n",
      "Batch_idx 234\n",
      "batch_going: 234\n",
      "Change in Train_loss: -11.280207633972168\n",
      "Batch_idx 235\n",
      "batch_going: 235\n",
      "Change in Train_loss: 11.278842091560364\n",
      "Batch_idx 236\n",
      "batch_going: 236\n",
      "Change in Train_loss: -20.09464919567108\n",
      "Batch_idx 237\n",
      "batch_going: 237\n",
      "Change in Train_loss: 19.821472764015198\n",
      "Batch_idx 238\n",
      "batch_going: 238\n",
      "Change in Train_loss: -13.909371495246887\n",
      "Batch_idx 239\n",
      "batch_going: 239\n",
      "Change in Train_loss: 5.864579677581787\n",
      "Batch_idx 240\n",
      "batch_going: 240\n",
      "Change in Train_loss: 3.6935830116271973\n",
      "Batch_idx 241\n",
      "batch_going: 241\n",
      "Change in Train_loss: 4.702304899692535\n",
      "Batch_idx 242\n",
      "batch_going: 242\n",
      "Change in Train_loss: -15.400189459323883\n",
      "Batch_idx 243\n",
      "batch_going: 243\n",
      "Change in Train_loss: 9.206982851028442\n",
      "Batch_idx 244\n",
      "batch_going: 244\n",
      "Change in Train_loss: 3.2806426286697388\n",
      "Batch_idx 245\n",
      "batch_going: 245\n",
      "Change in Train_loss: -1.8773090839385986\n",
      "Batch_idx 246\n",
      "batch_going: 246\n",
      "Change in Train_loss: 0.5550581216812134\n",
      "Batch_idx 247\n",
      "batch_going: 247\n",
      "Change in Train_loss: -1.5261423587799072\n",
      "Batch_idx 248\n",
      "batch_going: 248\n",
      "Change in Train_loss: 9.024922847747803\n",
      "Batch_idx 249\n",
      "batch_going: 249\n",
      "Change in Train_loss: -8.573037385940552\n",
      "Batch_idx 250\n",
      "batch_going: 250\n",
      "Change in Train_loss: 2.8422385454177856\n",
      "Batch_idx 251\n",
      "batch_going: 251\n",
      "Change in Train_loss: 1.8304765224456787\n",
      "Batch_idx 252\n",
      "batch_going: 252\n",
      "Change in Train_loss: -8.43986451625824\n",
      "Batch_idx 253\n",
      "batch_going: 253\n",
      "Change in Train_loss: -3.46038818359375\n",
      "Batch_idx 254\n",
      "batch_going: 254\n",
      "Change in Train_loss: 11.959542632102966\n",
      "Batch_idx 255\n",
      "batch_going: 255\n",
      "Change in Train_loss: -7.416278719902039\n",
      "Batch_idx 256\n",
      "batch_going: 256\n",
      "Change in Train_loss: -3.629051446914673\n",
      "Batch_idx 257\n",
      "batch_going: 257\n",
      "Change in Train_loss: 13.028720319271088\n",
      "Batch_idx 258\n",
      "batch_going: 258\n",
      "Change in Train_loss: 1.3699713349342346\n",
      "Batch_idx 259\n",
      "batch_going: 259\n",
      "Change in Train_loss: -5.647883415222168\n",
      "Batch_idx 260\n",
      "batch_going: 260\n",
      "Change in Train_loss: -12.576415538787842\n",
      "Batch_idx 261\n",
      "batch_going: 261\n",
      "Change in Train_loss: 6.460576057434082\n",
      "Batch_idx 262\n",
      "batch_going: 262\n",
      "Change in Train_loss: 5.303663015365601\n",
      "Batch_idx 263\n",
      "batch_going: 263\n",
      "Change in Train_loss: 0.6654727458953857\n",
      "Batch_idx 264\n",
      "batch_going: 264\n",
      "Change in Train_loss: -9.222595691680908\n",
      "Batch_idx 265\n",
      "batch_going: 265\n",
      "Change in Train_loss: -1.9736409187316895\n",
      "Batch_idx 266\n",
      "batch_going: 266\n",
      "Change in Train_loss: 11.951106190681458\n",
      "Batch_idx 267\n",
      "batch_going: 267\n",
      "Change in Train_loss: 0.5693662166595459\n",
      "Batch_idx 268\n",
      "batch_going: 268\n",
      "Change in Train_loss: -12.895588278770447\n",
      "Batch_idx 269\n",
      "batch_going: 269\n",
      "Change in Train_loss: 15.628422200679779\n",
      "Batch_idx 270\n",
      "batch_going: 270\n",
      "Change in Train_loss: -6.2093386054039\n",
      "Batch_idx 271\n",
      "batch_going: 271\n",
      "Change in Train_loss: 0.6004375219345093\n",
      "Batch_idx 272\n",
      "batch_going: 272\n",
      "Change in Train_loss: 0.14506936073303223\n",
      "Batch_idx 273\n",
      "batch_going: 273\n",
      "Change in Train_loss: -8.77442181110382\n",
      "Batch_idx 274\n",
      "batch_going: 274\n",
      "Change in Train_loss: 12.962153553962708\n",
      "Batch_idx 275\n",
      "batch_going: 275\n",
      "Change in Train_loss: -9.983977675437927\n",
      "Batch_idx 276\n",
      "batch_going: 276\n",
      "Change in Train_loss: 2.4456214904785156\n",
      "Batch_idx 277\n",
      "batch_going: 277\n",
      "Change in Train_loss: 0.027256011962890625\n",
      "Batch_idx 278\n",
      "batch_going: 278\n",
      "Change in Train_loss: -1.1340582370758057\n",
      "Batch_idx 279\n",
      "batch_going: 279\n",
      "Change in Train_loss: -0.09998917579650879\n",
      "Batch_idx 280\n",
      "batch_going: 280\n",
      "Change in Train_loss: 0.47885894775390625\n",
      "Batch_idx 281\n",
      "batch_going: 281\n",
      "Change in Train_loss: -3.124631643295288\n",
      "Batch_idx 282\n",
      "batch_going: 282\n",
      "Change in Train_loss: 7.869101166725159\n",
      "Batch_idx 283\n",
      "batch_going: 283\n",
      "Change in Train_loss: -3.6337262392044067\n",
      "Batch_idx 284\n",
      "batch_going: 284\n",
      "Change in Train_loss: -0.00408172607421875\n",
      "Batch_idx 285\n",
      "batch_going: 285\n",
      "Change in Train_loss: -0.6613969802856445\n",
      "Batch_idx 286\n",
      "batch_going: 286\n",
      "Change in Train_loss: -7.9241251945495605\n",
      "Batch_idx 287\n",
      "batch_going: 287\n",
      "Change in Train_loss: 9.93699312210083\n",
      "Batch_idx 288\n",
      "batch_going: 288\n",
      "Change in Train_loss: -3.3437466621398926\n",
      "Batch_idx 289\n",
      "batch_going: 289\n",
      "Change in Train_loss: 7.8545016050338745\n",
      "Batch_idx 290\n",
      "batch_going: 290\n",
      "Change in Train_loss: -6.950634121894836\n",
      "Batch_idx 291\n",
      "batch_going: 291\n",
      "Change in Train_loss: -2.475022077560425\n",
      "Batch_idx 292\n",
      "batch_going: 292\n",
      "Change in Train_loss: -3.9013242721557617\n",
      "Batch_idx 293\n",
      "batch_going: 293\n",
      "Change in Train_loss: 8.94113540649414\n",
      "Batch_idx 294\n",
      "batch_going: 294\n",
      "Change in Train_loss: 2.1941006183624268\n",
      "Batch_idx 295\n",
      "batch_going: 295\n",
      "Change in Train_loss: 2.3752379417419434\n",
      "Batch_idx 296\n",
      "batch_going: 296\n",
      "Change in Train_loss: -5.576999187469482\n",
      "Batch_idx 297\n",
      "batch_going: 297\n",
      "Change in Train_loss: 4.459660649299622\n",
      "Batch_idx 298\n",
      "batch_going: 298\n",
      "Change in Train_loss: -6.9081491231918335\n",
      "Batch_idx 299\n",
      "batch_going: 299\n",
      "Change in Train_loss: 5.61309278011322\n",
      "Batch_idx 300\n",
      "batch_going: 300\n",
      "Change in Train_loss: -11.836273074150085\n",
      "Batch_idx 301\n",
      "batch_going: 301\n",
      "Change in Train_loss: -7.526097297668457\n",
      "Batch_idx 302\n",
      "batch_going: 302\n",
      "Change in Train_loss: 16.194279193878174\n",
      "Batch_idx 303\n",
      "batch_going: 303\n",
      "Change in Train_loss: -0.010004043579101562\n",
      "Batch_idx 304\n",
      "batch_going: 304\n",
      "Change in Train_loss: 8.310900330543518\n",
      "Batch_idx 305\n",
      "batch_going: 305\n",
      "Change in Train_loss: -4.467076659202576\n",
      "Batch_idx 306\n",
      "batch_going: 306\n",
      "Change in Train_loss: -0.24316072463989258\n",
      "Batch_idx 307\n",
      "batch_going: 307\n",
      "Change in Train_loss: -4.756139516830444\n",
      "Batch_idx 308\n",
      "batch_going: 308\n",
      "Change in Train_loss: 3.798885941505432\n",
      "Batch_idx 309\n",
      "batch_going: 309\n",
      "Change in Train_loss: -2.8324323892593384\n",
      "Batch_idx 310\n",
      "batch_going: 310\n",
      "Change in Train_loss: -21.402218341827393\n",
      "Batch_idx 311\n",
      "batch_going: 311\n",
      "Change in Train_loss: 21.921274662017822\n",
      "Batch_idx 312\n",
      "batch_going: 312\n",
      "Change in Train_loss: 1.0570001602172852\n",
      "Batch_idx 313\n",
      "batch_going: 313\n",
      "Change in Train_loss: 2.0453107357025146\n",
      "Batch_idx 314\n",
      "batch_going: 314\n",
      "Change in Train_loss: -0.785362720489502\n",
      "Batch_idx 315\n",
      "batch_going: 315\n",
      "Change in Train_loss: 2.6408934593200684\n",
      "Batch_idx 316\n",
      "batch_going: 316\n",
      "Change in Train_loss: -4.449329376220703\n",
      "Batch_idx 317\n",
      "batch_going: 317\n",
      "Change in Train_loss: -0.5601584911346436\n",
      "Batch_idx 318\n",
      "batch_going: 318\n",
      "Change in Train_loss: 1.6495347023010254\n",
      "Batch_idx 319\n",
      "batch_going: 319\n",
      "Change in Train_loss: 1.8892651796340942\n",
      "Batch_idx 320\n",
      "batch_going: 320\n",
      "Change in Train_loss: -7.192613482475281\n",
      "Batch_idx 321\n",
      "batch_going: 321\n",
      "Change in Train_loss: 1.2008273601531982\n",
      "Batch_idx 322\n",
      "batch_going: 322\n",
      "Change in Train_loss: 11.723717749118805\n",
      "Batch_idx 323\n",
      "batch_going: 323\n",
      "Change in Train_loss: -6.314076483249664\n",
      "Batch_idx 324\n",
      "batch_going: 324\n",
      "Change in Train_loss: -6.11750602722168\n",
      "Batch_idx 325\n",
      "batch_going: 325\n",
      "Change in Train_loss: 2.37734317779541\n",
      "Batch_idx 326\n",
      "batch_going: 326\n",
      "Change in Train_loss: -8.611116409301758\n",
      "Batch_idx 327\n",
      "batch_going: 327\n",
      "Change in Train_loss: 8.674403429031372\n",
      "Batch_idx 328\n",
      "batch_going: 328\n",
      "Change in Train_loss: 0.959240198135376\n",
      "Batch_idx 329\n",
      "batch_going: 329\n",
      "Change in Train_loss: -2.2248005867004395\n",
      "Batch_idx 330\n",
      "batch_going: 330\n",
      "Change in Train_loss: 3.092825412750244\n",
      "Batch_idx 331\n",
      "batch_going: 331\n",
      "Change in Train_loss: 0.3235292434692383\n",
      "Batch_idx 332\n",
      "batch_going: 332\n",
      "Change in Train_loss: -0.46088337898254395\n",
      "Batch_idx 333\n",
      "batch_going: 333\n",
      "Change in Train_loss: -11.721609830856323\n",
      "Batch_idx 334\n",
      "batch_going: 334\n",
      "Change in Train_loss: 5.869340896606445\n",
      "Batch_idx 335\n",
      "batch_going: 335\n",
      "Change in Train_loss: 3.979315757751465\n",
      "Batch_idx 336\n",
      "batch_going: 336\n",
      "Change in Train_loss: 5.511878728866577\n",
      "Batch_idx 337\n",
      "batch_going: 337\n",
      "Change in Train_loss: -4.007951021194458\n",
      "Batch_idx 338\n",
      "batch_going: 338\n",
      "Change in Train_loss: 0.846027135848999\n",
      "Batch_idx 339\n",
      "batch_going: 339\n",
      "Change in Train_loss: -7.579176425933838\n",
      "Batch_idx 340\n",
      "batch_going: 340\n",
      "Change in Train_loss: 5.581175088882446\n",
      "Batch_idx 341\n",
      "batch_going: 341\n",
      "Change in Train_loss: 4.158318042755127\n",
      "Batch_idx 342\n",
      "batch_going: 342\n",
      "Change in Train_loss: -4.172931909561157\n",
      "Batch_idx 343\n",
      "batch_going: 343\n",
      "Change in Train_loss: -11.687613725662231\n",
      "Batch_idx 344\n",
      "batch_going: 344\n",
      "Change in Train_loss: 17.17789649963379\n",
      "Batch_idx 345\n",
      "batch_going: 345\n",
      "Change in Train_loss: -7.212333679199219\n",
      "Batch_idx 346\n",
      "batch_going: 346\n",
      "Change in Train_loss: 0.8946478366851807\n",
      "Batch_idx 347\n",
      "batch_going: 347\n",
      "Change in Train_loss: -6.594916582107544\n",
      "Batch_idx 348\n",
      "batch_going: 348\n",
      "Change in Train_loss: 1.9122576713562012\n",
      "Batch_idx 349\n",
      "batch_going: 349\n",
      "Change in Train_loss: 4.686161279678345\n",
      "Batch_idx 350\n",
      "batch_going: 350\n",
      "Change in Train_loss: -10.726615190505981\n",
      "Batch_idx 351\n",
      "batch_going: 351\n",
      "Change in Train_loss: 5.130664110183716\n",
      "Batch_idx 352\n",
      "batch_going: 352\n",
      "Change in Train_loss: 4.765068292617798\n",
      "Batch_idx 353\n",
      "batch_going: 353\n",
      "Change in Train_loss: -5.371992588043213\n",
      "Batch_idx 354\n",
      "batch_going: 354\n",
      "Change in Train_loss: -0.06879091262817383\n",
      "Batch_idx 355\n",
      "batch_going: 355\n",
      "Change in Train_loss: 5.087548494338989\n",
      "Batch_idx 356\n",
      "batch_going: 356\n",
      "Change in Train_loss: 0.25118589401245117\n",
      "Batch_idx 357\n",
      "batch_going: 357\n",
      "Change in Train_loss: -10.046030282974243\n",
      "Batch_idx 358\n",
      "batch_going: 358\n",
      "Change in Train_loss: 1.8616628646850586\n",
      "Batch_idx 359\n",
      "batch_going: 359\n",
      "Change in Train_loss: 15.50364077091217\n",
      "Batch_idx 360\n",
      "batch_going: 360\n",
      "Change in Train_loss: -3.662394881248474\n",
      "Batch_idx 361\n",
      "batch_going: 361\n",
      "Change in Train_loss: 0.21674633026123047\n",
      "Batch_idx 362\n",
      "batch_going: 362\n",
      "Change in Train_loss: -10.20966649055481\n",
      "Batch_idx 363\n",
      "batch_going: 363\n",
      "Change in Train_loss: 14.036722183227539\n",
      "Batch_idx 364\n",
      "batch_going: 364\n",
      "Change in Train_loss: -10.020661354064941\n",
      "Batch_idx 365\n",
      "batch_going: 365\n",
      "Change in Train_loss: -6.837959289550781\n",
      "Batch_idx 366\n",
      "batch_going: 366\n",
      "Change in Train_loss: 14.55767035484314\n",
      "Batch_idx 367\n",
      "batch_going: 367\n",
      "Change in Train_loss: -1.9076240062713623\n",
      "Batch_idx 368\n",
      "batch_going: 368\n",
      "Change in Train_loss: 4.2530739307403564\n",
      "Batch_idx 369\n",
      "batch_going: 369\n",
      "Change in Train_loss: -2.049541473388672\n",
      "Batch_idx 370\n",
      "batch_going: 370\n",
      "Change in Train_loss: 0.4513728618621826\n",
      "Batch_idx 371\n",
      "batch_going: 371\n",
      "Change in Train_loss: -8.441250324249268\n",
      "Batch_idx 372\n",
      "batch_going: 372\n",
      "Change in Train_loss: 6.883702874183655\n",
      "Batch_idx 373\n",
      "batch_going: 373\n",
      "Change in Train_loss: -0.3163158893585205\n",
      "Batch_idx 374\n",
      "batch_going: 374\n",
      "Change in Train_loss: 1.9306784868240356\n",
      "Batch_idx 375\n",
      "batch_going: 375\n",
      "Change in Train_loss: 0.9693789482116699\n",
      "Batch_idx 376\n",
      "batch_going: 376\n",
      "Change in Train_loss: -12.93393850326538\n",
      "Batch_idx 377\n",
      "batch_going: 377\n",
      "Change in Train_loss: 10.920993685722351\n",
      "Batch_idx 378\n",
      "batch_going: 378\n",
      "Change in Train_loss: -9.207332730293274\n",
      "Batch_idx 379\n",
      "batch_going: 379\n",
      "Change in Train_loss: -6.3575661182403564\n",
      "Batch_idx 380\n",
      "batch_going: 380\n",
      "Change in Train_loss: 19.15941834449768\n",
      "Batch_idx 381\n",
      "batch_going: 381\n",
      "Change in Train_loss: -5.505322217941284\n",
      "Batch_idx 382\n",
      "batch_going: 382\n",
      "Change in Train_loss: -8.990461826324463\n",
      "Batch_idx 383\n",
      "batch_going: 383\n",
      "Change in Train_loss: 13.309472799301147\n",
      "Batch_idx 384\n",
      "batch_going: 384\n",
      "Change in Train_loss: -9.589545726776123\n",
      "Batch_idx 385\n",
      "batch_going: 385\n",
      "Change in Train_loss: -3.5500919818878174\n",
      "Batch_idx 386\n",
      "batch_going: 386\n",
      "Change in Train_loss: 9.466066360473633\n",
      "Batch_idx 387\n",
      "batch_going: 387\n",
      "Change in Train_loss: -11.968951225280762\n",
      "Batch_idx 388\n",
      "batch_going: 388\n",
      "Change in Train_loss: 4.204498529434204\n",
      "Batch_idx 389\n",
      "batch_going: 389\n",
      "Change in Train_loss: 6.602613925933838\n",
      "Batch_idx 390\n",
      "batch_going: 390\n",
      "Change in Train_loss: -8.61302375793457\n",
      "Batch_idx 391\n",
      "batch_going: 391\n",
      "Change in Train_loss: 13.576049208641052\n",
      "Batch_idx 392\n",
      "batch_going: 392\n",
      "Change in Train_loss: -1.4578145742416382\n",
      "Batch_idx 393\n",
      "batch_going: 393\n",
      "Change in Train_loss: 0.3565305471420288\n",
      "Batch_idx 394\n",
      "batch_going: 394\n",
      "Change in Train_loss: 2.76462584733963\n",
      "Batch_idx 395\n",
      "batch_going: 395\n",
      "Change in Train_loss: -15.771225392818451\n",
      "Batch_idx 396\n",
      "batch_going: 396\n",
      "Change in Train_loss: 7.544189691543579\n",
      "Batch_idx 397\n",
      "batch_going: 397\n",
      "Change in Train_loss: -1.8259990215301514\n",
      "Batch_idx 398\n",
      "batch_going: 398\n",
      "Change in Train_loss: 0.22271990776062012\n",
      "Batch_idx 399\n",
      "batch_going: 399\n",
      "Change in Train_loss: 0.9976518154144287\n",
      "Batch_idx 400\n",
      "batch_going: 400\n",
      "Change in Train_loss: 0.7118165493011475\n",
      "Batch_idx 401\n",
      "batch_going: 401\n",
      "Change in Train_loss: 0.6331539154052734\n",
      "Batch_idx 402\n",
      "batch_going: 402\n",
      "Change in Train_loss: 2.9024523496627808\n",
      "Batch_idx 403\n",
      "batch_going: 403\n",
      "Change in Train_loss: -7.258093953132629\n",
      "Batch_idx 404\n",
      "batch_going: 404\n",
      "Change in Train_loss: 2.272430658340454\n",
      "Batch_idx 405\n",
      "batch_going: 405\n",
      "Change in Train_loss: 2.5709521770477295\n",
      "Batch_idx 406\n",
      "batch_going: 406\n",
      "Change in Train_loss: -11.01426362991333\n",
      "Batch_idx 407\n",
      "batch_going: 407\n",
      "Change in Train_loss: 7.694967985153198\n",
      "Batch_idx 408\n",
      "batch_going: 408\n",
      "Change in Train_loss: -2.628859281539917\n",
      "Batch_idx 409\n",
      "batch_going: 409\n",
      "Change in Train_loss: 8.979262709617615\n",
      "Batch_idx 410\n",
      "batch_going: 410\n",
      "Change in Train_loss: -9.500089287757874\n",
      "Batch_idx 411\n",
      "batch_going: 411\n",
      "Change in Train_loss: 9.421001076698303\n",
      "Batch_idx 412\n",
      "batch_going: 412\n",
      "Change in Train_loss: -6.8830567598342896\n",
      "Batch_idx 413\n",
      "batch_going: 413\n",
      "Change in Train_loss: 1.203075647354126\n",
      "Batch_idx 414\n",
      "batch_going: 414\n",
      "Change in Train_loss: 5.7994043827056885\n",
      "Batch_idx 415\n",
      "batch_going: 415\n",
      "Change in Train_loss: 0.6000256538391113\n",
      "Batch_idx 416\n",
      "batch_going: 416\n",
      "Change in Train_loss: -3.0633699893951416\n",
      "Batch_idx 417\n",
      "batch_going: 417\n",
      "Change in Train_loss: -2.2093093395233154\n",
      "Batch_idx 418\n",
      "batch_going: 418\n",
      "Change in Train_loss: -4.82791543006897\n",
      "Batch_idx 419\n",
      "batch_going: 419\n",
      "Change in Train_loss: 9.58459734916687\n",
      "Batch_idx 420\n",
      "batch_going: 420\n",
      "Change in Train_loss: -5.405460596084595\n",
      "Batch_idx 421\n",
      "batch_going: 421\n",
      "Change in Train_loss: 0.6849026679992676\n",
      "Batch_idx 422\n",
      "batch_going: 422\n",
      "Change in Train_loss: 7.6010048389434814\n",
      "Batch_idx 423\n",
      "batch_going: 423\n",
      "Change in Train_loss: -15.544317960739136\n",
      "Batch_idx 424\n",
      "batch_going: 424\n",
      "Change in Train_loss: 2.7252089977264404\n",
      "Batch_idx 425\n",
      "batch_going: 425\n",
      "Change in Train_loss: 10.442440509796143\n",
      "Batch_idx 426\n",
      "batch_going: 426\n",
      "Change in Train_loss: 2.90804922580719\n",
      "Batch_idx 427\n",
      "batch_going: 427\n",
      "Change in Train_loss: -6.538029313087463\n",
      "Batch_idx 428\n",
      "batch_going: 428\n",
      "Change in Train_loss: 0.06801962852478027\n",
      "Batch_idx 429\n",
      "batch_going: 429\n",
      "Change in Train_loss: 4.38953697681427\n",
      "Batch_idx 430\n",
      "batch_going: 430\n",
      "Change in Train_loss: -7.364020943641663\n",
      "Batch_idx 431\n",
      "batch_going: 431\n",
      "Change in Train_loss: 3.1485486030578613\n",
      "Batch_idx 432\n",
      "batch_going: 432\n",
      "Change in Train_loss: -3.617379665374756\n",
      "Batch_idx 433\n",
      "batch_going: 433\n",
      "Change in Train_loss: 8.933197855949402\n",
      "Batch_idx 434\n",
      "batch_going: 434\n",
      "Change in Train_loss: -7.9968708753585815\n",
      "Batch_idx 435\n",
      "batch_going: 435\n",
      "Change in Train_loss: -1.2872350215911865\n",
      "Batch_idx 436\n",
      "batch_going: 436\n",
      "Change in Train_loss: 0.4969191551208496\n",
      "Batch_idx 437\n",
      "batch_going: 437\n",
      "Change in Train_loss: 1.4320433139801025\n",
      "Batch_idx 438\n",
      "batch_going: 438\n",
      "Change in Train_loss: 8.159481287002563\n",
      "Batch_idx 439\n",
      "batch_going: 439\n",
      "Change in Train_loss: -0.03731667995452881\n",
      "Batch_idx 440\n",
      "batch_going: 440\n",
      "Change in Train_loss: -13.54279100894928\n",
      "Batch_idx 441\n",
      "batch_going: 441\n",
      "Change in Train_loss: 6.535881757736206\n",
      "Batch_idx 442\n",
      "batch_going: 442\n",
      "Change in Train_loss: 2.236008644104004\n",
      "Batch_idx 443\n",
      "batch_going: 443\n",
      "Change in Train_loss: 2.3737967014312744\n",
      "Batch_idx 444\n",
      "batch_going: 444\n",
      "Change in Train_loss: -0.8594292402267456\n",
      "Batch_idx 445\n",
      "batch_going: 445\n",
      "Change in Train_loss: -3.1091028451919556\n",
      "Batch_idx 446\n",
      "batch_going: 446\n",
      "Change in Train_loss: -13.148995637893677\n",
      "Batch_idx 447\n",
      "batch_going: 447\n",
      "Change in Train_loss: 13.925036191940308\n",
      "Batch_idx 448\n",
      "batch_going: 448\n",
      "Change in Train_loss: -1.0597419738769531\n",
      "Batch_idx 449\n",
      "batch_going: 449\n",
      "Change in Train_loss: -0.3446066379547119\n",
      "Batch_idx 450\n",
      "batch_going: 450\n",
      "Change in Train_loss: 4.049345254898071\n",
      "Batch_idx 451\n",
      "batch_going: 451\n",
      "Change in Train_loss: -9.01720643043518\n",
      "Batch_idx 452\n",
      "batch_going: 452\n",
      "Change in Train_loss: 10.214287638664246\n",
      "Batch_idx 453\n",
      "batch_going: 453\n",
      "Change in Train_loss: -6.058983206748962\n",
      "Batch_idx 454\n",
      "batch_going: 454\n",
      "Change in Train_loss: 11.282826364040375\n",
      "Batch_idx 455\n",
      "batch_going: 455\n",
      "Change in Train_loss: -4.690413177013397\n",
      "Batch_idx 456\n",
      "batch_going: 456\n",
      "Change in Train_loss: -8.589271306991577\n",
      "Batch_idx 457\n",
      "batch_going: 457\n",
      "Change in Train_loss: 6.514871120452881\n",
      "Batch_idx 458\n",
      "batch_going: 458\n",
      "Change in Train_loss: -5.608558654785156\n",
      "Batch_idx 459\n",
      "batch_going: 459\n",
      "Change in Train_loss: 7.568775415420532\n",
      "Batch_idx 460\n",
      "batch_going: 460\n",
      "Change in Train_loss: -21.699079275131226\n",
      "Batch_idx 461\n",
      "batch_going: 461\n",
      "Change in Train_loss: 11.351404190063477\n",
      "Batch_idx 462\n",
      "batch_going: 462\n",
      "Change in Train_loss: 2.6830363273620605\n",
      "Batch_idx 463\n",
      "batch_going: 463\n",
      "Change in Train_loss: 6.652261018753052\n",
      "Batch_idx 464\n",
      "batch_going: 464\n",
      "Change in Train_loss: -3.6578428745269775\n",
      "Batch_idx 465\n",
      "batch_going: 465\n",
      "Change in Train_loss: 0.4077637195587158\n",
      "Batch_idx 466\n",
      "batch_going: 466\n",
      "Change in Train_loss: -6.035730838775635\n",
      "Batch_idx 467\n",
      "batch_going: 467\n",
      "Change in Train_loss: 10.310603976249695\n",
      "Batch_idx 468\n",
      "batch_going: 468\n",
      "Change in Train_loss: -5.4111868143081665\n",
      "Batch_idx 469\n",
      "batch_going: 469\n",
      "Change in Train_loss: 2.9407691955566406\n",
      "Batch_idx 470\n",
      "batch_going: 470\n",
      "Change in Train_loss: -9.82475996017456\n",
      "Batch_idx 471\n",
      "batch_going: 471\n",
      "Change in Train_loss: 7.421709299087524\n",
      "Batch_idx 472\n",
      "batch_going: 472\n",
      "Change in Train_loss: 1.2834680080413818\n",
      "Batch_idx 473\n",
      "batch_going: 473\n",
      "Change in Train_loss: -5.9183502197265625\n",
      "Batch_idx 474\n",
      "batch_going: 474\n",
      "Change in Train_loss: 2.1090424060821533\n",
      "Batch_idx 475\n",
      "batch_going: 475\n",
      "Change in Train_loss: 0.9318351745605469\n",
      "Batch_idx 476\n",
      "batch_going: 476\n",
      "Change in Train_loss: -1.8622303009033203\n",
      "Batch_idx 477\n",
      "batch_going: 477\n",
      "Change in Train_loss: 2.149580717086792\n",
      "Batch_idx 478\n",
      "batch_going: 478\n",
      "Change in Train_loss: 2.154421806335449\n",
      "Batch_idx 479\n",
      "batch_going: 479\n",
      "Change in Train_loss: -10.675837993621826\n",
      "Batch_idx 480\n",
      "batch_going: 480\n",
      "Change in Train_loss: 15.295758247375488\n",
      "Batch_idx 481\n",
      "batch_going: 481\n",
      "Change in Train_loss: -10.25452971458435\n",
      "Batch_idx 482\n",
      "batch_going: 482\n",
      "Change in Train_loss: 0.3135859966278076\n",
      "Batch_idx 483\n",
      "batch_going: 483\n",
      "Change in Train_loss: 6.997009515762329\n",
      "Batch_idx 484\n",
      "batch_going: 484\n",
      "Change in Train_loss: 1.4497220516204834\n",
      "Batch_idx 485\n",
      "batch_going: 485\n",
      "Change in Train_loss: -13.520894050598145\n",
      "Batch_idx 486\n",
      "batch_going: 486\n",
      "Change in Train_loss: 4.883458614349365\n",
      "Batch_idx 487\n",
      "batch_going: 487\n",
      "Change in Train_loss: 1.8267035484313965\n",
      "Batch_idx 488\n",
      "batch_going: 488\n",
      "Change in Train_loss: -0.8784890174865723\n",
      "Batch_idx 489\n",
      "batch_going: 489\n",
      "Change in Train_loss: 4.245401620864868\n",
      "Batch_idx 490\n",
      "batch_going: 490\n",
      "Change in Train_loss: -5.071309804916382\n",
      "Batch_idx 491\n",
      "batch_going: 491\n",
      "Change in Train_loss: 2.099597454071045\n",
      "Batch_idx 492\n",
      "batch_going: 492\n",
      "Change in Train_loss: 2.400798797607422\n",
      "Batch_idx 493\n",
      "batch_going: 493\n",
      "Change in Train_loss: -1.8656766414642334\n",
      "Batch_idx 494\n",
      "batch_going: 494\n",
      "Change in Train_loss: 4.712531566619873\n",
      "Batch_idx 495\n",
      "batch_going: 495\n",
      "Change in Train_loss: -20.570112466812134\n",
      "Batch_idx 496\n",
      "batch_going: 496\n",
      "Change in Train_loss: 14.785013198852539\n",
      "Batch_idx 497\n",
      "batch_going: 497\n",
      "Change in Train_loss: 3.060002326965332\n",
      "Batch_idx 498\n",
      "batch_going: 498\n",
      "Change in Train_loss: -2.2281384468078613\n",
      "Batch_idx 499\n",
      "batch_going: 499\n",
      "Change in Train_loss: 2.5430715084075928\n",
      "Batch_idx 500\n",
      "batch_going: 500\n",
      "Change in Train_loss: -8.202179670333862\n",
      "Batch_idx 501\n",
      "batch_going: 501\n",
      "Change in Train_loss: 0.49106597900390625\n",
      "Batch_idx 502\n",
      "batch_going: 502\n",
      "Change in Train_loss: -4.634590148925781\n",
      "Batch_idx 503\n",
      "batch_going: 503\n",
      "Change in Train_loss: 10.264191627502441\n",
      "Batch_idx 504\n",
      "batch_going: 504\n",
      "Change in Train_loss: 7.4108850955963135\n",
      "Batch_idx 505\n",
      "batch_going: 505\n",
      "Change in Train_loss: -5.1073503494262695\n",
      "Batch_idx 506\n",
      "batch_going: 506\n",
      "Change in Train_loss: -6.511482000350952\n",
      "Batch_idx 507\n",
      "batch_going: 507\n",
      "Change in Train_loss: -1.7612040042877197\n",
      "Batch_idx 508\n",
      "batch_going: 508\n",
      "Change in Train_loss: 1.630871295928955\n",
      "Batch_idx 509\n",
      "batch_going: 509\n",
      "Change in Train_loss: 8.604598641395569\n",
      "Batch_idx 510\n",
      "batch_going: 510\n",
      "Change in Train_loss: -3.4319645166397095\n",
      "Batch_idx 511\n",
      "batch_going: 511\n",
      "Change in Train_loss: 1.5731394290924072\n",
      "Batch_idx 512\n",
      "batch_going: 512\n",
      "Change in Train_loss: -3.6596298217773438\n",
      "Batch_idx 513\n",
      "batch_going: 513\n",
      "Change in Train_loss: -1.6585206985473633\n",
      "Batch_idx 514\n",
      "batch_going: 514\n",
      "Change in Train_loss: 3.0997610092163086\n",
      "Batch_idx 515\n",
      "batch_going: 515\n",
      "Change in Train_loss: 4.575719237327576\n",
      "Batch_idx 516\n",
      "batch_going: 516\n",
      "Change in Train_loss: -9.319667220115662\n",
      "Batch_idx 517\n",
      "batch_going: 517\n",
      "Change in Train_loss: 6.994788646697998\n",
      "Batch_idx 518\n",
      "batch_going: 518\n",
      "Change in Train_loss: 1.2159764766693115\n",
      "Batch_idx 519\n",
      "batch_going: 519\n",
      "Change in Train_loss: -5.386725664138794\n",
      "Batch_idx 520\n",
      "batch_going: 520\n",
      "Change in Train_loss: 5.033071041107178\n",
      "Batch_idx 521\n",
      "batch_going: 521\n",
      "Change in Train_loss: -2.137267589569092\n",
      "Batch_idx 522\n",
      "batch_going: 522\n",
      "Change in Train_loss: 4.130399823188782\n",
      "Batch_idx 523\n",
      "batch_going: 523\n",
      "Change in Train_loss: -8.930824398994446\n",
      "Batch_idx 524\n",
      "batch_going: 524\n",
      "Change in Train_loss: 11.386058330535889\n",
      "Batch_idx 525\n",
      "batch_going: 525\n",
      "Change in Train_loss: -15.68443775177002\n",
      "Batch_idx 526\n",
      "batch_going: 526\n",
      "Change in Train_loss: 6.475902795791626\n",
      "Batch_idx 527\n",
      "batch_going: 527\n",
      "Change in Train_loss: -2.537611722946167\n",
      "Batch_idx 528\n",
      "batch_going: 528\n",
      "Change in Train_loss: 5.548214912414551\n",
      "Batch_idx 529\n",
      "batch_going: 529\n",
      "Change in Train_loss: 3.65106463432312\n",
      "Batch_idx 530\n",
      "batch_going: 530\n",
      "Change in Train_loss: -6.018580198287964\n",
      "Batch_idx 531\n",
      "batch_going: 531\n",
      "Change in Train_loss: 4.8632752895355225\n",
      "Batch_idx 532\n",
      "batch_going: 532\n",
      "Change in Train_loss: 3.187234401702881\n",
      "Batch_idx 533\n",
      "batch_going: 533\n",
      "Change in Train_loss: -20.391660928726196\n",
      "Batch_idx 534\n",
      "batch_going: 534\n",
      "Change in Train_loss: 12.240074872970581\n",
      "Batch_idx 535\n",
      "batch_going: 535\n",
      "Change in Train_loss: 0.4152214527130127\n",
      "Batch_idx 536\n",
      "batch_going: 536\n",
      "Change in Train_loss: -3.2370376586914062\n",
      "Batch_idx 537\n",
      "batch_going: 537\n",
      "Change in Train_loss: -2.741680145263672\n",
      "Batch_idx 538\n",
      "batch_going: 538\n",
      "Change in Train_loss: -3.238041400909424\n",
      "Batch_idx 539\n",
      "batch_going: 539\n",
      "Change in Train_loss: 16.92738711833954\n",
      "Batch_idx 540\n",
      "batch_going: 540\n",
      "Change in Train_loss: -8.383232951164246\n",
      "Batch_idx 541\n",
      "batch_going: 541\n",
      "Change in Train_loss: -7.23099946975708\n",
      "Batch_idx 542\n",
      "batch_going: 542\n",
      "Change in Train_loss: 16.09298586845398\n",
      "Batch_idx 543\n",
      "batch_going: 543\n",
      "Change in Train_loss: -3.5191720724105835\n",
      "Batch_idx 544\n",
      "batch_going: 544\n",
      "Change in Train_loss: -5.226464867591858\n",
      "Batch_idx 545\n",
      "batch_going: 545\n",
      "Change in Train_loss: 4.193696975708008\n",
      "Batch_idx 546\n",
      "batch_going: 546\n",
      "Change in Train_loss: 4.2062705755233765\n",
      "Batch_idx 547\n",
      "batch_going: 547\n",
      "Change in Train_loss: -5.634064078330994\n",
      "Batch_idx 548\n",
      "batch_going: 548\n",
      "Change in Train_loss: -6.75392746925354\n",
      "Batch_idx 549\n",
      "batch_going: 549\n",
      "Change in Train_loss: 3.2377147674560547\n",
      "Batch_idx 550\n",
      "batch_going: 550\n",
      "Change in Train_loss: 1.7153429985046387\n",
      "Batch_idx 551\n",
      "batch_going: 551\n",
      "Change in Train_loss: 0.4496908187866211\n",
      "Batch_idx 552\n",
      "batch_going: 552\n",
      "Change in Train_loss: -4.579334259033203\n",
      "Batch_idx 553\n",
      "batch_going: 553\n",
      "Change in Train_loss: 11.344903111457825\n",
      "Batch_idx 554\n",
      "batch_going: 554\n",
      "Change in Train_loss: -25.67991316318512\n",
      "Batch_idx 555\n",
      "batch_going: 555\n",
      "Change in Train_loss: 29.09029394388199\n",
      "Batch_idx 556\n",
      "batch_going: 556\n",
      "Change in Train_loss: -8.161393702030182\n",
      "Batch_idx 557\n",
      "batch_going: 557\n",
      "Change in Train_loss: -9.04921293258667\n",
      "Batch_idx 558\n",
      "batch_going: 558\n",
      "Change in Train_loss: -2.537863254547119\n",
      "Batch_idx 559\n",
      "batch_going: 559\n",
      "Change in Train_loss: -7.984483242034912\n",
      "Batch_idx 560\n",
      "batch_going: 560\n",
      "Change in Train_loss: 15.255277156829834\n",
      "Batch_idx 561\n",
      "batch_going: 561\n",
      "Change in Train_loss: -4.3309783935546875\n",
      "Batch_idx 562\n",
      "batch_going: 562\n",
      "Change in Train_loss: 9.155470132827759\n",
      "Batch_idx 563\n",
      "batch_going: 563\n",
      "Change in Train_loss: -7.7828288078308105\n",
      "Batch_idx 564\n",
      "batch_going: 564\n",
      "Change in Train_loss: 3.6108124256134033\n",
      "Batch_idx 565\n",
      "batch_going: 565\n",
      "Change in Train_loss: 5.158652663230896\n",
      "Batch_idx 566\n",
      "batch_going: 566\n",
      "Change in Train_loss: -13.840314745903015\n",
      "Batch_idx 567\n",
      "batch_going: 567\n",
      "Change in Train_loss: 15.140065550804138\n",
      "Batch_idx 568\n",
      "batch_going: 568\n",
      "Change in Train_loss: -4.637290835380554\n",
      "Batch_idx 569\n",
      "batch_going: 569\n",
      "Change in Train_loss: -5.8341169357299805\n",
      "Batch_idx 570\n",
      "batch_going: 570\n",
      "Change in Train_loss: 4.044780731201172\n",
      "Batch_idx 571\n",
      "batch_going: 571\n",
      "Change in Train_loss: -1.355358362197876\n",
      "Batch_idx 572\n",
      "batch_going: 572\n",
      "Change in Train_loss: 5.1100969314575195\n",
      "Batch_idx 573\n",
      "batch_going: 573\n",
      "Change in Train_loss: -0.3865838050842285\n",
      "Batch_idx 574\n",
      "batch_going: 574\n",
      "Change in Train_loss: -1.1381876468658447\n",
      "Batch_idx 575\n",
      "batch_going: 575\n",
      "Change in Train_loss: 3.499012589454651\n",
      "Batch_idx 576\n",
      "batch_going: 576\n",
      "Change in Train_loss: -13.653960824012756\n",
      "Batch_idx 577\n",
      "batch_going: 577\n",
      "Change in Train_loss: 13.033185601234436\n",
      "Batch_idx 578\n",
      "batch_going: 578\n",
      "Change in Train_loss: -1.1459535360336304\n",
      "Batch_idx 579\n",
      "batch_going: 579\n",
      "Change in Train_loss: -5.615723133087158\n",
      "Batch_idx 580\n",
      "batch_going: 580\n",
      "Change in Train_loss: 0.621711015701294\n",
      "Batch_idx 581\n",
      "batch_going: 581\n",
      "Change in Train_loss: 0.7442748546600342\n",
      "Batch_idx 582\n",
      "batch_going: 582\n",
      "Change in Train_loss: -13.978618383407593\n",
      "Batch_idx 583\n",
      "batch_going: 583\n",
      "Change in Train_loss: 15.765323638916016\n",
      "Batch_idx 584\n",
      "batch_going: 584\n",
      "Change in Train_loss: -1.2915706634521484\n",
      "Batch_idx 585\n",
      "batch_going: 585\n",
      "Change in Train_loss: -0.7469081878662109\n",
      "Batch_idx 586\n",
      "batch_going: 586\n",
      "Change in Train_loss: 0.7745671272277832\n",
      "Batch_idx 587\n",
      "batch_going: 587\n",
      "Change in Train_loss: 0.5969202518463135\n",
      "Batch_idx 588\n",
      "batch_going: 588\n",
      "Change in Train_loss: -9.431458711624146\n",
      "Batch_idx 589\n",
      "batch_going: 589\n",
      "Change in Train_loss: 1.304609775543213\n",
      "Batch_idx 590\n",
      "batch_going: 590\n",
      "Change in Train_loss: 4.26013708114624\n",
      "Batch_idx 591\n",
      "batch_going: 591\n",
      "Change in Train_loss: 0.7241940498352051\n",
      "Batch_idx 592\n",
      "batch_going: 592\n",
      "Change in Train_loss: 0.8979713916778564\n",
      "Batch_idx 593\n",
      "batch_going: 593\n",
      "Change in Train_loss: 5.340803861618042\n",
      "Batch_idx 594\n",
      "batch_going: 594\n",
      "Change in Train_loss: -0.16127467155456543\n",
      "Batch_idx 595\n",
      "batch_going: 595\n",
      "Change in Train_loss: -0.5053675174713135\n",
      "Batch_idx 596\n",
      "batch_going: 596\n",
      "Change in Train_loss: -8.439137935638428\n",
      "Batch_idx 597\n",
      "batch_going: 597\n",
      "Change in Train_loss: 3.7781357765197754\n",
      "Batch_idx 598\n",
      "batch_going: 598\n",
      "Change in Train_loss: 3.474583625793457\n",
      "Batch_idx 599\n",
      "batch_going: 599\n",
      "Change in Train_loss: -2.3442435264587402\n",
      "Batch_idx 600\n",
      "batch_going: 600\n",
      "Change in Train_loss: 2.6011812686920166\n",
      "Batch_idx 601\n",
      "batch_going: 601\n",
      "Change in Train_loss: 5.2072978019714355\n",
      "Batch_idx 602\n",
      "batch_going: 602\n",
      "Change in Train_loss: -3.587768077850342\n",
      "Batch_idx 603\n",
      "batch_going: 603\n",
      "Change in Train_loss: -6.49592399597168\n",
      "Batch_idx 604\n",
      "batch_going: 604\n",
      "Change in Train_loss: 7.180759906768799\n",
      "Batch_idx 605\n",
      "batch_going: 605\n",
      "Change in Train_loss: -1.3770341873168945\n",
      "Batch_idx 606\n",
      "batch_going: 606\n",
      "Change in Train_loss: 6.253039240837097\n",
      "Batch_idx 607\n",
      "batch_going: 607\n",
      "Change in Train_loss: -11.130979657173157\n",
      "Batch_idx 608\n",
      "batch_going: 608\n",
      "Change in Train_loss: -3.1256532669067383\n",
      "Batch_idx 609\n",
      "batch_going: 609\n",
      "Change in Train_loss: 13.132169246673584\n",
      "Batch_idx 610\n",
      "batch_going: 610\n",
      "Change in Train_loss: -0.6555426120758057\n",
      "Batch_idx 611\n",
      "batch_going: 611\n",
      "Change in Train_loss: -6.1094653606414795\n",
      "Batch_idx 612\n",
      "batch_going: 612\n",
      "Change in Train_loss: 1.4901137351989746\n",
      "Batch_idx 613\n",
      "batch_going: 613\n",
      "Change in Train_loss: 0.26546359062194824\n",
      "Batch_idx 614\n",
      "batch_going: 614\n",
      "Change in Train_loss: -11.923149824142456\n",
      "Batch_idx 615\n",
      "batch_going: 615\n",
      "Change in Train_loss: 1.4719653129577637\n",
      "Batch_idx 616\n",
      "batch_going: 616\n",
      "Change in Train_loss: 14.681183099746704\n",
      "Batch_idx 617\n",
      "batch_going: 617\n",
      "Change in Train_loss: -1.4671337604522705\n",
      "Batch_idx 618\n",
      "batch_going: 618\n",
      "Change in Train_loss: 2.0079219341278076\n",
      "Batch_idx 619\n",
      "batch_going: 619\n",
      "Change in Train_loss: -0.37253379821777344\n",
      "Batch_idx 620\n",
      "batch_going: 620\n",
      "Change in Train_loss: -4.04265284538269\n",
      "Batch_idx 621\n",
      "batch_going: 621\n",
      "Change in Train_loss: 4.058548808097839\n",
      "Batch_idx 622\n",
      "batch_going: 622\n",
      "Change in Train_loss: -4.765095114707947\n",
      "Batch_idx 623\n",
      "batch_going: 623\n",
      "Change in Train_loss: 3.265942931175232\n",
      "Batch_idx 624\n",
      "batch_going: 624\n",
      "Change in Train_loss: -7.341603636741638\n",
      "Batch_idx 625\n",
      "batch_going: 625\n",
      "Change in Train_loss: 4.314790964126587\n",
      "Batch_idx 626\n",
      "batch_going: 626\n",
      "Change in Train_loss: 0.990830659866333\n",
      "Batch_idx 627\n",
      "batch_going: 627\n",
      "Change in Train_loss: -3.204805850982666\n",
      "Batch_idx 628\n",
      "batch_going: 628\n",
      "Change in Train_loss: -5.3251564502716064\n",
      "Batch_idx 629\n",
      "batch_going: 629\n",
      "Change in Train_loss: 7.168375253677368\n",
      "Batch_idx 630\n",
      "batch_going: 630\n",
      "Change in Train_loss: -12.131731510162354\n",
      "Batch_idx 631\n",
      "batch_going: 631\n",
      "Change in Train_loss: 12.372902631759644\n",
      "Batch_idx 632\n",
      "batch_going: 632\n",
      "Change in Train_loss: 5.613749623298645\n",
      "Batch_idx 633\n",
      "batch_going: 633\n",
      "Change in Train_loss: -7.923302054405212\n",
      "Batch_idx 634\n",
      "batch_going: 634\n",
      "Change in Train_loss: 0.7546663284301758\n",
      "Batch_idx 635\n",
      "batch_going: 635\n",
      "Change in Train_loss: -5.550771951675415\n",
      "Batch_idx 636\n",
      "batch_going: 636\n",
      "Change in Train_loss: 5.835486650466919\n",
      "Batch_idx 637\n",
      "batch_going: 637\n",
      "Change in Train_loss: -9.315247535705566\n",
      "Batch_idx 638\n",
      "batch_going: 638\n",
      "Change in Train_loss: 2.0319414138793945\n",
      "Batch_idx 639\n",
      "batch_going: 639\n",
      "Change in Train_loss: 8.912882804870605\n",
      "Batch_idx 640\n",
      "batch_going: 640\n",
      "Change in Train_loss: 0.7117080688476562\n",
      "Batch_idx 641\n",
      "batch_going: 641\n",
      "Change in Train_loss: -0.4271984100341797\n",
      "Batch_idx 642\n",
      "batch_going: 642\n",
      "Change in Train_loss: 8.134461343288422\n",
      "Batch_idx 643\n",
      "batch_going: 643\n",
      "Change in Train_loss: -19.689076840877533\n",
      "Batch_idx 644\n",
      "batch_going: 644\n",
      "Change in Train_loss: 7.878803014755249\n",
      "Batch_idx 645\n",
      "batch_going: 645\n",
      "Change in Train_loss: -5.268014669418335\n",
      "Batch_idx 646\n",
      "batch_going: 646\n",
      "Change in Train_loss: 8.187212944030762\n",
      "Batch_idx 647\n",
      "batch_going: 647\n",
      "Change in Train_loss: 2.5153911113739014\n",
      "Batch_idx 648\n",
      "batch_going: 648\n",
      "Change in Train_loss: -8.086614608764648\n",
      "Batch_idx 649\n",
      "batch_going: 649\n",
      "Change in Train_loss: 0.4355466365814209\n",
      "Batch_idx 650\n",
      "batch_going: 650\n",
      "Change in Train_loss: -2.434573173522949\n",
      "Batch_idx 651\n",
      "batch_going: 651\n",
      "Change in Train_loss: 6.324453353881836\n",
      "Batch_idx 652\n",
      "batch_going: 652\n",
      "Change in Train_loss: 4.301686882972717\n",
      "Batch_idx 653\n",
      "batch_going: 653\n",
      "Change in Train_loss: -5.2928489446640015\n",
      "Batch_idx 654\n",
      "batch_going: 654\n",
      "Change in Train_loss: 6.846080422401428\n",
      "Batch_idx 655\n",
      "batch_going: 655\n",
      "Change in Train_loss: 1.521221399307251\n",
      "Batch_idx 656\n",
      "batch_going: 656\n",
      "Change in Train_loss: -9.796839356422424\n",
      "Batch_idx 657\n",
      "batch_going: 657\n",
      "Change in Train_loss: 5.507339239120483\n",
      "Batch_idx 658\n",
      "batch_going: 658\n",
      "Change in Train_loss: 2.496301531791687\n",
      "Batch_idx 659\n",
      "batch_going: 659\n",
      "Change in Train_loss: -13.098235726356506\n",
      "Batch_idx 660\n",
      "batch_going: 660\n",
      "Change in Train_loss: -1.8471360206604004\n",
      "Batch_idx 661\n",
      "batch_going: 661\n",
      "Change in Train_loss: 2.5734305381774902\n",
      "Batch_idx 662\n",
      "batch_going: 662\n",
      "Change in Train_loss: 5.249502658843994\n",
      "Batch_idx 663\n",
      "batch_going: 663\n",
      "Change in Train_loss: -3.3659327030181885\n",
      "Batch_idx 664\n",
      "batch_going: 664\n",
      "Change in Train_loss: 0.3764665126800537\n",
      "Batch_idx 665\n",
      "batch_going: 665\n",
      "Change in Train_loss: -5.320076942443848\n",
      "Batch_idx 666\n",
      "batch_going: 666\n",
      "Change in Train_loss: 10.804890394210815\n",
      "Batch_idx 667\n",
      "batch_going: 667\n",
      "Change in Train_loss: 2.654564380645752\n",
      "train end, valid start\n",
      "batch_going: 0\n",
      "change in Valid loss: -40.036306381225586\n",
      "batch_going: 1\n",
      "change in Valid loss: -73.49236488342285\n",
      "batch_going: 2\n",
      "change in Valid loss: -54.31682586669922\n",
      "batch_going: 3\n",
      "change in Valid loss: -58.629608154296875\n",
      "batch_going: 4\n",
      "change in Valid loss: -59.17196750640869\n",
      "batch_going: 5\n",
      "change in Valid loss: -49.46807861328125\n",
      "batch_going: 6\n",
      "change in Valid loss: -48.935322761535645\n",
      "batch_going: 7\n",
      "change in Valid loss: -62.776689529418945\n",
      "batch_going: 8\n",
      "change in Valid loss: -54.5804500579834\n",
      "batch_going: 9\n",
      "change in Valid loss: -42.298269271850586\n",
      "batch_going: 10\n",
      "change in Valid loss: -49.78477954864502\n",
      "batch_going: 11\n",
      "change in Valid loss: -48.11915397644043\n",
      "batch_going: 12\n",
      "change in Valid loss: -56.735148429870605\n",
      "batch_going: 13\n",
      "change in Valid loss: -55.56939125061035\n",
      "batch_going: 14\n",
      "change in Valid loss: -57.95044422149658\n",
      "batch_going: 15\n",
      "change in Valid loss: -63.18281650543213\n",
      "batch_going: 16\n",
      "change in Valid loss: -65.1809310913086\n",
      "batch_going: 17\n",
      "change in Valid loss: -44.39596176147461\n",
      "batch_going: 18\n",
      "change in Valid loss: -43.97839069366455\n",
      "batch_going: 19\n",
      "change in Valid loss: -54.948320388793945\n",
      "batch_going: 20\n",
      "change in Valid loss: -57.79874801635742\n",
      "batch_going: 21\n",
      "change in Valid loss: -59.79233741760254\n",
      "batch_going: 22\n",
      "change in Valid loss: -61.687517166137695\n",
      "batch_going: 23\n",
      "change in Valid loss: -37.57460117340088\n",
      "batch_going: 24\n",
      "change in Valid loss: -27.576379776000977\n",
      "batch_going: 25\n",
      "change in Valid loss: -54.15419101715088\n",
      "batch_going: 26\n",
      "change in Valid loss: -82.23907470703125\n",
      "batch_going: 27\n",
      "change in Valid loss: -45.18596649169922\n",
      "batch_going: 28\n",
      "change in Valid loss: -54.07801628112793\n",
      "batch_going: 29\n",
      "change in Valid loss: -42.97610282897949\n",
      "batch_going: 30\n",
      "change in Valid loss: -45.63608646392822\n",
      "batch_going: 31\n",
      "change in Valid loss: -45.11094570159912\n",
      "batch_going: 32\n",
      "change in Valid loss: -48.2219123840332\n",
      "batch_going: 33\n",
      "change in Valid loss: -79.71652030944824\n",
      "batch_going: 34\n",
      "change in Valid loss: -60.529465675354004\n",
      "batch_going: 35\n",
      "change in Valid loss: -41.64870262145996\n",
      "batch_going: 36\n",
      "change in Valid loss: -43.87666702270508\n",
      "batch_going: 37\n",
      "change in Valid loss: -50.94525337219238\n",
      "batch_going: 38\n",
      "change in Valid loss: -49.366254806518555\n",
      "batch_going: 39\n",
      "change in Valid loss: -77.12904930114746\n",
      "batch_going: 40\n",
      "change in Valid loss: -35.4425048828125\n",
      "batch_going: 41\n",
      "change in Valid loss: -53.00397872924805\n",
      "batch_going: 42\n",
      "change in Valid loss: -50.14657020568848\n",
      "batch_going: 43\n",
      "change in Valid loss: -42.367024421691895\n",
      "batch_going: 44\n",
      "change in Valid loss: -43.01602363586426\n",
      "batch_going: 45\n",
      "change in Valid loss: -65.12687683105469\n",
      "batch_going: 46\n",
      "change in Valid loss: -61.121788024902344\n",
      "batch_going: 47\n",
      "change in Valid loss: -60.40398597717285\n",
      "batch_going: 48\n",
      "change in Valid loss: -35.93555450439453\n",
      "batch_going: 49\n",
      "change in Valid loss: -60.38315773010254\n",
      "batch_going: 50\n",
      "change in Valid loss: -47.12576866149902\n",
      "batch_going: 51\n",
      "change in Valid loss: -46.799988746643066\n",
      "batch_going: 52\n",
      "change in Valid loss: -47.559356689453125\n",
      "batch_going: 53\n",
      "change in Valid loss: -31.480109691619873\n",
      "batch_going: 54\n",
      "change in Valid loss: -45.740365982055664\n",
      "batch_going: 55\n",
      "change in Valid loss: -56.57722473144531\n",
      "batch_going: 56\n",
      "change in Valid loss: -68.39398860931396\n",
      "batch_going: 57\n",
      "change in Valid loss: -60.56328773498535\n",
      "batch_going: 58\n",
      "change in Valid loss: -59.17009353637695\n",
      "batch_going: 59\n",
      "change in Valid loss: -54.28990364074707\n",
      "batch_going: 60\n",
      "change in Valid loss: -40.27459144592285\n",
      "batch_going: 61\n",
      "change in Valid loss: -40.504417419433594\n",
      "batch_going: 62\n",
      "change in Valid loss: -57.296204566955566\n",
      "batch_going: 63\n",
      "change in Valid loss: -48.84499549865723\n",
      "batch_going: 64\n",
      "change in Valid loss: -63.16957950592041\n",
      "batch_going: 65\n",
      "change in Valid loss: -40.07218360900879\n",
      "batch_going: 66\n",
      "change in Valid loss: -58.59703063964844\n",
      "batch_going: 67\n",
      "change in Valid loss: -67.88575649261475\n",
      "batch_going: 68\n",
      "change in Valid loss: -51.29077434539795\n",
      "batch_going: 69\n",
      "change in Valid loss: -57.131080627441406\n",
      "batch_going: 70\n",
      "change in Valid loss: -49.59762096405029\n",
      "batch_going: 71\n",
      "change in Valid loss: -47.98088550567627\n",
      "batch_going: 72\n",
      "change in Valid loss: -43.305559158325195\n",
      "batch_going: 73\n",
      "change in Valid loss: -58.53806495666504\n",
      "batch_going: 74\n",
      "change in Valid loss: -55.64103126525879\n",
      "batch_going: 75\n",
      "change in Valid loss: -45.15676498413086\n",
      "batch_going: 76\n",
      "change in Valid loss: -36.44116163253784\n",
      "batch_going: 77\n",
      "change in Valid loss: -45.26284217834473\n",
      "batch_going: 78\n",
      "change in Valid loss: -66.40257835388184\n",
      "batch_going: 79\n",
      "change in Valid loss: -57.821879386901855\n",
      "batch_going: 80\n",
      "change in Valid loss: -46.452903747558594\n",
      "batch_going: 81\n",
      "change in Valid loss: -50.28097152709961\n",
      "batch_going: 82\n",
      "change in Valid loss: -39.928085803985596\n",
      "batch_going: 83\n",
      "change in Valid loss: -34.336700439453125\n",
      "Epoch: 13 \tTraining Loss: 12.501312 \tValidation Loss: 52.091146\n",
      "Validation loss decreased (54.501052 --> 52.091146).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        total_train_loss = 0.0\n",
    "        train_loss_prev=0.0\n",
    "        total_valid_loss = 0.0\n",
    "        valid_loss_prev=0.0\n",
    "        print(len(loaders['train']))\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        #print(list(enumerate(loaders['train'])))\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            print(\"Batch_idx\",batch_idx)\n",
    "        #for data,target in train_loader:\n",
    "            # move to GPU\n",
    "            if(batch_idx<len(loaders['train'])):\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                #print(data.shape)\n",
    "                output=model(data)\n",
    "                loss=criterion(output,target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss=(loss.item()*data.size(0))\n",
    "                total_train_loss+=train_loss\n",
    "                change_in_loss=train_loss_prev-train_loss\n",
    "                train_loss_prev=train_loss\n",
    "                print(\"batch_going:\",batch_idx)\n",
    "                print(\"Change in Train_loss:\",change_in_loss)\n",
    "                batch_idx+=1\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        print(\"train end, valid start\")     \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        batch_idx=0\n",
    "        for batch_idx,(data, target) in enumerate(loaders['valid']):\n",
    "        # move to GPU\n",
    "            if(batch_idx<len(loaders['valid'])):\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                ## update the average validation loss\n",
    "                output=model(data)\n",
    "                loss=criterion(output,target)\n",
    "                valid_loss=loss.item()*data.size(0)\n",
    "                total_valid_loss+=valid_loss\n",
    "                change_in_loss=valid_loss_prev-valid_loss\n",
    "                print(\"batch_going:\",batch_idx)\n",
    "                print(\"change in Valid loss:\",change_in_loss)\n",
    "                batch_idx+=1\n",
    "          \n",
    "        # print training/validation statistics \n",
    "        train_loss=total_train_loss/len(loaders['train'])\n",
    "        valid_loss=total_valid_loss/len(loaders['valid'])                                       \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation:loss has decreased\n",
    "        if (valid_loss<=valid_loss_min):\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model_scratch = train(13, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images.  Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 51.214133\n",
      "\n",
      "\n",
      "Test Accuracy: 11% (95/836)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    total_test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if batch_idx< len(loaders['test']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average test loss \n",
    "            total_test_loss+= loss.item()*data.size(0)\n",
    "            # convert output probabilities to predicted class\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions to true label\n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "            batch_idx+=1\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(total_test_loss/len(loaders['test'])))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively). \n",
    "\n",
    "If you like, **you are welcome to use the same data loaders from the previous step**, when you created a CNN from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 6677 6678 6679]\n",
      "668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d634f44e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Specify data loaders\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0))) \n",
    "    print(\"showing\")\n",
    "    print(img.shape)# convert from Tensor image\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "transform=transforms.Compose([transforms.Resize([256,256]),transforms.RandomCrop(224),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])])\n",
    "batch_size=10\n",
    "\n",
    "train_data=datasets.ImageFolder(root=\"/data/dog_images/train\",transform=transform)\n",
    "test_data=datasets.ImageFolder(root=\"/data/dog_images/test\",transform=transform)\n",
    "valid_data=datasets.ImageFolder(root=\"/data/dog_images/valid\",transform=transform)\n",
    "\n",
    "train_list=np.arange(0,len(train_data))\n",
    "print(train_list)\n",
    "test_list=np.arange(0,len(test_data))\n",
    "valid_list=np.arange(0,len(valid_data))\n",
    "train_sampler = SubsetRandomSampler(train_list)\n",
    "valid_sampler = SubsetRandomSampler(valid_list)\n",
    "test_sampler=SubsetRandomSampler(test_list)\n",
    "\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_data,batch_size=batch_size,sampler=train_sampler)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid_data,batch_size=batch_size,sampler=valid_sampler)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_data,batch_size=batch_size,sampler=test_sampler)\n",
    "print(len(train_loader))\n",
    "#print(train_loader)\n",
    "#for data,target in train_loader:\n",
    "#    print(\"data:\",len(data))\n",
    "#    print(\"Target:\",len(target))\n",
    "dataiter=iter(train_loader)\n",
    "images,labels=dataiter.next()\n",
    "images=images.numpy()\n",
    "fig=plt.figure(figsize=(25,4))\n",
    "'''for idx in np.arange(10):\n",
    "    ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
    "    #p=images[0][idx]\n",
    "    #imshow(images[idx])\n",
    "    #print(images[0].shape)\n",
    "    #print(\"done moving next\")\n",
    "    #ax.set_title(labels[idx])'''\n",
    "loaders_transfer=dict()\n",
    "loaders_transfer['train']=train_loader\n",
    "loaders_transfer['valid']=valid_loader\n",
    "loaders_transfer['test']=test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=133, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "## TODO: Specify model architecture \n",
    "\n",
    "vgg16=models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "#freezing the parameters\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "n_inputs = vgg16.classifier[6].in_features\n",
    "\n",
    "# add last linear layer (n_inputs -> 5 flower classes)\n",
    "# new layers automatically have requires_grad = True\n",
    "last_layer = nn.Linear(n_inputs, 133)\n",
    "\n",
    "vgg16.classifier[6] = last_layer\n",
    "print(vgg16)\n",
    "\n",
    "if use_cuda:\n",
    "    vgg16=vgg16.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(vgg16.classifier.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 51.95561408996582\n",
      "train_loss: 100.56838035583496\n",
      "train_loss: 154.6048879623413\n",
      "train_loss: 201.7685317993164\n",
      "train_loss: 253.1181287765503\n",
      "train_loss: 301.38601779937744\n",
      "train_loss: 351.96516513824463\n",
      "train_loss: 395.46735286712646\n",
      "train_loss: 445.9063386917114\n",
      "train_loss: 491.0815382003784\n",
      "train_loss: 533.9075517654419\n",
      "train_loss: 577.6808738708496\n",
      "train_loss: 607.8571128845215\n",
      "train_loss: 640.5346298217773\n",
      "train_loss: 684.6516227722168\n",
      "train_loss: 735.8925914764404\n",
      "train_loss: 775.7430028915405\n",
      "train_loss: 822.7896547317505\n",
      "train_loss: 856.2545108795166\n",
      "train_loss: 895.6198167800903\n",
      "train_loss: 932.974808216095\n",
      "train_loss: 982.1008658409119\n",
      "train_loss: 1018.5142111778259\n",
      "train_loss: 1055.143666267395\n",
      "train_loss: 1096.8035697937012\n",
      "train_loss: 1140.664496421814\n",
      "train_loss: 1172.4920773506165\n",
      "train_loss: 1213.8115048408508\n",
      "train_loss: 1241.2314176559448\n",
      "train_loss: 1280.5525279045105\n",
      "train_loss: 1305.3650212287903\n",
      "train_loss: 1339.3409085273743\n",
      "train_loss: 1371.7576789855957\n",
      "train_loss: 1418.9869594573975\n",
      "train_loss: 1456.6726851463318\n",
      "train_loss: 1478.9266276359558\n",
      "train_loss: 1510.3532409667969\n",
      "train_loss: 1540.3203129768372\n",
      "train_loss: 1572.9211473464966\n",
      "train_loss: 1611.6783833503723\n",
      "train_loss: 1643.3816194534302\n",
      "train_loss: 1678.835849761963\n",
      "train_loss: 1713.3449029922485\n",
      "train_loss: 1744.806067943573\n",
      "train_loss: 1781.96053981781\n",
      "train_loss: 1816.3666605949402\n",
      "train_loss: 1848.5811614990234\n",
      "train_loss: 1879.2136430740356\n",
      "train_loss: 1913.6345767974854\n",
      "train_loss: 1937.5053882598877\n",
      "train_loss: 1962.0410633087158\n",
      "train_loss: 1991.3810443878174\n",
      "train_loss: 2025.6681108474731\n",
      "train_loss: 2048.8303780555725\n",
      "train_loss: 2087.2689509391785\n",
      "train_loss: 2113.966164588928\n",
      "train_loss: 2131.63259267807\n",
      "train_loss: 2154.6069765090942\n",
      "train_loss: 2179.528329372406\n",
      "train_loss: 2198.9967954158783\n",
      "train_loss: 2214.740779399872\n",
      "train_loss: 2240.511133670807\n",
      "train_loss: 2268.8827562332153\n",
      "train_loss: 2297.7954292297363\n",
      "train_loss: 2319.969642162323\n",
      "train_loss: 2335.3667736053467\n",
      "train_loss: 2349.9809110164642\n",
      "train_loss: 2375.014079809189\n",
      "train_loss: 2402.007340192795\n",
      "train_loss: 2415.193428993225\n",
      "train_loss: 2436.767075061798\n",
      "train_loss: 2461.6465163230896\n",
      "train_loss: 2483.793616294861\n",
      "train_loss: 2514.149079322815\n",
      "train_loss: 2524.9510967731476\n",
      "train_loss: 2538.9188039302826\n",
      "train_loss: 2559.4822323322296\n",
      "train_loss: 2578.805238008499\n",
      "train_loss: 2595.3860580921173\n",
      "train_loss: 2611.3733053207397\n",
      "train_loss: 2621.356965303421\n",
      "train_loss: 2649.8606884479523\n",
      "train_loss: 2670.918756723404\n",
      "train_loss: 2684.8523092269897\n",
      "train_loss: 2716.4435482025146\n",
      "train_loss: 2746.727044582367\n",
      "train_loss: 2771.6114449501038\n",
      "train_loss: 2794.679548740387\n",
      "train_loss: 2811.3570070266724\n",
      "train_loss: 2837.0721554756165\n",
      "train_loss: 2861.254189014435\n",
      "train_loss: 2881.541955471039\n",
      "train_loss: 2895.8400547504425\n",
      "train_loss: 2914.018063545227\n",
      "train_loss: 2929.9729311466217\n",
      "train_loss: 2963.050767183304\n",
      "train_loss: 2974.2267727851868\n",
      "train_loss: 2989.8267316818237\n",
      "train_loss: 3021.819200515747\n",
      "train_loss: 3038.4004080295563\n",
      "train_loss: 3057.8981626033783\n",
      "train_loss: 3068.1007742881775\n",
      "train_loss: 3088.706474304199\n",
      "train_loss: 3106.688826084137\n",
      "train_loss: 3125.1523208618164\n",
      "train_loss: 3153.1240916252136\n",
      "train_loss: 3173.7116384506226\n",
      "train_loss: 3181.023411154747\n",
      "train_loss: 3197.842109799385\n",
      "train_loss: 3210.6355863809586\n",
      "train_loss: 3222.088696360588\n",
      "train_loss: 3233.992068171501\n",
      "train_loss: 3250.239241719246\n",
      "train_loss: 3269.0336388349533\n",
      "train_loss: 3277.5511199235916\n",
      "train_loss: 3301.231330037117\n",
      "train_loss: 3317.566470503807\n",
      "train_loss: 3337.2820407152176\n",
      "train_loss: 3357.128546833992\n",
      "train_loss: 3376.2189477682114\n",
      "train_loss: 3387.254530787468\n",
      "train_loss: 3406.16630256176\n",
      "train_loss: 3423.4425669908524\n",
      "train_loss: 3439.2310601472855\n",
      "train_loss: 3472.3066836595535\n",
      "train_loss: 3491.6099828481674\n",
      "train_loss: 3509.2144829034805\n",
      "train_loss: 3534.9994975328445\n",
      "train_loss: 3543.8123589754105\n",
      "train_loss: 3551.6125839948654\n",
      "train_loss: 3563.556999564171\n",
      "train_loss: 3580.152146220207\n",
      "train_loss: 3593.373970389366\n",
      "train_loss: 3608.6590868234634\n",
      "train_loss: 3624.1892904043198\n",
      "train_loss: 3650.9262484312057\n",
      "train_loss: 3668.6678582429886\n",
      "train_loss: 3677.962131500244\n",
      "train_loss: 3696.8968272209167\n",
      "train_loss: 3707.2256338596344\n",
      "train_loss: 3726.68350815773\n",
      "train_loss: 3732.0595490932465\n",
      "train_loss: 3744.490158557892\n",
      "train_loss: 3752.862764596939\n",
      "train_loss: 3766.029281616211\n",
      "train_loss: 3791.090931892395\n",
      "train_loss: 3803.930552005768\n",
      "train_loss: 3814.316508769989\n",
      "train_loss: 3821.0571986436844\n",
      "train_loss: 3833.2628363370895\n",
      "train_loss: 3849.70341861248\n",
      "train_loss: 3863.057454228401\n",
      "train_loss: 3887.936368584633\n",
      "train_loss: 3903.3665531873703\n",
      "train_loss: 3925.0543135404587\n",
      "train_loss: 3947.4742072820663\n",
      "train_loss: 3962.9045075178146\n",
      "train_loss: 3971.5946024656296\n",
      "train_loss: 3980.767417550087\n",
      "train_loss: 3994.141736626625\n",
      "train_loss: 4009.0931636095047\n",
      "train_loss: 4015.5653512477875\n",
      "train_loss: 4029.845744371414\n",
      "train_loss: 4045.690129995346\n",
      "train_loss: 4065.589781999588\n",
      "train_loss: 4081.282024383545\n",
      "train_loss: 4104.94410276413\n",
      "train_loss: 4120.888516902924\n",
      "train_loss: 4139.574273824692\n",
      "train_loss: 4152.612148523331\n",
      "train_loss: 4166.761186122894\n",
      "train_loss: 4190.344579219818\n",
      "train_loss: 4195.859451889992\n",
      "train_loss: 4207.66156733036\n",
      "train_loss: 4224.7768419981\n",
      "train_loss: 4244.479264616966\n",
      "train_loss: 4254.770647883415\n",
      "train_loss: 4263.678684830666\n",
      "train_loss: 4273.224174976349\n",
      "train_loss: 4295.488665103912\n",
      "train_loss: 4311.5050411224365\n",
      "train_loss: 4324.86216545105\n",
      "train_loss: 4342.503499984741\n",
      "train_loss: 4357.309631109238\n",
      "train_loss: 4373.857551813126\n",
      "train_loss: 4390.972582101822\n",
      "train_loss: 4404.43944811821\n",
      "train_loss: 4416.1096704006195\n",
      "train_loss: 4433.138099908829\n",
      "train_loss: 4449.614247083664\n",
      "train_loss: 4458.1503438949585\n",
      "train_loss: 4480.002956390381\n",
      "train_loss: 4491.08610868454\n",
      "train_loss: 4502.693345546722\n",
      "train_loss: 4510.754432082176\n",
      "train_loss: 4536.586536765099\n",
      "train_loss: 4546.8244951963425\n",
      "train_loss: 4555.255780220032\n",
      "train_loss: 4568.813143968582\n",
      "train_loss: 4583.060067892075\n",
      "train_loss: 4602.468081712723\n",
      "train_loss: 4617.661212682724\n",
      "train_loss: 4624.021944999695\n",
      "train_loss: 4640.027391910553\n",
      "train_loss: 4654.244312047958\n",
      "train_loss: 4673.228105306625\n",
      "train_loss: 4688.261433839798\n",
      "train_loss: 4702.138165235519\n",
      "train_loss: 4709.448427557945\n",
      "train_loss: 4721.258394122124\n",
      "train_loss: 4738.495698571205\n",
      "train_loss: 4747.775569558144\n",
      "train_loss: 4757.982329726219\n",
      "train_loss: 4769.915658831596\n",
      "train_loss: 4772.084167301655\n",
      "train_loss: 4781.22133821249\n",
      "train_loss: 4787.971380650997\n",
      "train_loss: 4792.8138884902\n",
      "train_loss: 4814.622543752193\n",
      "train_loss: 4834.728167951107\n",
      "train_loss: 4848.058305680752\n",
      "train_loss: 4863.019449412823\n",
      "train_loss: 4876.452752053738\n",
      "train_loss: 4889.864102303982\n",
      "train_loss: 4901.9895657897\n",
      "train_loss: 4914.861868321896\n",
      "train_loss: 4925.562306344509\n",
      "train_loss: 4937.534060180187\n",
      "train_loss: 4950.483848750591\n",
      "train_loss: 4963.079849183559\n",
      "train_loss: 4976.766175925732\n",
      "train_loss: 4983.130551278591\n",
      "train_loss: 4990.877873599529\n",
      "train_loss: 4998.28023403883\n",
      "train_loss: 5007.273737490177\n",
      "train_loss: 5025.402506887913\n",
      "train_loss: 5031.355672180653\n",
      "train_loss: 5047.123592197895\n",
      "train_loss: 5059.184935390949\n",
      "train_loss: 5070.742011368275\n",
      "train_loss: 5078.947221338749\n",
      "train_loss: 5087.644856870174\n",
      "train_loss: 5096.712150275707\n",
      "train_loss: 5105.7123801112175\n",
      "train_loss: 5119.541618525982\n",
      "train_loss: 5133.169312179089\n",
      "train_loss: 5136.495326757431\n",
      "train_loss: 5155.8875596523285\n",
      "train_loss: 5177.045804262161\n",
      "train_loss: 5190.006432533264\n",
      "train_loss: 5212.993631362915\n",
      "train_loss: 5222.316681742668\n",
      "train_loss: 5225.807240009308\n",
      "train_loss: 5244.201189279556\n",
      "train_loss: 5260.809347629547\n",
      "train_loss: 5270.136711597443\n",
      "train_loss: 5283.244638442993\n",
      "train_loss: 5304.213762283325\n",
      "train_loss: 5313.736675977707\n",
      "train_loss: 5334.424375295639\n",
      "train_loss: 5349.602185487747\n",
      "train_loss: 5356.1055344343185\n",
      "train_loss: 5368.501519560814\n",
      "train_loss: 5385.933839678764\n",
      "train_loss: 5404.442016482353\n",
      "train_loss: 5413.061028122902\n",
      "train_loss: 5423.724464774132\n",
      "train_loss: 5433.395975232124\n",
      "train_loss: 5440.806171298027\n",
      "train_loss: 5457.558941245079\n",
      "train_loss: 5463.6273765563965\n",
      "train_loss: 5468.162152767181\n",
      "train_loss: 5483.730456829071\n",
      "train_loss: 5487.672021985054\n",
      "train_loss: 5492.278129756451\n",
      "train_loss: 5496.573539078236\n",
      "train_loss: 5513.147238790989\n",
      "train_loss: 5522.718840539455\n",
      "train_loss: 5533.065330684185\n",
      "train_loss: 5542.972442805767\n",
      "train_loss: 5555.340833365917\n",
      "train_loss: 5558.745546042919\n",
      "train_loss: 5581.895558536053\n",
      "train_loss: 5589.928937256336\n",
      "train_loss: 5598.668750822544\n",
      "train_loss: 5612.113318741322\n",
      "train_loss: 5642.159674465656\n",
      "train_loss: 5653.196404278278\n",
      "train_loss: 5666.002211868763\n",
      "train_loss: 5684.466620981693\n",
      "train_loss: 5688.895165622234\n",
      "train_loss: 5700.832452476025\n",
      "train_loss: 5719.445333182812\n",
      "train_loss: 5732.256581485271\n",
      "train_loss: 5754.306580722332\n",
      "train_loss: 5764.6012160182\n",
      "train_loss: 5770.147710740566\n",
      "train_loss: 5777.186799943447\n",
      "train_loss: 5784.860756099224\n",
      "train_loss: 5798.342876136303\n",
      "train_loss: 5803.087011873722\n",
      "train_loss: 5807.053623795509\n",
      "train_loss: 5822.676103711128\n",
      "train_loss: 5837.628727555275\n",
      "train_loss: 5848.046520352364\n",
      "train_loss: 5861.029877066612\n",
      "train_loss: 5873.943000435829\n",
      "train_loss: 5881.396487951279\n",
      "train_loss: 5893.43067407608\n",
      "train_loss: 5911.979328393936\n",
      "train_loss: 5924.6437776088715\n",
      "train_loss: 5939.716891050339\n",
      "train_loss: 5954.885404109955\n",
      "train_loss: 5964.634318947792\n",
      "train_loss: 5980.5901473760605\n",
      "train_loss: 5998.446382880211\n",
      "train_loss: 6011.0093384981155\n",
      "train_loss: 6016.881150603294\n",
      "train_loss: 6026.322389245033\n",
      "train_loss: 6034.295846819878\n",
      "train_loss: 6040.085981488228\n",
      "train_loss: 6059.897872805595\n",
      "train_loss: 6070.82607448101\n",
      "train_loss: 6079.466688036919\n",
      "train_loss: 6093.606271147728\n",
      "train_loss: 6100.576785802841\n",
      "train_loss: 6105.871729850769\n",
      "train_loss: 6123.230555057526\n",
      "train_loss: 6137.886537313461\n",
      "train_loss: 6155.254688262939\n",
      "train_loss: 6166.407397985458\n",
      "train_loss: 6172.5191378593445\n",
      "train_loss: 6186.502857208252\n",
      "train_loss: 6200.606600046158\n",
      "train_loss: 6216.5127646923065\n",
      "train_loss: 6226.939561367035\n",
      "train_loss: 6235.256887078285\n",
      "train_loss: 6242.1140229702\n",
      "train_loss: 6244.880489110947\n",
      "train_loss: 6246.514455974102\n",
      "train_loss: 6258.417815864086\n",
      "train_loss: 6278.744363486767\n",
      "train_loss: 6288.567740023136\n",
      "train_loss: 6292.586373388767\n",
      "train_loss: 6301.348899900913\n",
      "train_loss: 6313.331175148487\n",
      "train_loss: 6322.73581713438\n",
      "train_loss: 6334.337863624096\n",
      "train_loss: 6353.302943408489\n",
      "train_loss: 6363.2342103123665\n",
      "train_loss: 6368.218546807766\n",
      "train_loss: 6379.609795510769\n",
      "train_loss: 6387.055920660496\n",
      "train_loss: 6392.36584931612\n",
      "train_loss: 6396.547118127346\n",
      "train_loss: 6402.949487864971\n",
      "train_loss: 6407.998134791851\n",
      "train_loss: 6421.396331489086\n",
      "train_loss: 6434.6726831793785\n",
      "train_loss: 6440.282157957554\n",
      "train_loss: 6451.088542044163\n",
      "train_loss: 6460.836024582386\n",
      "train_loss: 6473.807870447636\n",
      "train_loss: 6493.044889271259\n",
      "train_loss: 6514.8232010006905\n",
      "train_loss: 6525.744328796864\n",
      "train_loss: 6530.529764592648\n",
      "train_loss: 6545.446617305279\n",
      "train_loss: 6575.333504378796\n",
      "train_loss: 6588.83803576231\n",
      "train_loss: 6598.272198736668\n",
      "train_loss: 6602.696133553982\n",
      "train_loss: 6608.079083263874\n",
      "train_loss: 6615.977986752987\n",
      "train_loss: 6621.488392055035\n",
      "train_loss: 6632.844509780407\n",
      "train_loss: 6637.331087887287\n",
      "train_loss: 6648.889357149601\n",
      "train_loss: 6656.750912964344\n",
      "train_loss: 6666.855466663837\n",
      "train_loss: 6683.6656203866005\n",
      "train_loss: 6697.974998056889\n",
      "train_loss: 6706.923761069775\n",
      "train_loss: 6720.912332236767\n",
      "train_loss: 6727.626441419125\n",
      "train_loss: 6734.277362525463\n",
      "train_loss: 6744.08962816\n",
      "train_loss: 6756.423434913158\n",
      "train_loss: 6768.077604472637\n",
      "train_loss: 6773.328659832478\n",
      "train_loss: 6782.822233736515\n",
      "train_loss: 6792.867250740528\n",
      "train_loss: 6803.890952169895\n",
      "train_loss: 6815.6056717038155\n",
      "train_loss: 6824.229485094547\n",
      "train_loss: 6832.891623079777\n",
      "train_loss: 6843.881638348103\n",
      "train_loss: 6852.34037309885\n",
      "train_loss: 6865.385901033878\n",
      "train_loss: 6876.388985216618\n",
      "train_loss: 6884.988833963871\n",
      "train_loss: 6904.1971281170845\n",
      "train_loss: 6919.381845295429\n",
      "train_loss: 6933.768407404423\n",
      "train_loss: 6942.415162622929\n",
      "train_loss: 6948.402807414532\n",
      "train_loss: 6960.701949298382\n",
      "train_loss: 6970.212744772434\n",
      "train_loss: 6973.728087842464\n",
      "train_loss: 6981.017594635487\n",
      "train_loss: 6986.870264112949\n",
      "train_loss: 6999.458465874195\n",
      "train_loss: 7010.333284437656\n",
      "train_loss: 7022.155615389347\n",
      "train_loss: 7036.035634577274\n",
      "train_loss: 7041.918633282185\n",
      "train_loss: 7043.457845449448\n",
      "train_loss: 7053.172302246094\n",
      "train_loss: 7062.165539860725\n",
      "train_loss: 7069.5127230882645\n",
      "train_loss: 7085.163055062294\n",
      "train_loss: 7097.1825486421585\n",
      "train_loss: 7099.2597380280495\n",
      "train_loss: 7104.473576843739\n",
      "train_loss: 7109.41550463438\n",
      "train_loss: 7120.124344527721\n",
      "train_loss: 7132.335145175457\n",
      "train_loss: 7140.043344795704\n",
      "train_loss: 7152.640039026737\n",
      "train_loss: 7160.884143412113\n",
      "train_loss: 7176.097183525562\n",
      "train_loss: 7184.499578773975\n",
      "train_loss: 7199.244138300419\n",
      "train_loss: 7207.184307873249\n",
      "train_loss: 7216.909741461277\n",
      "train_loss: 7230.606733858585\n",
      "train_loss: 7240.759692490101\n",
      "train_loss: 7253.905456364155\n",
      "train_loss: 7263.585234582424\n",
      "train_loss: 7274.990633428097\n",
      "train_loss: 7282.102527916431\n",
      "train_loss: 7300.479591190815\n",
      "train_loss: 7311.0922983288765\n",
      "train_loss: 7319.766103327274\n",
      "train_loss: 7325.513696372509\n",
      "train_loss: 7343.6063823103905\n",
      "train_loss: 7352.8560426831245\n",
      "train_loss: 7364.249188005924\n",
      "train_loss: 7371.498262584209\n",
      "train_loss: 7378.404041230679\n",
      "train_loss: 7383.897504508495\n",
      "train_loss: 7401.679807603359\n",
      "train_loss: 7413.887678086758\n",
      "train_loss: 7428.886092603207\n",
      "train_loss: 7444.131383597851\n",
      "train_loss: 7452.172147333622\n",
      "train_loss: 7461.458227932453\n",
      "train_loss: 7466.574592292309\n",
      "train_loss: 7481.178918778896\n",
      "train_loss: 7497.774553000927\n",
      "train_loss: 7503.839807212353\n",
      "train_loss: 7509.141153395176\n",
      "train_loss: 7515.046345293522\n",
      "train_loss: 7523.320812880993\n",
      "train_loss: 7534.682578742504\n",
      "train_loss: 7545.302604138851\n",
      "train_loss: 7550.042214691639\n",
      "train_loss: 7555.297159254551\n",
      "train_loss: 7564.40049380064\n",
      "train_loss: 7577.281984984875\n",
      "train_loss: 7585.319420397282\n",
      "train_loss: 7590.92624694109\n",
      "train_loss: 7598.572264611721\n",
      "train_loss: 7607.954819500446\n",
      "train_loss: 7620.326434671879\n",
      "train_loss: 7624.755419194698\n",
      "train_loss: 7632.78605312109\n",
      "train_loss: 7634.885729253292\n",
      "train_loss: 7637.067454755306\n",
      "train_loss: 7649.789219796658\n",
      "train_loss: 7658.393748104572\n",
      "train_loss: 7671.927630007267\n",
      "train_loss: 7679.098835885525\n",
      "train_loss: 7696.296631991863\n",
      "train_loss: 7719.134761989117\n",
      "train_loss: 7726.628759205341\n",
      "train_loss: 7733.274201452732\n",
      "train_loss: 7737.978088855743\n",
      "train_loss: 7748.648061752319\n",
      "train_loss: 7759.738647937775\n",
      "train_loss: 7763.038429319859\n",
      "train_loss: 7778.101154863834\n",
      "train_loss: 7783.192777335644\n",
      "train_loss: 7793.616792857647\n",
      "train_loss: 7798.61092120409\n",
      "train_loss: 7802.912676632404\n",
      "train_loss: 7810.279197394848\n",
      "train_loss: 7818.357826769352\n",
      "train_loss: 7822.340069711208\n",
      "train_loss: 7843.783822953701\n",
      "train_loss: 7855.6377145648\n",
      "train_loss: 7874.241332709789\n",
      "train_loss: 7876.745718717575\n",
      "train_loss: 7884.357535839081\n",
      "train_loss: 7893.661452531815\n",
      "train_loss: 7905.332518815994\n",
      "train_loss: 7921.919728517532\n",
      "train_loss: 7932.185682058334\n",
      "train_loss: 7937.684211730957\n",
      "train_loss: 7940.037152767181\n",
      "train_loss: 7947.820259332657\n",
      "train_loss: 7953.346813321114\n",
      "train_loss: 7966.315608620644\n",
      "train_loss: 7968.7816344201565\n",
      "train_loss: 7982.637723535299\n",
      "train_loss: 7987.89501413703\n",
      "train_loss: 7998.807591050863\n",
      "train_loss: 8006.068172305822\n",
      "train_loss: 8010.488927811384\n",
      "train_loss: 8011.954824477434\n",
      "train_loss: 8020.803216248751\n",
      "train_loss: 8031.271838694811\n",
      "train_loss: 8042.453634291887\n",
      "train_loss: 8047.97870233655\n",
      "train_loss: 8062.491730004549\n",
      "train_loss: 8071.938716322184\n",
      "train_loss: 8093.321510702372\n",
      "train_loss: 8099.705698639154\n",
      "train_loss: 8112.767573744059\n",
      "train_loss: 8121.629419475794\n",
      "train_loss: 8132.871234565973\n",
      "train_loss: 8144.12573710084\n",
      "train_loss: 8155.1182951033115\n",
      "train_loss: 8161.692381650209\n",
      "train_loss: 8172.704060822725\n",
      "train_loss: 8184.023466855288\n",
      "train_loss: 8195.852211266756\n",
      "train_loss: 8201.504071503878\n",
      "train_loss: 8209.335501343012\n",
      "train_loss: 8222.808509021997\n",
      "train_loss: 8227.788823395967\n",
      "train_loss: 8231.82585939765\n",
      "train_loss: 8235.070149749517\n",
      "train_loss: 8237.962264865637\n",
      "train_loss: 8247.947727292776\n",
      "train_loss: 8261.475227922201\n",
      "train_loss: 8269.852880090475\n",
      "train_loss: 8282.783849090338\n",
      "train_loss: 8290.954719632864\n",
      "train_loss: 8296.771407574415\n",
      "train_loss: 8305.557525008917\n",
      "train_loss: 8318.28275308013\n",
      "train_loss: 8321.933062523603\n",
      "train_loss: 8323.216216117144\n",
      "train_loss: 8336.862453967333\n",
      "train_loss: 8350.077108889818\n",
      "train_loss: 8360.63088491559\n",
      "train_loss: 8370.587558299303\n",
      "train_loss: 8373.401100188494\n",
      "train_loss: 8382.008443027735\n",
      "train_loss: 8387.053402811289\n",
      "train_loss: 8398.571087270975\n",
      "train_loss: 8403.668949157\n",
      "train_loss: 8414.350121766329\n",
      "train_loss: 8423.191824108362\n",
      "train_loss: 8434.014849811792\n",
      "train_loss: 8450.837855488062\n",
      "train_loss: 8468.237292915583\n",
      "train_loss: 8472.150356918573\n",
      "train_loss: 8483.047713190317\n",
      "train_loss: 8487.943510860205\n",
      "train_loss: 8500.151021331549\n",
      "train_loss: 8516.080208867788\n",
      "train_loss: 8529.249886125326\n",
      "train_loss: 8539.938390105963\n",
      "train_loss: 8554.096484035254\n",
      "train_loss: 8560.024510473013\n",
      "train_loss: 8567.153866738081\n",
      "train_loss: 8572.454392760992\n",
      "train_loss: 8586.143876165152\n",
      "train_loss: 8595.596128553152\n",
      "train_loss: 8605.518426150084\n",
      "train_loss: 8617.788218706846\n",
      "train_loss: 8632.438632696867\n",
      "train_loss: 8635.69068685174\n",
      "train_loss: 8643.933648020029\n",
      "train_loss: 8648.099270612001\n",
      "train_loss: 8658.961475640535\n",
      "train_loss: 8668.283602148294\n",
      "train_loss: 8675.720033198595\n",
      "train_loss: 8680.185102969408\n",
      "train_loss: 8692.379570752382\n",
      "train_loss: 8699.070530086756\n",
      "train_loss: 8704.600650817156\n",
      "train_loss: 8720.114093571901\n",
      "train_loss: 8739.273674041033\n",
      "train_loss: 8756.580780297518\n",
      "train_loss: 8764.256756454706\n",
      "train_loss: 8773.016171008348\n",
      "train_loss: 8785.69441869855\n",
      "train_loss: 8794.107880145311\n",
      "train_loss: 8811.002865582705\n",
      "train_loss: 8816.017504483461\n",
      "train_loss: 8824.39423635602\n",
      "train_loss: 8838.851342946291\n",
      "train_loss: 8852.568763047457\n",
      "train_loss: 8857.927386313677\n",
      "train_loss: 8866.963954120874\n",
      "train_loss: 8879.363161474466\n",
      "train_loss: 8898.555511385202\n",
      "train_loss: 8900.03755748272\n",
      "train_loss: 8919.88029897213\n",
      "train_loss: 8928.763065934181\n",
      "train_loss: 8933.91878604889\n",
      "train_loss: 8946.231210231781\n",
      "train_loss: 8954.746091365814\n",
      "train_loss: 8956.983465701342\n",
      "train_loss: 8967.022022753954\n",
      "train_loss: 8972.612722665071\n",
      "train_loss: 8975.34082815051\n",
      "train_loss: 8986.433312147856\n",
      "train_loss: 8994.65841576457\n",
      "train_loss: 8999.209764450788\n",
      "train_loss: 9011.590818613768\n",
      "train_loss: 9021.994286030531\n",
      "train_loss: 9032.082577198744\n",
      "train_loss: 9048.887726515532\n",
      "train_loss: 9049.244066923857\n",
      "train_loss: 9064.312586039305\n",
      "train_loss: 9088.812994211912\n",
      "train_loss: 9095.670591443777\n",
      "train_loss: 9097.160717099905\n",
      "train_loss: 9098.658739179373\n",
      "train_loss: 9111.218861192465\n",
      "train_loss: 9118.484764546156\n",
      "train_loss: 9124.242593497038\n",
      "train_loss: 9133.132133930922\n",
      "train_loss: 9143.905578106642\n",
      "train_loss: 9148.255592733622\n",
      "train_loss: 9159.524408727884\n",
      "train_loss: 9166.54484167695\n",
      "train_loss: 9174.560903459787\n",
      "train_loss: 9189.407154470682\n",
      "train_loss: 9209.77758064866\n",
      "train_loss: 9216.974480301142\n",
      "train_loss: 9232.21286430955\n",
      "train_loss: 9251.967064291239\n",
      "train_loss: 9257.128034979105\n",
      "train_loss: 9268.906830698252\n",
      "train_loss: 9276.700635105371\n",
      "train_loss: 9285.404955297709\n",
      "train_loss: 9307.582417875528\n",
      "train_loss: 9315.62926068902\n",
      "train_loss: 9320.927928835154\n",
      "train_loss: 9331.43708601594\n",
      "train_loss: 9332.267872691154\n",
      "train_loss: 9339.91284430027\n",
      "train_loss: 9349.451415538788\n",
      "train_loss: 9352.815930843353\n",
      "train_loss: 9362.406839728355\n",
      "train_loss: 9380.208852887154\n",
      "train_loss: 9390.689852833748\n",
      "train_loss: 9402.554175257683\n",
      "train_loss: 9411.434059143066\n",
      "train_loss: 9428.811286687851\n",
      "train_loss: 9435.347869992256\n",
      "train_loss: 9440.989975333214\n",
      "train_loss: 9456.50208413601\n",
      "Valid loss: 0.3443021699786186\n",
      "Valid loss: 15.70357870310545\n",
      "Valid loss: 30.150609724223614\n",
      "Valid loss: 37.878589145839214\n",
      "Valid loss: 53.021733276546\n",
      "Valid loss: 55.06729509681463\n",
      "Valid loss: 65.12336876243353\n",
      "Valid loss: 68.52233316749334\n",
      "Valid loss: 76.22939851135015\n",
      "Valid loss: 83.52425243705511\n",
      "Valid loss: 86.63570310920477\n",
      "Valid loss: 93.65746762603521\n",
      "Valid loss: 97.50916089862585\n",
      "Valid loss: 100.97384061664343\n",
      "Valid loss: 107.77027692645788\n",
      "Valid loss: 114.60260059684515\n",
      "Valid loss: 119.62848987430334\n",
      "Valid loss: 134.066662453115\n",
      "Valid loss: 150.95666732639074\n",
      "Valid loss: 162.47218575328588\n",
      "Valid loss: 167.68761422485113\n",
      "Valid loss: 171.41143288463354\n",
      "Valid loss: 184.89084091037512\n",
      "Valid loss: 194.30753078311682\n",
      "Valid loss: 196.86706211417913\n",
      "Valid loss: 198.19254826754332\n",
      "Valid loss: 205.6633509323001\n",
      "Valid loss: 215.17768871039152\n",
      "Valid loss: 228.9282263442874\n",
      "Valid loss: 230.53093563765287\n",
      "Valid loss: 237.90297519415617\n",
      "Valid loss: 240.38460742682219\n",
      "Valid loss: 241.6851593181491\n",
      "Valid loss: 247.51289676874876\n",
      "Valid loss: 252.77428340166807\n",
      "Valid loss: 257.06382643431425\n",
      "Valid loss: 262.34498511999846\n",
      "Valid loss: 268.1394375488162\n",
      "Valid loss: 275.640341155231\n",
      "Valid loss: 281.7926688119769\n",
      "Valid loss: 286.5870414301753\n",
      "Valid loss: 305.2019665762782\n",
      "Valid loss: 307.4362700805068\n",
      "Valid loss: 312.77930077165365\n",
      "Valid loss: 321.14280339330435\n",
      "Valid loss: 330.32246347516775\n",
      "Valid loss: 342.684270106256\n",
      "Valid loss: 345.97231682389975\n",
      "Valid loss: 349.95577927678823\n",
      "Valid loss: 354.05862744897604\n",
      "Valid loss: 361.8484925851226\n",
      "Valid loss: 371.63028236478567\n",
      "Valid loss: 378.30746229737997\n",
      "Valid loss: 382.8298794850707\n",
      "Valid loss: 391.8976139649749\n",
      "Valid loss: 393.58127158135176\n",
      "Valid loss: 408.14465682953596\n",
      "Valid loss: 412.600870244205\n",
      "Valid loss: 420.252419821918\n",
      "Valid loss: 430.0912393257022\n",
      "Valid loss: 440.6040681526065\n",
      "Valid loss: 448.6271144077182\n",
      "Valid loss: 452.7701483294368\n",
      "Valid loss: 455.6104866787791\n",
      "Valid loss: 461.03809338063\n",
      "Valid loss: 464.1333619877696\n",
      "Valid loss: 471.2485174462199\n",
      "Valid loss: 485.01156609505415\n",
      "Valid loss: 492.78976779431105\n",
      "Valid loss: 495.4721597954631\n",
      "Valid loss: 504.9605117365718\n",
      "Valid loss: 511.86881344765425\n",
      "Valid loss: 518.0521802231669\n",
      "Valid loss: 533.9467028900981\n",
      "Valid loss: 541.721612624824\n",
      "Valid loss: 544.651651494205\n",
      "Valid loss: 548.8495249673724\n",
      "Valid loss: 558.4919370338321\n",
      "Valid loss: 565.658851377666\n",
      "Valid loss: 567.6821849867702\n",
      "Valid loss: 573.5093293711543\n",
      "Valid loss: 584.2198322340846\n",
      "Valid loss: 589.647621922195\n",
      "Valid loss: 595.9725878760219\n",
      "Epoch: 1 \tTraining Loss: 9456.502084 \tValidation Loss: 595.972588\n",
      "Validation loss decreased (inf --> 595.972588).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_transfer =vgg16\n",
    "#train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "def train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, model_save):\n",
    "    valid_loss_min=np.Inf\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        train_loss=0.0\n",
    "        valid_loss=0.0\n",
    "        model_transfer.train()\n",
    "        for batch_idx,(dta,target) in enumerate(loaders_transfer['train']):\n",
    "            if use_cuda:\n",
    "                dta=dta.cuda()\n",
    "                target=target.cuda()\n",
    "            optimizer_transfer.zero_grad()\n",
    "            output=model_transfer(dta)\n",
    "            loss=criterion_transfer(output,target)\n",
    "            loss.backward()\n",
    "            optimizer_transfer.step()\n",
    "            train_loss+=loss.item()*dta.size(0)\n",
    "            print(\"train_loss:\",train_loss)\n",
    "        \n",
    "        model_transfer.eval()\n",
    "        for batch_idx,(dta,target) in enumerate(loaders_transfer['valid']):\n",
    "            if use_cuda:\n",
    "                dta=dta.cuda()\n",
    "                target=target.cuda()\n",
    "            optimizer_transfer.zero_grad()\n",
    "            output=model_transfer(dta)\n",
    "            loss=criterion_transfer(output,target)\n",
    "\n",
    "            valid_loss+=loss.item()*dta.size(0)\n",
    "            print(\"Valid loss:\",valid_loss)\n",
    "        trainloss=train_loss/(len(loaders_transfer['train']))\n",
    "        validloss=valid_loss/(len(loaders_transfer['valid']))\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        n_epochs, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model_transfer.state_dict(), model_save)\n",
    "        valid_loss_min = valid_loss\n",
    "n_epochs=1\n",
    "\n",
    "train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')         \n",
    "            \n",
    "            \n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterating : 0\n",
      "tensor(53, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(69, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(27, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(132, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(48, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(121, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(48, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(77, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(120, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(82, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(83, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(65, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(18, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(126, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(110, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(94, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(83, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(101, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(64, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(109, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(18, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(27, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(74, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(42, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(132, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(116, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(58, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(98, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(112, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(109, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(51, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(42, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(97, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(103, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(2, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(2, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(72, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(128, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(91, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(87, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(73, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(103, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(97, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(32, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(71, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(73, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(93, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(21, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(82, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(93, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(115, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(107, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(121, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(113, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(64, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(73, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(61, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(109, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(116, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(106, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(129, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(34, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(94, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(25, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(65, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(53, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(100, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(25, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(18, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(66, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(62, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(108, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(132, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(116, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(112, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(110, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(82, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(72, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(97, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(36, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(99, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(108, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(9, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(53, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(127, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(129, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(32, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(118, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(32, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(34, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(94, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(105, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(82, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(108, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(93, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(24, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(99, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(115, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(77, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(51, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(82, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(116, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(104, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(58, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(120, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(25, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(103, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(62, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(24, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(48, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(127, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(49, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(52, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(51, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(61, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(123, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(120, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(100, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(49, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(116, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(87, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(100, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(42, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(61, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(94, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(61, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(94, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(25, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(124, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(129, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(36, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(73, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(64, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(123, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(79, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(118, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(119, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(96, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(105, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(95, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(131, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(51, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(21, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(118, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(100, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(77, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(98, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(24, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(62, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(122, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(119, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(98, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(132, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(88, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(73, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(112, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(103, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(130, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(106, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(101, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(69, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(121, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(93, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(128, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(91, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(83, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(126, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(95, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(76, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(2, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(100, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(122, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(63, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(53, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(49, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(21, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(34, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(105, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(21, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(79, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(130, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(74, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(128, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(88, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(91, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(58, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(36, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(9, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(91, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(119, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(12, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(124, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(36, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(125, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(9, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(51, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(18, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(2, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(96, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(109, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(84, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(108, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(36, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(107, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(76, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(83, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(95, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(77, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(82, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(104, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(118, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(131, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(129, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(128, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(107, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(62, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(101, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(18, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(119, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(58, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(113, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(69, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(106, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(123, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(25, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(93, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(123, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(79, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(94, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(58, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(63, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(88, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(105, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(105, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(119, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(95, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(27, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(65, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(127, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(66, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(64, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(115, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(52, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(99, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(88, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(52, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(72, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(63, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(122, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(12, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(76, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(106, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(112, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(126, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(42, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(63, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(87, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(12, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(87, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(53, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(71, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(64, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(127, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(122, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(53, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(100, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(87, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(98, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(76, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(71, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(104, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(77, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(8, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(42, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(92, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(83, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(103, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(34, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(13, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(95, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(21, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(51, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(52, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(75, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(92, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(71, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(96, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(12, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(61, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(85, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(122, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(89, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(9, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(79, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(115, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(125, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(92, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(72, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(69, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(50, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(96, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(71, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(42, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(8, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(10, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(128, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(16, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(69, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(36, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(96, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(117, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(90, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(22, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(39, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(6, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(62, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(79, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(131, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(66, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(112, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(0, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(121, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(24, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(9, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(123, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(92, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(58, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(52, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(48, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(32, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(84, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(124, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(12, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(113, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(110, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(2, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(97, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(110, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(69, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(5, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(98, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(81, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(126, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(108, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(59, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(21, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(34, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(74, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(8, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(49, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(128, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(17, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(106, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(91, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(83, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(41, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(105, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(11, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(3, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(23, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(30, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(99, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(15, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(104, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(106, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(61, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(74, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(52, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(54, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(116, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(111, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(71, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(123, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(7, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(110, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(113, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(20, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(35, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(48, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(76, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(126, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(84, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(124, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(34, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(14, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(87, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(31, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(63, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(86, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(57, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(1, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(88, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(129, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(29, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(72, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(38, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(40, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(55, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(80, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(56, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(27, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(67, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(43, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(8, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(114, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(4, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(62, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(74, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(49, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(49, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(84, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(2, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(19, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(60, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(68, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(125, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(45, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(48, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(9, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(37, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(70, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(33, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(28, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(44, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(66, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(18, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(26, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(102, device='cuda:0')\n",
      "iterating : 0\n",
      "tensor(12, device='cuda:0')\n",
      "iterating : 1\n",
      "tensor(65, device='cuda:0')\n",
      "iterating : 2\n",
      "tensor(96, device='cuda:0')\n",
      "iterating : 3\n",
      "tensor(88, device='cuda:0')\n",
      "iterating : 4\n",
      "tensor(46, device='cuda:0')\n",
      "iterating : 5\n",
      "tensor(97, device='cuda:0')\n",
      "iterating : 6\n",
      "tensor(47, device='cuda:0')\n",
      "iterating : 7\n",
      "tensor(78, device='cuda:0')\n",
      "iterating : 8\n",
      "tensor(32, device='cuda:0')\n",
      "iterating : 9\n",
      "tensor(53, device='cuda:0')\n",
      "Test Loss: 0.752926\n",
      "\n",
      "Test Accuracy of     0: 50% ( 4/ 8)\n",
      "Test Accuracy of     1: 75% ( 6/ 8)\n",
      "Test Accuracy of     2: 83% ( 5/ 6)\n",
      "Test Accuracy of     3: 75% ( 6/ 8)\n",
      "Test Accuracy of     4: 100% (10/10)\n",
      "Test Accuracy of     5: 87% ( 7/ 8)\n",
      "Test Accuracy of     6:  0% ( 0/ 7)\n",
      "Test Accuracy of     7: 100% ( 8/ 8)\n",
      "Test Accuracy of     8: 25% ( 1/ 4)\n",
      "Test Accuracy of     9: 83% ( 5/ 6)\n",
      "\n",
      "Test Accuracy (Overall): 79% (657/830)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders_transfer, model_transfer, criterion_transfer, use_cuda):\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(1,134))\n",
    "    class_total = list(0. for i in range(1,134))\n",
    "    batch_size=10\n",
    "    model_transfer.eval()\n",
    "    # iterate over test data\n",
    "    for dta, target in loaders_transfer['test']:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if len(target)<10:\n",
    "            break\n",
    "        if use_cuda:\n",
    "            dta, target = dta.cuda(), target.cuda()\n",
    "            #print(len(target))\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model_transfer(dta)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion_transfer(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*dta.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate test accuracy for each object class\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            print(\"iterating :\",i)\n",
    "            \n",
    "            label = target.data[i]\n",
    "            print(label)\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # average test loss\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                i, 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))\n",
    "\n",
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "Mastiff\n",
      "tensor([ 102], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mastiff'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "from PIL import Image\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    transform=transforms.Compose([transforms.Resize([256,256]),transforms.RandomCrop(224),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    im=Image.open(img_path)\n",
    "    img=transform(im)\n",
    "    \n",
    "    img=img.unsqueeze(0)\n",
    "    print(img.size())\n",
    "    img=img.cuda()\n",
    "    output=model_transfer(img)\n",
    "    _, pred = torch.max(output, 1) \n",
    "    print(class_names[pred])\n",
    "    print(pred)\n",
    "    \n",
    "    return class_names[pred]\n",
    "\n",
    "predict_breed_transfer('/data/dog_images/train/103.Mastiff/Mastiff_06833.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `human_detector` functions developed above.  You are __required__ to use your CNN from Step 4 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def run_app(img_path):\n",
    "    if img_path is not None:\n",
    "        name=predict_breed_transfer(img_path)\n",
    "        print(name)\n",
    "    else:\n",
    "        print(\"not found\")\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that _you_ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ (Three possible points for improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "American staffordshire terrier\n",
      "tensor([ 7], device='cuda:0')\n",
      "American staffordshire terrier\n",
      "torch.Size([1, 3, 224, 224])\n",
      "Bull terrier\n",
      "tensor([ 38], device='cuda:0')\n",
      "Bull terrier\n",
      "torch.Size([1, 3, 224, 224])\n",
      "Old english sheepdog\n",
      "tensor([ 112], device='cuda:0')\n",
      "Old english sheepdog\n",
      "torch.Size([1, 3, 224, 224])\n",
      "Bullmastiff\n",
      "tensor([ 40], device='cuda:0')\n",
      "Bullmastiff\n",
      "torch.Size([1, 3, 224, 224])\n",
      "Mastiff\n",
      "tensor([ 102], device='cuda:0')\n",
      "Mastiff\n",
      "torch.Size([1, 3, 224, 224])\n",
      "Mastiff\n",
      "tensor([ 102], device='cuda:0')\n",
      "Mastiff\n"
     ]
    }
   ],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "\n",
    "## suggested code, below\n",
    "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
    "    run_app(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
